Microsoft Q# employs a concept of measurement that involves collapsing parity of a set of qubits. That is, if I give this type of measurement method 3 qubit indices, (and Pauli bases to measure each qubit in, but this can be applied externally,) then the chance of returning "0" is the overall probability of all even parity combinations of the bits, and the chance of returning "1" is that of all odd parity combinations of the bits, and the state ends up collapsed into entirely even or entirely odd parity, somewhat similar to our bit mask based probability methods.
This seemed exotic, to me, perhaps in anticipation of a particular real hardware architecture, and not highly demanded outside of Q#. Now that I have more experience with Q# and particularly Clifford set simulations, that initial impression might have been wrong; Microsoft's measurement variant is likely natural enough for Pauli operator stabilizer states. The simulation of this approach can likely be well-optimized, and the information we gain from this type of measurement might be very theoretically useful in algorithm design, (and I take that on the assertion of Microsoft's language design, but it's beginning to make more sense, why).
We have supported this type of measurement, but not with priority for optimization or inclusion in the base Qrack API. The "enhancement" portion of this issue is that we should pull that work back from the PInvoke DLL and support and optimize it in the base QInterface API. The "bug" portion is that, with updates to Microsoft's Q# runtime, we seem to have lapsed in proper expected support for this type of measurement, which might have never been perfectly implemented. This method is now a major "workhorse" for the Q# runtime unit tests, and it probably serves a similarly important role in the overall Q# paradigm, by design.
Several pulls including #520 addressed the bugs and updated the feature.
