People from Oak Ridge National Laboratory have investigated the software structure of CP2K:
https://www.osti.gov/servlets/purl/1493977
There is also some 'advice' on future development.
I must say that one of the authors contacted me to run CP2K on Summit-dev, but it is really a pity that she didn't ask advice on how to optimize DBCSR for Titan.
For instance, LIBXSMM can be used on AMD too (just requiring SSE). Actually, we also provide a specific LIBSMM version for Cray XK7 (i.e. Titan) ready to download from the toolchain...
Their concern is to get performance out-of-the-box, while we believe in external libraries and autotuning... this is it... That's to say that I disagree with most of the conclusions on section VII.D:
1)-4) See my comment above, we trust in vendor libraries... Any magic trick (Compiler auto-vectorization, OpenMP 4, OpenACC, OpenCL, ...) is not (yet) able to give a good performance. I really don't understand, should we reimplement our own FFTW?
2) OK
3) Well, actually adding a back-end is pretty easy. I take note for DBCSR on how to do that (and actually we have to explain how to use libsmm (and when to use it).
From what I understand they are mostly unhappy about CUDA because it's proprietary and might therefore not survive the next architecture change.
For for CUDA-C, section V:
Sections of code written in CUDA-C, currently only compatible with NVIDIA GPUs, are not considered portable components: all sections of code currently using CUDA-C would have to be rewritten for a different GPU with competitive performance.
What a surprise...
Well, maybe Oak Ridge should start running their LINPACK with OpenCL then.
LIBXSMM can be used on AMD (just requiring SSE)
Yes, even SSE4 as our default can be dropped on very old systems. SSE2 is part of the x86-64 definition (64-bit ABI), and 64-bits are required for LIBXSMM. In fact, building as a shared library under Linux automatically drops SSE4.2 because of .so's are used to build packages for various Linux distributions (and maintainers wanted to go back in time for more than a decade ;-). Regarding newer non-Intel processors, AVX/2 and AVX-512 are also just dispatched based on feature-bits (no vendor check).
Btw, thanks for sharing!
Did anybody figure out what exact workload they ran with CP2K?
I am not sure to fully understand their comment on dbcsr. I compile the full thing out of the box on summitdev, openpower, whatever you name it, bref, anything that support GPU. DBCSR should performs almost the same on these platforms provided that the computations are done on GPU. The CPU backend however is another story but I would not do much calculations CPU anyway.
the point 4 is kind of moot because most of the clusters in the world are either amd or intel. So it is logical to concentrate on the hardware we have at disposal.
It seems there is nothing actionable. Hence, I'm closing this issue for now.
