@itsubaki will be great add parallelization for tensor product.
As I know, we can sharding big matrix on different host and compute in parallel.
Do you have any ideas about it?
Yes. To speed up for tensor product on classical computer, we need distributed system. and Speedup is necessary not only for tensor products but also for all matrix operations. My idea is develop distributed system for matrix operation and this library use it.
Or, for speed up, we'd better choose Python, NumPy and GPU.
