Hi,
this issue is primarily along the lines of tensorflow/tensorflow@a90383a.
I was wondering if the tight pins in requirements.txt are primarily due to functionality or solvability? Reason is, that I'm thinking about adding this package to conda-forge but the restrictions currently make this difficult.
It seems like things like the numpy pin are primarily to make solving easier but I just wanted to double check if this is correct?
Thanks!
Hi @BastianZim thanks for opening the issue. There are a few reasons why we pin specific versions (most being for functionality)
Also note we use requirements.txt for setting up a development environment, but the requirements we impose on the user can be found in setup.py.
Most of these requirements trickle down to us from TF and the known toolchain + flags that are used to compile it. On conda I believe that the process isn't identical and it could wind up that you might need to compile TFQ using whatever flags match the ones on conda. Looking here: https://anaconda.org/conda-forge/tensorflow/files?version it looks like conda doesn't host TF 2.5.1, so that may already be a non-starter, until we can get an upgrade on the version of TF we depend on here in TFQ.
Hi @MichaelBroughton thanks for the reply. Let me answer in a list as well, just to make it easier.
requirements.txt
Ahh ok I didn't find it originally but just saw that it's under /release/setup.py. That makes it much easier.
On conda I believe that the process isn't identical and it could wind up that you might need to compile TFQ using whatever flags match the ones on conda.
Yes, conda-forge has it's own compiler infrastructure which is used for all packages and a bazel toolchain which is used to generate the respective flags. This is done to prevent the exact situation you described where different packages might end up not working together.
I would also have one question regarding the compilation: Proto etc. is generally, in my experience, required during compilation and then when running the package, but from what I can see the only thing required here (Besides the compiler toolchain) is Tensorflow. Is that correct?
We use the version of protoc provided by TensorFlow in our project (via bazel dependencies) when developing code:
This is a problem TensorFlow also has and is working on fixing here
Any updates on this issue or can it be closed?
TF fixed the protobuf issue in tensorflow/tensorflow@84f4092
