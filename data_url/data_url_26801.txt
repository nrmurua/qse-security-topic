Hi, I use one node with one Nvidia GPU to run the performance tests.
H2O-64, Fayalite-FIST and LiH-HFX can run finish in 2 hours. However, H2O-DFT-LS and H2O-64-RI-MP2 cannot and may hit some errors. Is there any limitations on these two performance tests if I use one node setting?
I also found that there is no performance test data with one node setting in the following link.
https://www.cp2k.org/performance:piz-daint-h2o-dft-ls
https://www.cp2k.org/performance:piz-daint-h2o-64-ri-mp2
Here is the attached error log.
H2O-DFT-LS-1-8.log
H2O-64-RI-MP2-2-2.log
Thanks,
Vitesse.
one of the logs show an allocation failure in CUFFT which suggest an out-of-memory. @vitesselin could you share some more info about your system?
@shoshijak any ideas?
As far as I can remember, it is very unlikely that a single node can run H2O-DFT-LS.inp because of memory footprint. I would assume it is the same for H2O-64-RI-MP2.
As far as I can remember, it is very unlikely that a single node can run H2O-DFT-LS.inp because of memory footprint. I would assume it is the same for H2O-64-RI-MP2.
That's right, these tests are too large (in terms of memory) for a single-node run.
@vitesselin If you'd like to run these tests on a single node, you can do so by reducing the test's NREP parameter, which controls the system's size.
If I'm not mistaken, with NREP 6, the system will be repeated 6 times in each of the 3 spatial dimensions, i.e. the system will be 6x6x6 = 216 times larger; the number of atoms in the system (and so, its memory) grow (more or less) cubically with NREP.
I've never run H2O-64-RI-MP2, but I agree with @alazzaro , it must be the same issue.
@dev-zero do you think this should be better documented? If you tell me where, I can take care of it.
@shoshijak one idea could be to create a tests/README.md or TESTING.MD to put documentation for testing with the code instead of https://www.cp2k.org/dev:regtesting and then create additional README.md in the given test directories for additional information.
If we are to use a somewhat structured approach in the documentation (tables or - key: value) for documenting minimal requirements on the test environment, we could then parse these requirements also from the new Python-based regtesting script by Ole.
What do you think?
@shoshijak one idea could be to create a tests/README.md or TESTING.MD to put documentation for testing with the code instead of https://www.cp2k.org/dev:regtesting and then create additional README.md in the given test directories for additional information.
Sounds good.
I feel a little daunted by this task because I've only run a small number of the CP2K tests, and I don't understand most acronyms (though I just discovered this page and wish I'd come across it sooner ðŸ˜‰)
Can I maybe open a draft PR with the docs I can contribute, then kindly ask other people to supplement it?
... we could then parse these requirements also from the new Python-based regtesting script by Ole.
Which python script?
Which python script?
I started to re-implement our do_regtest script in Python. Hopefully, I'll  get back to it after #458.
I think there is some confusion here between regtests and benchmarks. The original post by @vitesselin refers to the later.
I do agree that our benchmarks could use some curating. I suggest we start by moving them into a separate root directory /benchmarks and add a welcoming top-level README.md. Most of the individual benchmarks actually have already a README file. So, these would only need to be converted to Markdown and touched up. For further inspiration we can draw on our wiki page and PRACE incl. this doc starting page 27.
Regarding NREP, we should not encourage people to edited the input files. Instead we should provide copies with different NREP-values. This way a benchmark is uniquely identifiable by its input filename.
Thanks for the responses. I will ignore these two cases in one node system.
It is a good idea to create one more README for benchmark tests or python script to check the minmal requirments.
@oschuett Great, thank you for the detailed answer.
I'll open an issue to discuss the curating and documenting of cp2k benchmarks as a follow up to your suggestion.
Regarding NREP, we should not encourage people to edited the input files. Instead we should provide copies with different NREP-values. This way a benchmark is uniquely identifiable by its input filename.
I understand. In this case, I'll create a 1-node version of the H2O-DFT-LS benchmark, since it seems to be a popular one, and to avoid issues such as the current one in the future.
@shoshijak
How many nodes should I use at least if I want to run the current H2O-DFT-LS and H2O-64-RI-MP2 without changing current parameters? I have one node with 4 GPU cards.
Thanks,
Vitesse.
@vitesselin I have never run H2O-64-RI-MP2 , so I'm not sure about that.
H2O-DFT-LS can be run on 8 Piz Daint XC50 compute nodes.
I have one node with 4 GPU cards.
As far as I know, CP2K does not support multi-GPU. Meaning, in CP2K, 1 MPI rank cannot offload work to multiple GPUs, only to one. Therefore, to take full advantage of your node, you should run 4 MPI ranks and make sure each MPI rank has one dedicated GPU.
Perhaps try running H2O-DFT-LS on two of your nodes then?
The MP2 calculation with 32 water molecules runs with 8 nodes on the GPU section of Daint. For the 64 water molecules I need 16 nodes on a multicore section and 4 ranks per node. So, for the GPU section you might need 32 nodes. You should check that for your system.
