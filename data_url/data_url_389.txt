For code snippets like this:
observe should automatically broadcast the call based on the leading dimension of data rather than creating a for loop in python which can be slow.
Currently running an 8 qubit circuit with cudaq.set_qpu('cuquantum_mgpu') but can only see one gpu being utilized.
I am guessing that the multi gpu functionality is only used when the memory of the statevector exceeds what one gpu can handle?
It would be nice if the cudaq.observe call above on multiple data values can parallelize and distribute this over the multiple gpus available.
