A bug is detected while some simulations were run and analyzed. We have narrowed it down, and it seems that the delay time has a role to play in the final state. This isn't expected, given that a delay time in the beginning of a sequence shouldn't influence anything.
Below is the implementation of a simple quantum circuit using pulser.
The function create_sequence_with_delay takes the delay_time in nanoseconds and creates a sequence with one single qubit and apply a gate U(-pi/2,pi/2,pi/2). We'll see the effect of different delay times by drawing a graph.
Below is the result, the ideal state is what we should be expecting:

Let's see the sequence corresponding to a delay time of 100 ns.

The delay time only determines the window in the beginning.
Hi! Thanks for your question.
More than a bug in Pulser, this is a matter of setting QuTiP's solver options according to your simulation. In your case, try sim.run(max_step=0.1), with max_step half of your actual pulse length (since it was 200 ns, I set it to 0.1 Âµs).  Since you are adding a delay, the solver chooses automatically the initial step by default and thinks it has nothing ahead. You may check out other parameters in their documentation (https://qutip.org/docs/latest/guide/dynamics/dynamics-options.html).
EDIT: As it turns out, the current version of Pulser has a set max_step=5 parameter, which was thought for nano seconds. Since the user cannot change this by design, this is indeed a bug. I'll raise an issue.
