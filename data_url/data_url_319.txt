I am using the docker image cuda-quantum:latest. I have two GPUs on my machine. I start the container successfully and can see the GPUs in the container using nvidia-smi and python codes. I follow the cuda-quantum documentation and try to use cuquantum-mgpu backend. Please refer to "https://nvidia.github.io/cuda-quantum/latest/using/simulators.html#cuquantum-multi-node-multi-gpu".
I run "nvq++ examples/cpp/basics/static_kernel.cpp --target cuquantum_mgpu" but get "nvq++:426: Invalid Target: (cuquantum_mgpu)". Your Python examples give me the same error. However, the target "nvidia" works and the executable works well on a single GPU.
Is cuquantum_mgpu supported as described in your doc? How can I use this mgpu backend?
docker pull ghcr.io/nvidia/cuda-quantum:latest
docker run -it --gpus all --name cuda-quantum ghcr.io/nvidia/cuda-quantum
nvq++ examples/cpp/basics/static_kernel.cpp --target cuquantum_mgpu
An executable file should be built and able to run on multiple GPUs.
Not a regression
No response
I think this is because the documentation is not yet updated.
Using the ghcr.io/nvidia/cuda-quantum:latest docker image, I can use the multi-GPU target with:
(it printed 2 for me when I had 2 GPUs)
One thing to note is that there is a difference between the MQPU target and the single-state-vector multi-GPU simulation backend.
For the multi-GPU simulation backend, I don't think the latest docker image contains that work, as it is an internal implementation. I do think the next release (coming out in a week or so) will have that backend available. @bettinaheim could provide more detail.
@nadbp @amccaskey Correct - the images that were published continuously on GitHub so far only contained the components that are checked into this repository. The latest change now finally adds the mgpu backend also for the CD images. That said, the setup is not yet fully validated, and the tensornet backend is still not deployed on GitHub - I will need to make some updates to the internal repository first. We should get there in the next couple of weeks.
FYI, the docker image contains all currently supported backends starting with version 0.4.0 and newer.
Tien, are you looking at this with the tensornet work?
