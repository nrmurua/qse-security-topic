The method Covalent currently uses to retrieve the stdout and stderr logs of each task is unreliable. When multiple tasks are run concurrently, the messages output by one task may be inadvertently attributed to another task and stored in the wrong graph node.
The following workflow reproduces the problem on my machine.
After dispatching this workflow, I retrieved the result object and inspected the stdout property of each graph node. Here is what I get:
If I interchange the sleep statements, the output of each task is correctly retrieved and persisted:
Each executor's implementation of run() is currently expected to retrieve the stdout and stderr from the executor backend after a task completes and print those strings to sys.stdout and sys.stderr, respectively. These streams are redirected by a context manager in the base executor's implementation of execute() and returned to the dispatcher. For example, here is how the Dask executor captures the stdout for a task.
Since all executor instances monitor the same sys.stdout file descriptor, this technique breaks down when multiple tasks are writing to that file descriptor. The context manager for one task could inadvertently capture the output printed by the run() method for another task.
It would seem better for each task to print to its own "stdout" and "stderr" file descriptors which are not shared with any other task.
Acceptance Criteria
For BaseExecutor and AsyncBaseExecutor
Local and Dask executors should be adjusted:
 Add a functional test involving a workflow with multiple electrons concurrently printing to stdout and stderr. Verify that the messages generated by each task are stored in the correct transport graph node.
