The tests run with 1 or 2 qubits, so I actually wonder why they take so long.
We should profile, as @ShellyGarion did for randomized benchmarking. If compilation seems to be the problem, can we disable the transpiler?
Also related is the question of tests accuracy. The tests set the initial values for the fitter to be the correct fitting parameters. This does not mimic the reality, where the user does not know the correct parameters, so she sets as initial values her inaccurate estimates for the correct parameters.
If we stick with these accurate initial values, then we can decrease the gap (delta) that we allow between the real T1/T2/T2* and the computed one. This was indeed done in test_t2 and test_t2star, but not in test_t1. Alternatively, we can increase delta and decrease the number of shots and data points.
The problem is that aer's trajectory approach is good for large numbers of qubits, but has a lot of overhead for small numbers and needs a lot of shots to converge.
It depends what we want to test. To test the fitter I would suggest using pickled results then it's deterministic (are pickled results ok @mtreinish ?). To test the circuit generation we should generate the circuits and make sure they run on the qasm simulator.
