Currently QuTiP solvers are pure batch jobs. One calls a function, e.g. mesolve, which then runs until the state has been propagated to all requested time steps and then the function returns the result.
There are a variety of use cases where having access to results as they are calculated can be useful:
We're currently refactoring the QuTiP solvers for QuTiP v5, so perhaps now is a good time to consider whether this feature will see enough use to be worth the effort.
Implementation options:
Probably these are not mutually exclusive. To make porting easier, it should still be possible to call some solve function without a callback or yielding as one can do now.
Related issues:
@Ericgig (or any other QuTiP developers): Thoughts on this proposal? Is it something that's been on your wish list a long time? Seem really cool? Or not? Any concerns?
@goerz Would you mind elaborating a little on the use case you describe in qucontrol/krotov#93? How useful would something like this be to you? Do you think you'd keep an implementation based on this long term? Or would you end up implementing your own thing in the end anyway? Hoping we can continue to support the use cases of other libraries better and better.
Most of it is already in qutip or in development:
Which would work like a yield:
I prefer using steps since you don't have do define tlist first, you could use it in a while True loop or interactively.
@Ericgig .step(...) looks like a great solution. We should definine more precisely what one is allowed to modify in between calls to .step and document that.
Aside regarding things we have already implemented: I know -- my point is that there are many such things and we have only implemented one kind of each (for example, what kind of progress bar is appropriate is highly dependent on the environment the code is running in -- if the code is running on a server without a terminal it might be some kind of logging, inside a hypothetical QuTiP UI GUI application it might be a progress bar provided by the GUI toolkit being used, etc).
Wow! Thanks for getting on this!
Let me elaborate a little. First,
How useful would something like this be to you? Do you think you'd keep an implementation based on this long term? Or would you end up implementing your own thing in the end anyway?
It would be extremely useful. It would become the default propagator for the krotov package. I would expect that with the ability to propagate single time steps with mesolve, optimization becomes feasible for any system that mesolve can propagate over the entire time grid in less than a few seconds. That would be a huge improvement over the current situation, where the lack of a good propagator limits the optimization effectively to toy problems.
We may still try to implement in Cython some polynomial propagators (propagators that evaluate exp[-i H dt] Ψ or exp[L dt] ρ via expansion into a polynomial series - think Taylor series but faster converging, through the use of Chebychev or Newton polynomials). That work hasn't really been going anywhere lately, though. It may or may not end up being faster than mesolve, but it's certainly less flexible. So even then, an mesolve that can do single steps would still be great.
I would also think that being able to do time steps would be exceedingly useful to any gradient-based optimal control scheme. Wouldn't it greatly simplify your own GRAPE implementation? I'm referring to the "Object model" in Optimal Quantum Control in QuTiP, specifically the TimeslotComputer (in fact, we looked at whether TimeslotComputer could be used for krotov at the time, but couldn't quite figure it out)
I elaborated a little bit in qucontrol/krotov#93 (comment) on the requirements: beyond yielding the propagated states, we'll also have to modify the controls, i.e. the time-dependencies for QuTiP's nested-list format. Within the krotov package, these would always be numpy arrays. As an explanation, see the figure for Krotov's update scheme from the documentation. The single-step-mesolve would be for the "(2) forward-propagation with updated control" in the bottom of the diagram: After each propagation time step, we calculate a new control value based on the current propagated state and other information (the ∂H/∂ϵ and stored backward-propagated states χ). The new control value is then used for the next time step.
I'd also add that mesolve ideally should be "thread-safe" in the sense that we may have multiple mesolve run in parallel (index k in the diagram, where all the different k contribute to the update of the control values at the next time step), within whatever parallelization framework Python makes available. I vaguely remember looking at some Runge-Kutta implementations within scipy where this was a problem. I noted this in the docstring of krotov's DensityMatrixODEPropagator, which was an attempt to adapt some of mesolve's inner workings to Krotov's needs. It turned out the overhead was still too large for this work very well, cf. the large runtime of the corresponding example.
To get very technical, Krotov's requirements are laid out in the documentation of the Propagator abstract base class, DensityMatrixODEPropagator being a particular example. In particular, the interface we define there is strictly for a single time step, makes no reference to tlist and  we use H=[H0, [H1, u]] where u is a scalar for that particular timestep. However, I can easily write a wrapper around an mesolve that would work something along the lines of the pseudo-code from qucontrol/krotov#93 (comment):
So I don't think you'd have to worry about these details: any implementation with low overhead that would allow me to get the states from mesolve as well as tweak the control fields for the next time step should be sufficient. In particular, the .step that you discuss in #1571 (comment) looks very much like it's going in the right direction! The one option from the earlier #1571 (comment) that might not work very well is callback functions. I might be able to work around that, but it wouldn't really fit into the control flow of an optimization.  The code
from #1571 (comment) on the other hand would definitely fit the bill, assuming that args=new_args is the way to modify the control fields.
Sorry for the long explanation, but I hope this clarifies the use case. If not, I'll be happy to try to explain better! ;-)
Most of scipy's solver are not "thread-safe", but we will be able to use other solvers in the new version. We will be sure to add at least one which is thread safe.
The args=new_args refer to the args in [H0, [H1, f(t, args)]], in your case, you could use something like:
We don't have step interpolation with changing coefficient array. It could be added, but we will have to think about it. Using a mutable, as in your example, would create error with most ODE solver with variable step, so I would not recommend it.
That's a neat way to do it! I have total control over what I'm passing to mesolve, so there's actually no need to change the coefficient array then! Very nice!
I think you might be able to achieve a lot of what you want already.  The pseudo-code looks like it's not using mesolve super efficiently, though maybe it's only because of simplifications to make a MWE.  For example, if your controls are piecewise constant, then it might be inefficient to represent those terms as "time dependent"; doing so means you incur the cost of multiplying each term by a scalar at every intermediate step the integrator chooses to take, then you have to perform the matrix-vector product for each one individually and add them up.  It might be faster already if you evaluate the piecewise varying parts into one "constant" part at each point.  This isn't guaranteed, because it involves copying rather more data before the call (to construct the constant matrix once), but if the integrator would need to take many intermediate time steps, I expect it would win out.
Would something like this work for you?
By giving mesolve the Liouvillian instead of the Hamiltonian and collapse operators separately, you've already done most of its setup, so the time penalties should be much less than the current system (i.e. you avoid several Kronecker products and safety checks on the time-dependence terms because you've done them once at the start).  In theory, that should already work from at least 4.5 onwards, and likely most of it will work from 4.4.  In the 5.x series, almost all the intermediary operations should get a speed up as well (Qobj.__init__ is getting its time slashed, and the line current_liouvillian += control * operator may be able to be replaced with one that applies the same in-place calculation optimisations that mesolve does internally).  One thing you pay a nasty penalty for right now if that internally we'd keep column-stacking/unstacking the state, but in the 5.x branch it'll stop being represented internally by a sparse matrix, and instead it'll be a Fortran-ordered dense matrix, for which the stack/unstack is a free operation.
In the form I've written it, this loop is thread-safe already.  As it stands in the 4.x series, mesolve is re-entrant (I'm fairly sure), but note that it does generally mutate its arguments, especially if you pass a QobjEvo Liouvillian as the first argument.  As long as you make sure you give each thread a distinct copy of the input Liouvillian, mesolve itself doesn't access global state as far as I recall.
QuTiP 5 is (probably) going to formalise that (^) sort of low-level calling convention of mesolve, but it should work already. The new one look a bit different because instead of doing the setup very manually, there'll be a "low-level" function to prepare a master equation problem (and a Schrodinger equation one, etc), and then there'll be a step method instead of calling the "high-level" interface function mesolve, but functionally it'll do largely the same, just with a lot less data copying than the current form has to do.  In the new system, it's likely that the function mesolve itself will keep the exact same interface it has now, just internally most of its processing will be split into modular components, each of which will be accessible (with different names) to the user to compose themselves, if they want low-level access.
We're unlikely to add yield to mesolve directly because that's a very breaking change to one of QuTiP's core functions (we can't return from a generator, or at least not ergonomically), but we are splitting up the mesolve monolith into a much more modular architecture, and making it more user-accessible.  The other advantage of this is that the integrator component will just be one element of a composable system, so we'll not be tied to scipy integrators any more.
Oh, also, about callback functions and yield: if we did this, the patterns for making mesolve re-entrant and forwards-compatible without hamstringing our ability to extend the APIs in the future would probably not be very ergonomic.  Both callbacks and yield allow the caller to feed information back into mesolve, but in this architecture, we'd have to completely define an interchange API, and specify quite explicitly what "commands" you can tell this sort of mesolve state machine to execute.
The pattern in your original comment (reproduced here)
is probably a little fragile; doing this means we have to guarantee that at no point is the ctrl_array object copied.  If you wanted to branch off execution part-way through the iterator, you'd have to copy the whole state, and then you'd lose your reference to the control array unless you kept manually walking the structure of the time-dependent object (internally it gets converted into a QobjEvo Liouvillian) to retrieve it.  The other problem is that state0 and the Qobj parts of the Hamiltonian aren't mutable; the preprocessing of mesolve means that none of those objects will exist inside the integrator loop.  That's fine for this use-case, but it's not very general.  These problems of mutability would apply to callback functions as well.
A different way of using yield or callback function would be to really lean into a co-routine sort of pattern.  So mesolve internally would look like
and a call to mesolve would be like
That's not super user friendly, but it is nicely re-entrant.  You'd have a single object you can copy and branch off, and QuTiP would be able to update the relevant objects for you at any given time.  Still, I don't think it's a good strategy in general - we'd have to very rigorously define the "instructions" API, and it would be pretty awkward to use.  It would also be a nuisance for extensibility, probably; the intermediate state and instructions of mesolve would just more APIs we have to maintain and keep constant.  Note that you can achieve the exact same thing with a callback function pattern here, except that control would never really pass back to the caller, so it would be impossible to (for example) branch execution part way through.
The new, modular system we want to put into QuTiP 5 is an attempt to get the best of all these worlds.  For users who don't need all this low-level behaviour, there'll still be the convenient mesolve, which just keeps working the same way it does now.  For users (like you) who need more, we'll expose all the inner logic of the mesolve loop as separate components, so you'll still get all the nice set-up utilities if you want them, but you'll also then just be able to run the inner loop yourself.  Since everything is modular, you'll have access to modify everything that mesolve can access, so we won't need to define a specific, awkward API, and you can change it in whatever programming style you like, and is appropriate for your use case.
I also note that I'm not replying to the thread I thought I was - I thought I was in krotov!  For my response to the discussion points:
I think this architecture is approximately what Eric had in mind too, though I presumably haven't used the same names.
Ok, so I did some benchmarking at https://nbviewer.ipython.org/gist/goerz/34af142b78d7e344417d838bbea78aaf/06_example_3states_benchmark.ipynb (gist), based on one of the example notebooks from the Krotov package. I'll be referring to the numbered cells in that notebook in the discussion below.
@jakelishman in #1571 (comment):
I think you might be able to achieve a lot of what you want already. The pseudo-code looks like it's not using mesolve super efficiently, though maybe it's only because of simplifications to make a MWE. For example, if your controls are piecewise constant, then it might be inefficient to represent those terms as "time dependent"; doing so means you incur the cost of multiplying each term by a scalar at every intermediate step the integrator chooses to take, then you have to perform the matrix-vector product for each one individually and add them up.
That's certainly worth trying: when calling mesolve in a loop over the time grid, I did indeed see a significant speedup when summing the Lindbladian into a single constant Qobj, see In [21] vs In [24]. On the other hand, it doesn't always give a speedup: in the low-level DensityMatrixODEPropagator it actually makes the propagation slower, see In [29] vs In [32]. It's a bit surprising, but then, as you say:
[...] This isn't guaranteed, because it involves copying rather more data before the call
So that's ok.
Would something like this work for you? [...]
By giving mesolve the Liouvillian instead of the Hamiltonian and collapse operators separately
To be clear, I personally never use collapse operators (and the Krotov documentation heavily discourages it). Instead, I have a nested list like [L0, [L1, control1], ...] where L0, L1, ... are super-operators. I should also note that I use mesolve both for Schrödinger equations and Lindblad equations (relying on mesolve delegating to sesolve), and the Krotov package uses H as a variable/attribute name to refer to nested-Lindbladians or nested Hamiltonians interchangeable. Sorry if that's causing a bit of confusion. I am ultimately interested both in open system and closed system dynamics interchangeably.
[...] In the 5.x series, almost all the intermediary operations should get a speed up as well (Qobj.__init__ is getting its time slashed, and the line current_liouvillian += control * operator may be able to be replaced with one that applies the same in-place calculation optimisations that mesolve does internally). One thing you pay a nasty penalty for right now if that internally we'd keep column-stacking/unstacking the state, but in the 5.x branch it'll stop being represented internally by a sparse matrix, and instead it'll be a Fortran-ordered dense matrix, for which the stack/unstack is a free operation.
That's an extremely exciting prospect! I'd love to be able to have internal sparse data for Qobj's that represent Hamiltonians/Liouvillians, but dense data for Qobj's that represent Hilbert space states or Density matrices. In fact, it looks like a significant part of the overhead in the calculation of the Krotov's pulse update is due to the stacking/unstacking, see profile.svg in the gist. In the benchmarking notebook, for the optimization in In [34], that's the extra 6 seconds per iteration (iterations 1-3 should ideally take exactly twice as long as iteration 0, as iteration 0 is a simple forward propagation and all later iterations are one forward and one backward propagations). That's what we have in our Fortran implementation, too: the runtime of the optimization is basically just the runtime of all the internal propagations; calculating the updates should be completely negligible.
There's also shape conversions happening in DensityMatrixODEPropagator which would be nice to eliminate.
Lastly, having dense internal storage for states might actually give the same speedup as we've demonstrated in https://qucontrol.github.io/krotov/v1.2.1/notebooks/09_example_numpy.html for doing Krotov with numpy arrays instead of Qobj's -- potentially even more speedup, in fact, since with numpy now everything is dense (including the Hamiltonian), whereas the best thing to do numerically would be to do sparse-matrix-dense-vector operations (which is what we do in Fortran, incidentally).
In the form I've written it, this loop is thread-safe already. As it stands in the 4.x series, mesolve is re-entrant (I'm fairly sure), but note that it does generally mutate its arguments, especially if you pass a QobjEvo Liouvillian as the first argument. As long as you make sure you give each thread a distinct copy of the input Liouvillian, mesolve itself doesn't access global state as far as I recall.
Just to be clear: there's two interconnected issues here: One is just being "reentrant" in the sense that I can safely have multiple mesolve's run in parallel. This doesn't seem to be a problem for mesolve as a whole (propagating over the entire time grid). The other issue, at a lower level is whether I can keep the internal state of the integrator (scipy.integrate.ode or whatever else mesolve might be using) when propagating a single time step (and whether I can have multiple integrators to run in parallel that each safely keep track of their own state). That comes down to the integrator itself being "reentrant", of course. Certainly, calling mesolve in a loop (In [19]) doesn't keep the internal state of the integrator, hence the overhead between In [21] compared to In [18]. I wouldn't expect it to, of course, but the question is whether a refactoring of mesolves internals into an object that keeps state in a thread-safe way and allows doing time steps would alleviate this overhead (like the mesolve_prepare_ode(H, state, c_ops) -> OdeState that you propose in #1571 (comment)). On the other hand, looping over the full mesolve as in In [19] obviously has no problems with parallelization. I wasn't sure if that's what you meant by "mesolve is re-entrant" or whether recent changes in QuTiP now use a re-entrant internal integrator, i.e. not scipy.integrate.ode. At the time I implemented the DensityMatrixODEPropagator by looking at what mesolve was doing at a low level for the specific case of density matrices, scipy.integrate.ode was definitely being used, and that couldn't handle propagating in parallel (and by "parallel" I include alternating propagation steps from two different propagations).
I'm also not sure what using QobjEvo does: In the benchmarking, there didn't seem to be any difference whether I wrap my nested lists into QobjEvo or not. Is there something specific that QobjEvo should enable that I can't do with nested lists?
QuTiP 5 is (probably) going to formalise that (^) sort of low-level calling convention of mesolve, but it should work already. The new one look a bit different because instead of doing the setup very manually, there'll be a "low-level" function to prepare a master equation problem (and a Schrodinger equation one, etc), and then there'll be a step method instead of calling the "high-level" interface function mesolve, but functionally it'll do largely the same, just with a lot less data copying than the current form has to do. In the new system, it's likely that the function mesolve itself will keep the exact same interface it has now, just internally most of its processing will be split into modular components, each of which will be accessible (with different names) to the user to compose themselves, if they want low-level access.
That sounds perfect! I might wait for QuTiP 5 to come out, or if these things are already in master, I'll see if I can maybe revisit DensityMatrixODEPropagator and maybe also add something for the Hilbert space case (whatever sesolve is doing internally). As an aside, I was actually surprised how much better DensityMatrixODEPropagator performs compared to looping over mesolve (In [29] vs In [21]): Since the DensityMatrixODEPropagator also re-initializes scipy.integrate.ode in every time steps, it would seem like the only difference between the two is the overhead of mesolve deciding that it has to handle the specific case of density matrix propagation. That might be something to keep an eye on in future QuTiP development: Ideally, calling mesolve would have negligible overhead compared to manually doing whatever mesolve does internally for a particular case.
We're unlikely to add yield to mesolve directly because that's a very breaking change to one of QuTiP's core functions (we can't return from a generator, or at least not ergonomically), but we are splitting up the mesolve monolith into a much more modular architecture, and making it more user-accessible. The other advantage of this is that the integrator component will just be one element of a composable system, so we'll not be tied to scipy integrators any more.
I would absolutely not expect you to modifying how mesolve works directly. In fact, I would strongly recommend leaving the mesolve interface unchanged. The internal refactoring is all I'm after here.
@jakelishman in #1571 (comment):
I also note that I'm not replying to the thread I thought I was - I thought I was in krotov! For my response to the discussion points:
Yeah, sorry the discussion got a little confused between what I was suggesting in qucontrol/krotov#93 for myself to try out (adding a yield to mesolve as a dirty hack) and the discussion here about how to address the underlying use case properly in QuTiP itself. So just to be clear: Do not add a yield to the existing mesolve function in QuTiP! I would strongly recommend keeping the existing interface for mesolve and just refactor what is going on in the backend to enable single-time-step propagation with as little overhead as possible.
That sounds like the exact right solution! ;-)
I think this architecture is approximately what Eric had in mind too, though I presumably haven't used the same names.
Yeah, I think we're actually all on the same page, irrespective of minor implementation/naming details: Have an object that keeps internal state of mesolve and allows to advance step-by-step. Personally, I like the naming of MeSolver that @Ericgig wrote out in #1571 (comment), but mesolve_prepare_ode/OdeState works too.
@Ericgig in #1571 (comment):
Most of scipy's solver are not "thread-safe", but we will be able to use other solvers in the new version.
If you can point me to any thread-safe solver, I'd love to try that out. As already discussed above, if I can replace scipy.integrate.ode in  Krotov's DensityMatrixODEPropagator with something that's reentrant so I don't have to re-initialize the integrator in every time step , that might be a significant performance boost already.
The new QuTiP solvers now support solver.step(self, t, args=args). which allows manually stepping the state until time t with the optional supplied args. I don't think this quite addresses the full feedback possibilities, but I am noting the progress here.
