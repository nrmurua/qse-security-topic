The discussion on #1544 shows that an API for accessing full functionality of the underlying HDF5 storage should be designed. This not only enables dataset compression but also other optimized / customizable storage (#1345).
Things to keep in mind:
Extend the OO approach in HasEnvironment and the state machine in worker_impl. Principle code:
Pros:
Cons:
The above concept is still very rough. In particular, store_dataset overrides can become very quickly very verbose and helpers matching common cases should be provided.
Comments (fully orthogonal ideas) most welcome!
how to read hdf5's global_attributes?thank you
