Dear quimb team,
I am interested to compute the magnetization of 1D and 2D models by implementing dmrg method.
How can I do that? I searched throughout the quimb website but I could not find any direct resource to obtain the local magnetization and total magnetization of a desired 1D or 2D model by using dmrg method.
thanks for your support.
Hi @HamidArianZad. MPSs do have the method magnetization:  https://quimb.readthedocs.io/en/latest/_autosummary/quimb.tensor.tensor_1d.html?highlight=magnetization#quimb.tensor.tensor_1d.MatrixProductState.magnetization.
Maybe this tutorial with usage demonstrated in the docs would be helpful too: https://quimb.readthedocs.io/en/latest/examples/ex_TEBD_evo.html?highlight=magnetization#Non-translationally-invariant-Hamiltonians.
For 2D, you would have to specify the local operators yourself and use compute_local_expectation: https://quimb.readthedocs.io/en/latest/_autosummary/quimb.tensor.tensor_2d.html?highlight=compute_local_expectation#quimb.tensor.tensor_2d.TensorNetwork2DVector.compute_local_expectation
Might these cover your use cases?
I tried following code to reproduce the Hamiltonian of a 2D square lattice of L = 4*5. Then I applied DMRG2 method to gain the ground-state energy and magnetization of the model.
But I get following error:
Traceback (most recent call last):
File "/home/hamid/PycharmProjects/Hamid Python Project/quimb Project/Mag_DMRG_2D.py", line 64, in 
dmrg = DMRG2(H, L)
File "/home/hamid/anaconda3/lib/python3.9/site-packages/quimb/tensor/tensor_dmrg.py", line 1080, in init
super().init(ham, bond_dims=bond_dims, cutoffs=cutoffs,
File "/home/hamid/anaconda3/lib/python3.9/site-packages/quimb/tensor/tensor_dmrg.py", line 541, in init
self.L = ham.L
File "/home/hamid/anaconda3/lib/python3.9/site-packages/scipy/sparse/_base.py", line 771, in getattr
raise AttributeError(attr + " not found")
AttributeError: L not found
Could you please guide me to resolve this problem?
Hi @HamidArianZad, the problem is that the DMRG algorithm requires its Hamiltonian in MPO form, see e.g. the docstring here. quimb does not yet have the functionality to generate MPO forms of 2D/arbitrary hamiltonians, but it will at  some point soon (or you could try constructing the MPO yourself).
For now you would have to use a native 2D / PEPS algorithm, which should scale better for non-'thin' systems too.
Hello,
Thank you very much!
I tried to run below tutorial:
But I get below warning:
energy_exact =  -0.5743254415745596
n=100, tau=0.1, energy~-0.544667: 100%|##########| 100/100 [00:01<00:00, 64.62it/s]
n=200, tau=0.01, energy~-0.544182: 100%|##########| 100/100 [00:01<00:00, 70.41it/s]
su.best:  {'energy': -0.5446668257748429, 'state': <PEPS(tensors=16, indices=40, Lx=4, Ly=4, max_bond=2)>, 'it': 100}
su.energies:  [-0.01394248455141442, -0.42462802975791175, -0.5438133939333119, -0.5445453694088561, -0.5445222409923282, -0.5446668257748429, -0.5444968907069688, -0.5443706273752631, -0.5442786430312206, -0.5442215405191778, -0.5441819975379001]
n=50, tau=0.02, energy~-0.544600: 100%|##########| 50/50 [00:08<00:00,  5.76it/s]
WARNING:jax._src.lib.xla_bridge:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
0%|          | 0/999 [00:00<?, ?it/s]
I tried several ways to remove this warning and I spent much time to optimize the results of the SU and FU methods with jax under gpu, but I failed.
I installed below dependencies for quimb and gpu usages:
My laptop has below gpu config: Nvidia GeForce RTX 3060 6GB GDDR6  & Integrated graphics card: Intel Iris Xe Graphics HD
Could you please also address this problem?
I'm afraid that seems to be jax installation issue unrelated to quimb, so you might have to find support elsewhere.
My only suggestion is that you appear to have at least 4 different cuda versions installed (11.2, 11.8, 11.3, 11.7), which are probably conflicting. I'd setup a fresh conda environment and install jax in that via the recommended pip install --upgrade "jax[cuda]" -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html.
