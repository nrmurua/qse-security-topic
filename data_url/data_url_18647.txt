TEST-MEASURE-SEMANTICS fails for me when running make test. This is testing on master and after a make clean clean-cache.
Fails consistently for me, so if this is only happening on my machine, I will get around to debugging it eventually.
Passing for me. Strange
Possibly my vintage computing technology, then.  As long as it's not bothering anyone else, I'll take my time.  I had a quick look and there was a comment in there from @ecpeterson with a bunch of math stuff I didn't understand that ended with a "Caveat programmer." Probably start there unless someone tells me otherwise.
Both arrays in the trace look like a MEASURE happened instead of a MEASURE-DISCARD. How up-to-date is the QVM that the tests are building against? These require it to be pretty close to GitHub master.
Bingo! That's a numberwang! Thank you for saving me from hours of looking for a bug that does not exist :).
Out-of-date QVM was the first thing I suspected/checked, but I forgot that my local repo now points at my fork at appleby/qvm, not rigetti/qvm, so when git pull told me "everything up to date", I foolishly believed it.
This feels like a learnable moment for me, so out of curiosity: how did you divine by staring at those amplitudes that a MEASURE was preformed, rather than MEASURE-DISCARD?
Bingo! That's a numberwang! Thank you for saving me from hours of looking for a bug that does not exist :).
Out-of-date QVM was the first thing I suspected/checked, but I forgot that my local repo now points at my fork at appleby/qvm, not rigetti/qvm, so when git pull told me "everything up to date", I foolishly believed it.
This feels like a learnable moment for me, so out of curiosity: how did you divine by staring at those amplitudes that a MEASURE was preformed, rather than MEASURE-DISCARD?
Because he's gosh darn wacky. During one conversation when we were debugging something, he made a similar point, something like "Well if you look here these two numbers look like +/- pi/7 and over here these two columns are clearly not orthogonal and ... and ...". Hopefully it's a skill we can all develop after looking at quilc stackframes for long enough.
By the way, I think the reason is that a MEASURE will collapse the quantum state -- this is evidenced by the above vectors having one and only one 1 and everything else 0 (ignoring small differences). MEASURE-DISCARD will not do the above. There is more subtlty here I think (namely that we're working with a density matrix) but that's the general idea.
By the way, I think the reason is that a MEASURE will collapse the quantum state -- this is evidenced by the above vectors having one and only one 1 and everything else 0 (ignoring small differences). MEASURE-DISCARD will not do the above. There is more subtlty here I think (namely that we're working with a density matrix) but that's the general idea.
That (surprisingly) makes sense. Thank you for ignoring the finer details and putting it in layman's terms for me :).
Now that my quantum lesson for the day is complete, I'm closing this and filing it under PEBKAC.
Mark is spot on in his second paragraph. What follows is an explanation of why:
One of the features of an ordinary "wavefunction" (or "pure state") in quantum computing, as represented by the QVM as a vector of complex values, is superposition. A wavefunction that looks like (1/sqrt(2), 1/2, 1/2, 0) is understood as being composed of pieces: there's 1/sqrt(2) that belongs to |00>, 1/2 that belongs to |01>, and 1/2 that belongs to |10>. The physical meaning of these numbers is that if you query the computer—viz., if you MEASURE it and examine the resulting bits of output—then you'll see the bitstrings 00, 01, and 10 with respective probabilities |1/sqrt(2)|^2 = 1/2, |1/2|^2 = 1/4, and |1/2|^2 = 1/4. Additionally, MEASURE has the relatively unique property of being an irreversible operation: depending on which bitstring you see after a measurement, the wavefunction itself gets replaced by (1, 0, 0, 0), (0, 1, 0, 0), or (0, 0, 1, 0).
There's an alternative formalism for tracking the state of a quantum computer, called the "density matrix", which has two main benefits:
The precise mathematical mechanism by which density matrices accomplish this isn't so important. It's more complicated than literally taking formal sums of pure-state things, but I'd advise you to not worry about it until later.
As for what this has to do with us, MEASURE itself has properties relevant to the density matrix formalism: MEASURE reveals information about a quantum system, previously considered to be isolated, to an outside observer, and so can be studied from the same perspective of 'information loss' as is used with noise. It also feels like it splits a single pure-state QVM apart into two pieces (or, if you like, two worlds): one where the QVM replied with 0 (weighted by whatever probability) and one where the QVM replied with 1 (weighted with the complementary probability). The main trouble with making all the pieces in this conversation thus far line up is that, because the QVM tells you which bit it measured you, can you tell which QVM in this pair ensemble that you're speaking to. If, however, you were to plug your ears and discard the bitstring that the QVM tried to communicate back to you, then you'd still be unable to tell the difference between which of the two QVMs you're speaking with (since, because you closed your ears, no one managed to accomplish any speaking), and so you really haven't exited the world of density matrices.
So: the recent QVM PR adds support for MEASURE-DISCARD applications (written MEASURE q in Quil, without a classical address) along these lines, and this quilc PR exploits this new simulation support to check the behavior of the compiler on MEASURE instructions by doing an analogue of what it does elsewhere in the tests to check correctness: it calculates a matrix that encodes the behavior (here: several density matrices; elsewhere: a unitary matrix) and checks for equality.
What this has to do with your bug: if this simulation mode were operating well, then the test case is designed to produce one of these ensemble "superpositions", and so you'd expect to see a weighted average of two things. If it were using the measure-and-collapse style of simulation, then you'd see a density matrix with population concentrated in one spot—and that's what you reported.
[1] - This set-up requires that I only MEASURE (and reply) at the very end of the program. If your program is just to MEASURE multiple times in a row, then each run of the pure-state version will reply with the same bitstring as it's repeatedly MEASUREd, but the coin-flipping one might not.
Wow. Thanks for taking the time to write that detailed explanation, and for not leaving out (some of) the finer details :). You managed to keep the conversation at the right abstraction level where I was mostly able to follow along.
One thing I'm still a little confused about. In your point (2), above, you say that density matrices are "suitable for studying combinations of states in a sense somewhat different from ordinary superposition". I think I can see how this would be useful for simulating noise, but are there other places density matrices pop-up?
Also, do I understand correctly that when you perform a MEASURE on one of the two ensemble "superpositions", it will cause both to collapse? Or am I just seeing the collapsed state of the one that "won" the coin toss? If the former, then I'm going to go have a drink to calm my nerves, then circle back! Although I admit I don't really understand how/why wavefunction collapse happens in the "pure state" model, and I just sort of accept it at face value as one of those spooky things that are true about quantum mechanical systems.
The precise mathematical mechanism by which density matrices accomplish this isn't so important. It's more complicated than literally taking formal sums of pure-state things, but I'd advise you to not worry about it until later.
This is advice that I am very happy to accept!
I'm going to run two QVMs simultaneously, and whatever I do to one I'll do to the other, but I'm going to start them from different places, and when I'm finally asked to MEASURE, I'll reply with one of the two measurements that I get by flipping an additional coin and choosing which of the two secret QVM's replies to return based on that
Just realizing that I may have misinterpreted the protocol for the ensemble QVMs.  Perhaps what you mean is that MEASUREs are still performed on both, and the coin flip only determines which result I see, not which one gets measured...
That's right: the "ensemble supervisor" performs all operations on both (gates, measurements, everything), and when the user requests a response from the supervisor, the supervisor selects at random from the responses of his subordinates.
I don't myself find this goofy alternative form of superposition to be particularly intuitive / something that arises naturally, but I do find it very practical. There are cool theoretical results from the first perspective:
These results are conceptually attractive, but they're computationally obnoxious: without any further input, you'd expect simulating these scenarios to require simulating the secret pure state, which can be expensive and which is breaking the abstraction barrier where you're not supposed to need access to my private data.
Meanwhile, the density matrix formalism makes simulation of these scenarios quite attractive: the operation of 'discarding' parts of a quantum system is given by the "partial trace", which is extremely mathematically simple, and the simulation of the resulting ensemble of QVMs can be done by one process in a way that guarantees that no knowledge (much less: total knowledge) is required of any parent quantum system.
At any rate, this partitioning of natural computational resources happens often enough that it's a good perspective to adopt: you could be literally be borrowing someone's qubits; you can think of 'noise' as being a background daemon whose qubits you're borrowing while it continues to run some process on the larger collection; you could swap qubits with someone as a means of communication; you might want to understand when it's safe to release resources, so that you can 'drop' a qubit from consideration without leaving it in some kind of dirty state; ... . Density matrices (or, at least, "open quantum systems") are lurking around the corner of each of these ideas.
This has certainly given me something to chew on!  The 3-qubit concrete example was very welcome, and (I think) helped clarify some confusion I had about in what sense these ensembles can be considered a  "superposition".
I am still not sure about this "partial trace" business, but I suspect that is heading in the direction of your earlier warning about ignoring the mathematical particulars of density matrices, which I will heed :).
