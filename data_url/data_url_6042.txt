I am running simulations on a hpc cluster and about half the time the memory usage spikes and the job is killed by the scheduler. The simulations I'm doing are very small (4 qubits), however the number of circuits submitted to execute  is large (~1000). I am using a qasm_simulator backend and handling circuit execution with aqua's QuantumInstance class. Additionally, I have set the backend option max_memory_mb to be within the memory requested from the scheduler. From looking through the code I have not been able to find any other options that set memory limits. Normal executions of the job (ones that complete) have a max memory usage of about 3GB, and the ones that experience a memory spike and are killed go up to about ~20GB (in this case I had requested 4GB RAM from the scheduler). Requesting large amounts of memory from the scheduler causes my jobs to queue for a long time, so although a simple fix would be to request more memory it is not ideal.
I have tried to reproduce the issue, but on many repeated runs (on a machine with large amounts of memory available) I have not seen instances that have high memory usage higher than ~2-3GB.
I would like to be able to set the amount of memory used by the QASM simulator in my code.
@chris-n-self Can you give an example of the Aqua code that was causing memory leak to help debug?
Hey @chris-n-self thanks for reporting this. I'd like to take a look at this... could you provide an example so we can reproduce this error? Thanks!
I think this should have been fixed in #763
Sorry for not responding sooner to the previous messages! I have updated to Aer 0.5.2 (which I think includes fix #763) but I still get this issue. Here is a small example that reliably gives me the error:
I ran this 100 times on the cluster I am using and 71 of the jobs went over the 1GB memory allowance. Looking through the job reports it seems that most of them were using 3GB when they were killed by the scheduler.
I can confirm this. It looks like execute(experiment, ...) for a long list of experiment parallelizes over them, regardless of any settings of the simulator (in particular it seems to ignore max_parallel_experiments=1).
This is pretty much a showstopper tbh, since if you run anything on a large shared node where you only have a fraction of CPUs and memory, but qiskit spawns like 20 times as many threads as you have cores reserved, you will run out of memory.
Closing this issue as stale. Feel free to reopen after 0.9 release if there are still issues with this.
Note that execute is deprecated and you should separately transpile your circuits and then run them using backend.run. If transpile is causing the issue this would indicate an issue with terra transpiler or retworkx library. If the run command is causing the additional threads then we this issue should be revisited here.
