This minimal code example raises the following:
ValueError: UnitaryChannel probability sum should be between 0 and 1 but is 1.0000000000000002.
Thanks for finding this, I can reproduce it. @scarrazza I think we should relax this error to have some tolerance, eg. instead of 0 <= sum(p) < 1 check something like -tol <= sum(p) < 1 + tol where possibly tol is a backend attribute and depends on the active precision.
By the way this is one of the examples where #561 would make a difference performance if you run for more qubits, as in principle we could apply this channel using the Pauli gates, instead of doing the Kronecker products.
Also, here you can avoid the SymbolicHamiltonian if you do the Kronecker products manually:
This will return the same as paulis = [pauli.dense.matrix for pauli in paulis] in your code.
Also, here you can avoid the SymbolicHamiltonian if you do the Kronecker products manually:
This will return the same as paulis = [pauli.dense.matrix for pauli in paulis] in your code.
I've done something similar to this before, but the problem is that it scales really poorly since there are 4^nqubits observables and nqubits - 1 kron products for each of them.
@stavros11 yes, we can probably use the approach implemented in np.isclose and keep a relative/absolute tolerance precision/backend dependent.
