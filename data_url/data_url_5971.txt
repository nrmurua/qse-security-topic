Many large simulation jobs have embarrassing parallelism (over shots and/or circuit instances) and could pick up a big speedup on an HPC cluster. We need some way to:
It seems to me that most self-contained way to implement this is as a new aer provider.
For point 2, I think that dask-distributed is potentially a great option, since it contains dask-jobqueue who wraps up all the big cluster queueing systems: LSF, PBS, Slurm, HTCondor, Moab, SGE, OAR giving jupyter widgets to monitor and with some well-thought-out example configurations and workflows. In addition there are components that provide the same interface via mpirun, an informal cluster of ssh-able machines, DRMAA-compliant resource managers, kubernetes-based cloud clusters, YARN/Hadoop cloud providers etc. You get a nice API that extends concurrent.futures. It can implement the same API locally (ie without a cluster) for testing, CI, etc. They've put some effort into serialize/deserialize that goes beyond pickle. It can do some forms of load scaling and such. And it's part of the dask project which is large, modern and very active. I guess we point users to the dask documentation for them to set up a dask.Cluster() instance which they can pass to our new provider.
Dask looks like a really nice option for doing this
Has there been any progress on this with regards to having such a capability in Aer?
@woodsp-ibm see #1084 which is intended for next release
Dask executor support added in 0.9.0
