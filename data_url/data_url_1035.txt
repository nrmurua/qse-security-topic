Is your feature request related to a use case or problem? Please describe.
When using run_batch() in Engine, the method will fail if the program size is greater than 10MB. It would be useful to have a method which could accept an oversized batch, and then automatically break it up into appropriately sized chunks. This is related to one of the concerns in #3960.
This would significantly improve usability when trying to create automated protocols that run circuits, as the batch sizes are sometime variable.
Describe the solution you'd like
I've written up the following attempt at a solution, however it seems to not be measuring the correct memory size, as batches which it believes to be too large(16-24MB) will still run as a single batch on the hardware. I assume the issue is in how I'm calculating the size of the batch (using sys.getsizeof(cg.FSIM_GATESET.serialize(circuit).SerializeToString())).
[optional] Describe alternatives/workarounds you've considered
I believe most of us have been just adjusting batch sizes by hand until they run, which is fine, but ideally would not be an issue.
What is the urgency from your perspective for this issue? Is it blocking important work?
P3 - I'm not really blocked by it, it is an idea I'd like to discuss / suggestion based on principle
This has come up often enough (with people rolling their own methods to do so) that it's worth doing. It may be preferable for this behavior to be available as a (non-default) option in run_batch to reduce the number of methods users need to learn.
#3235 is tangentially related as well - using CircuitOperations will reduce the serialized size of the circuit.
