If I recall correctly, we briefly discussed this in last week's meeting and decided to postpone it for now, but I wanted to keep track of it anyway.
Currently there's no reasonable way to run tests for only a specific implementation. As we start to collect dozens of implementations, it will likely become infeasible to run all tests all the time - already it's starting to take a few minutes, and that's with only one SPHINCS+ parameter set..
Can we come up with a way to only run tests for a specific scheme? By extension: can we convince CI to only run tests for schemes that contain modifications?
EDIT: as a quick hack when locally running tests, I realized that test_valgrind.py is of course the main culprit. During development it may make sense to temporarily delete that file so that nosetests doesn't pick it up.
We could have each test_x.py file to check for the presence of an environment variable SKIP_x.
We might also want to have some of the tests only run on some of the CI builds.  For example, there's no reason to run most of the source code checks (char, duplicate_consistency, format, license, linter, makefile_dependencies, metadata, metadata_sizes, no_symlinks, maybe more) on all platforms.
As for having the CI run tests only for schemes that were modified: the logic is more complex here.  I think it's something like:
if (running on a CI environment (*)) and (this branch's diff compared to master does not contain any changes outside an individual implementation's directory (**)) then (skip tests for all other implementations (***)).
We could have each test_x.py file to check for the presence of an environment variable SKIP_x.
That suggests "blacklisting" the tests we don't want to run? I'd rather have arguments or maybe environment variables that pick the ones we do want to run. The common pattern I'm expecting is that a developer is working on one new scheme and would want to test just that scheme or maybe just a new implementation of that scheme...
So you want to control which schemes/implementations are tested, not which tests are run?
Should probably also check for changes in the test directory, which suggest re-running CI for all schemes?
Yes, that was my assumed "else" branch: else (there exists a change outside of a implementation directory) run all tests.
PR #102 is a first attempt at using environment variables to filter tests.  In particular, it takes into account six environment variables:
All can be comma-separated lists, and can be set simultaneously.  Semantics:
As for the discussion above about only running tests on implementations that have changed, only when there are no changes outside implementation directories.  I am a bit nervous about doing that by default, as someone might not expect that behaviour and be wondering why the full test suite isn't running.  What about instead using an environment variable like PQCLEAN_ONLY_DIFF to trigger that behaviour?
I've added PR #103.  If environment variable PQCLEAN_ONLY_DIFF is present, then it will, when not on master branch, run tests only for schemes/implementations that have changes, as long there are no non-scheme/implementation changes.
I haven't modified any of the CI configurations to set PQCLEAN_ONLY_DIFF, unclear to me if we want to do so.
