We've been back-and-forth between QUnit -> QEngineCPU and QUnit -> QEngineOCL being faster on the unit test suite. In the earliest stages of development, the former was faster. The overall OpenCL host code was brought to a reasonably optimal point, and QUnit -> QEngineOCL pulled ahead, for a long time. Now, QUnit -> QEngineCPU is winning speed tests again, taking about 3.5 seconds real time on my machine, versus 8.6 seconds for QEngineOCL. (This includes a unit test which rebuilds the OCL kernels, in excess of anything the CPU variant does, but the test-by-test lag is easily noticeable to the human eye).
QEngineOCL without a QUnit layer, for any significant number of qubits, beats QEngineCPU on basically all benchmarks. However, under the QUnit layer, exactly these small qubit count cases are hoped for, and they leave QEngineOCL "shards" with insufficient work items to fill the width of the GPU.
I've thought about the practical implementation for some time, and I think we can definitely benefit from a hybrid engine type, with dual inheritance and a CPU/OCL switching threshold. Other simulators also use this approach, with technologies like OpenMP.
I will address this with highest priority, after the refactor planned by #194.
Noted.
Quick additional note: I think this is best implemented at the QEngine layer, not over its head in the QUnit layer.
With much development work since last year, even low qubit count OpenCL benchmarks tend to perform better than pure C++11 implementation benchmarks. Hence, this concept probably currently offers no benefit, but I'm not deleting the branches, yet.
