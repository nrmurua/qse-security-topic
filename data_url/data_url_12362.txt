Hi,
I have a set of training data, and for each of those examples I want to "learn embeddings on the fly", such is done in some NLP models for example. I.e., have a bank of parameters for training example 1, 2, 3, etc., and when training example 1 comes up I want to use its parameters in the model. I then have a classifier circuit which will have the same trainable parameters for all examples:
Encoding (different for each example) --> classifier (same for all examples) ( --> readout)
Apologies for what might be a basic question (I'm coming from quantum rather than ML background), but I'm struggling to implement this. I've come across nn.embedding_lookup and resolve_parameters which look like they could do what I want -- select the appropriate encoding params for my example, and put then into the encoding circuit  but I can't work out how to integrate this into a model. There's also the keras.layers.Embedding which does this sort of thing automatically classically, but it would be quite a job to make a quantum version of that with circuits rather than vectors... Any pointers appreciated!
I have limited NLP experience, but I seem to have 2 possible understandings (both of which are conditioned on some input)
These both seem very similar in spirit to a lot of the data reuploading structures. Your best bet would probably be to create a custom layer (although it may be possible to hack it together with expectation like in #672 (comment)). If you outline which interpretation is correct (or if they are both wrong, provide more detail), I can probably make a minimal example that might help you.
Hi, thanks very much for the reply. I'll try and be more clear.
I have an encoding circuit with a fixed structure, but where the parameters depend on the (classical) input -- in this case words in a sentence. I'll have a bank of parameters for the different words, so if the first word is "cat", then we look up the parameters for "cat" and put them into the first slot in the encoding circuit. If the second word is "sat" then we look up those parameters to go in slot 2, etc. The aim is to train these parameters as part of the task, in the same way that word embeddings are sometimes trained classically as part of a task.
The encoding circuit then feeds into a PQC which has the same structure and parameters for all the inputs, and is trained to correctly classify the input.
I hope that's clearer? I will have another look through the data reuploading examples, I think I understood the examples on the tutorials page but it's specifically having a bank of input parameters which are then selected from according to the input that I'm having trouble implementing.
Thanks again!
I think I see what you are getting at. It seems to bear certain similarities to reuploading, but it's definitely different. I think I have a minimal working demo below. I don't really do stuff with NLP, so I'm not sure what the pipeline is, but it should give an example of what you are trying to do from which you can build upon. There are probably other ways to implement this, but I went with a custom layer. If you understand the re-uploading implementations, this is pretty similar, I basically just combined the used the reuploading idea but with an embedding params variable that uses the tf.nn.embedding_lookup. So it has some embedding parameters that vary depending on the input (for constant structure embedding circuits) followed by a constant structure PQC with universal params.
It certainly seems to be learning the correct things for this simple example.

That's brilliant, thanks so much for your help! That's just what I was having trouble with but it all seems quite straightforward when it's done right. One quick question: what's the purpose of return (output + 1)/2 at the end of call()?
That's just to match the output range to the label range. The labels are [0, 1] but the Z expectation is -1 to 1 so I just shifted it to 0 to 1. I don't know if it's necessary, just something I usually do.
Any updates on this or should it be closed?
