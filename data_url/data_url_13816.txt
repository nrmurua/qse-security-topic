For performance purposes would it make sense to replace the functionality from

with something like
tensor.reshape([2 ** outputs, 2 ** inputs])?
I ran some preliminary tests and the outputs are equal, but reshape is around 10^5 times faster.
Oh wow, I hadn't realised that that method was so slow. Using reshape there might be some issues in where the elements are positioned though. When I wrote this I had to be very careful that the tensor of a CNOT for instance actually resulted in the matrix we commonly associate to the CNOT.
What are you using this method for that speed is important? I mostly implemented it to for visualisation purposes, so only small matrices.
I tested the reshape with random circuits that included CNOTs too. I will look more into making sure I understand the code correctly. It seems however that the permutations for achieving correct matrices are in tensorfy.
It is more of a learning process now to find out if and how to include a tensor (contraction) library. At this stage I am just reading code am curious how difficult it is to use sparse matrices.
@paultirleson has been working on integrating pyzx with the tensor network library quimb. Still somewhat of a WIP, but you might want to check out the new to_quimb_tensor method for ZX graphs.
