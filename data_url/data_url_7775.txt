It would be nice for e.g. variational quantum circuits, to be able to optimize the parameters that generate a tensor (like a rotation gate) rather than the tensor itself. Something like:
There is now preliminary support for this, see the example quantum circuit training example here.
TODO:
Hi @jcmgray, I'm having a bit of trouble with this. I'm trying to follow the example you linked above in order to:
However, I seem to be running into some compatibility issues between jax and opt_einsum when calling TensorNetwork.contract(). I attach a small example in which applying a single gate to the computational state causes the optimizer to crash when it makes its initial norm_fn call (before it ever even tries to call loss_fn).
The stacktrace shows some weirdness when opt_einsum tries to call the jax version of einsum (also happend when it tries to call tensordot). Relevant portion:
I believe this is somehow related to the PTensor class because if I don't add any gates, remove the constant_tags kwarg, and make a nontrivial loss function, then everything runs as expected.
I'm using the most recent versions of quimb and opt_einsum.
Hmm, will take a look shortly!
OK so the fix for that particular problem is the following:
I.e. to help autoray with the backend by specifying like in each of the functions above where the first argument is not an array (for the array call its a list e.g.). It was creating a numpy array of jax objects with dtype='O' thus the dtype error.
There's other errors after that, but they arise from the loss_fn being non-scalar currently.
Let me know if that helps!
EDIT: this is a good reminder to emphasize in the docs that these parametrized functions need to be able to trace through with the backend of params given.
Whoops, clearly I didn't follow closely enough. Thank you!
No worries! Identifying these problem points is always useful.
