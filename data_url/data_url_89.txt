Right now, only the code examples in .cpp and .py files are tested as part of CI as defined here: https://github.com/NVIDIA/cuda-quantum/blob/main/docs/CMakeLists.txt. We have since added Jupyter notebooks that are used in the documentation but not automatically validated. It would be good to set up CI for these notebooks. A good start is CI that just checks that the notebooks run without issue. A fancier check would be to check that the cell output is correct.
I'm interested in working on this.
@abhiram6121 Wow, that was quick. :)
That would be awesome! Have you already set up something similar and do you feel comfortable jumping into it with the minimal description I added, or do you need more info? If you feel you are good to go, could you post a quick outline of what you had in mind?
@abhiram6121 Wow, that was quick. :) That would be awesome! Have you already set up something similar and do you feel comfortable jumping into it with the minimal description I added, or do you need more info? If you feel you are good to go, could you post a quick outline of what you had in mind?
Sorry, I have jumped in because of the¬†good first issue¬†tag and I didn't have any idea how to get started.
@back-up-git @abhiram6121 (I assume that's the same person)
No problem at all. There are a couple of different options for how to approach this.
First things first - the goal:
I would like to set up the validation in a way that doesn't rely on any unit tests or similar being included in the checked in notebook itself. It is nice if we can write the notebook in a way that is nicest for the documentation without worrying about how they are validated.
Given that goal, I think the most straightforward way to set up validate is to simply run the notebook and compare the cell outputs to a checked in reference.
More concretely: The notebooks that are on this repository already contain both the cells as well as their output. The nbconvert tool can (among other things) be used to execute a notebook and save it (including all cell outputs) in a new notebook.
If you run the command
(replacing notebook_name with the name of the notebook to validate), it will produce a new notebook called notebook_name.nbconvert.ipynb. You could write a python script that
Implementing 1) is a good start, and we can then add that python script to the CI. 2) is a bit of additional work since not all notebooks are deterministic, meaning their output may vary, and we likely need to adjust the notebooks a bit to validate the outputs. Do you want to give 1) a go and post here when you have a python script that runs a notebook and checks that it executes successfully?
@back-up-git @abhiram6121 (I assume that's the same person) No problem at all. There are a couple of different options for how to approach this. First things first - the goal: I would like to set up the validation in a way that doesn't rely on any unit tests or similar being included in the checked in notebook itself. It is nice if we can write the notebook in a way that is nicest for the documentation without worrying about how they are validated. Given that goal, I think the most straightforward way to set up validate is to simply run the notebook and compare the cell outputs to a checked in reference. More concretely: The notebooks that are on this repository already contain both the cells as well as their output. The nbconvert tool can (among other things) be used to execute a notebook and save it (including all cell outputs) in a new notebook. If you run the command
(replacing notebook_name with the name of the notebook to validate), it will produce a new notebook called notebook_name.nbconvert.ipynb. You could write a python script that
Implementing 1) is a good start, and we can then add that python script to the CI. 2) is a bit of additional work since not all notebooks are deterministic, meaning their output may vary, and we likely need to adjust the notebooks a bit to validate the outputs. Do you want to give 1) a go and post here when you have a python script that runs a notebook and checks that it executes successfully?
Hi, I tried running jupyter nbconvert --to notebook --execute notebook_name.ipynb among files with .ipynb extension in the docs/sphinx/examples/python/tutorials directory. But getting below errors while executing some files.
Am I missing something?
Hi @abhiram6121 - I think you've uncovered the first underlying issue that this GitHub issue is trying to prevent. That is - I think the code snippet for this isn't entirely correct. I think n_qubits needs to be changed to qubit_count to match the ghz_state function definition.
You may uncover more issues like this as you're working through it. Don't hesitate to ask questions if you're unsure.
Hi @abhiram6121 - I think you've uncovered the first underlying issue that this GitHub issue is trying to prevent. That is - I think the code snippet for this isn't entirely correct. I think n_qubits needs to be changed to qubit_count to match the ghz_state function definition.
You may uncover more issues like this as you're working through it. Don't hesitate to ask questions if you're unsure.
It worked, Thanks üëç
@back-up-git @abhiram6121 (I assume that's the same person) No problem at all. There are a couple of different options for how to approach this. First things first - the goal: I would like to set up the validation in a way that doesn't rely on any unit tests or similar being included in the checked in notebook itself. It is nice if we can write the notebook in a way that is nicest for the documentation without worrying about how they are validated. Given that goal, I think the most straightforward way to set up validate is to simply run the notebook and compare the cell outputs to a checked in reference. More concretely: The notebooks that are on this repository already contain both the cells as well as their output. The nbconvert tool can (among other things) be used to execute a notebook and save it (including all cell outputs) in a new notebook. If you run the command
(replacing notebook_name with the name of the notebook to validate), it will produce a new notebook called notebook_name.nbconvert.ipynb. You could write a python script that
Implementing 1) is a good start, and we can then add that python script to the CI. 2) is a bit of additional work since not all notebooks are deterministic, meaning their output may vary, and we likely need to adjust the notebooks a bit to validate the outputs. Do you want to give 1) a go and post here when you have a python script that runs a notebook and checks that it executes successfully?
Hi @bettinaheim, Here is the python script. Can you please have a look into this?
@abhiram6121
Do you want to give it a go adding this to the github pipeline?
Concretely, I'd suggest the following:
Some of the notebooks require backends that may not be available on all platforms/runners. The validate_container.sh script has a minimal logic that first checks what backends are available. Hence, for the forth bullet, it might be easiest to add the logic to invoke your script to the validate_container.sh script. The changes I would do for the forth bullet are then:
Does that give you some ideas for a next step? Let me know if you have any questions.
@bettinaheim Sure, I will give it a try.
