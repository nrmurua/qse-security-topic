I am trying to create an adversarial quantum neural networks containing two hybrid quantum classical NN model. In the first model, a classical NN is going to find the parameters for a parameterized quantum circuit. However, the output of this QCNN should not be measured, since this output is going to be the input of the other QCNN’s PQC layer. So I need a controlled PQC layer that outputs circuits, without measurement, instead of expectation values.
To make it more clear, assume that ‘Hybrid Machine Learning for Quantum Control’ model mentioned in https://github.com/tensorflow/quantum/blob/research/control/control.ipynb, without getting measured, is going to be fed to the model mentioned in https://github.com/tensorflow/quantum/blob/master/docs/tutorials/qcnn.ipynb as an input of its PQC layer.
Is there any way to build such models in TensorFlow quantum?
If not,  is it possible to define another version of the ControlledPQC layer that outputs tensor of circuits, like AddCircuit layer, not expectations and does not need measurement operators?
( the same as classical adversarial NNs, loss functions of both QCNNs are functions of the output of the second QCNN which is expectation value; therefore, if the first QCNN does not output classical information, it doesn't make any problem in defining the loss functions, just in case.)
Yes this seems like it should be possible. If you need a controlledPQC layer that "outputs your circuit" without measuring it, but is still able to pass gradients through it by measuring you can do something like this:
Does that clear things up ?
Thank you so much, yes, it really helped.
Actually, the classical parameters need to be passed through the outputs, that need to be of type circuits, to the second QCNN, and then after some changes that this second QCNN applied, qubits are going to be measured for the loss function. What you said brought about an idea to me that for training each of these QCNNs, I have to design two different connected QCNN models, each model contains two connected QCNNs. By doing so, during the training of the second QCNN, which doesn't use the parameters of the first model in the backpropagation,  I can provide its input by building circuits from the extracted classical parameters from the first QCNN, as you mentioned.
