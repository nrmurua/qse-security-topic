Currently, we have the following nomenclature:
A compiler is a function that maps an instruction to a list of instructions, presumably taking it a step closer to "this is now runnable".
A translator is a compiler that's built out of define-translator, used to translate particular gates into a sequence of other gates.
A rewriting rule is a data structure that slurps up some pre-defined number of instructions, and barfs out presumably a shorter/more efficient sequence of instructions, by way of the compressor. A rewriting rule is not a compiler!
Rewriting rules are nice because they contain documentation and a bit of metadata (the arity of the rule), but compilers are a lot more opaque.
I suggest we begin to think about how to give more information about compilers that can be uniformly treated. One pattern that's maybe worth lifting into the actual compiler data structure is the architecture/chip specification requirements for the compiler to operate. Right now, we are selective at chip-spec-building time whether or not to install compilers based off these data. This makes that code for installation somewhat piquant. Instead, one could imagine just installing all compilers, but rejecting at run-time when the compiler is invoked if it doesn't match the chip spec.
This might seem sort of dumb, but it would allow the compiler passes to be a lot more uniform and extensible, and if the metadata is tagged onto the compiler (say with the MOP's funcallable-standard-class metaclass), then we could actually "compile" the compilers, removing redundant ones that will always fail. (There is some complexity in doing this of course; we would need to know the chip-spec and all that stuff later on.)
Anyway, I would like to reserve this issue for discussing how compilers could be improved, especially as we move in the direction of user-definable compilers.
(See also #97.)
Closed by #210.
