529a22b6 made some changes to how we reorder bits in stochastic swap and basic swap. These change slow down these passes about 2x slower for basic swap and 10-30% for stochastic swap.
You can also see the impact of stochastic swap for transpiles with the preset pass managers (because of stochastic swap) here: https://qiskit.github.io/qiskit/#transpiler_levels.TranspilerLevelBenchmarks.time_quantum_volume_transpile_50_x_20?machine=qiskit-benchmarking&os=Ubuntu%2018.04&ram=16%20GB&p-transpiler%20optimization%20level=1&commits=529a22b6
Some more data points.  I apologize that some of the columns are missing as I have not been keeping full statistics on the variants until recently.
I have been watching transpiler performance for a while mostly to insure the QiskitC effort stays on track.  Attached is a spreadsheet with data showing the performance regression in the Python code.  The first three tables show performance with BasicSwap with large circuits at three time-points.  Remember the ripple-adder uses 2N+2 qubits and N+1 Cbits so actual circuit width is 3N+3 total bits.
The next three tables show the same adder using StochasticSwap.
These statistics are for circuit generation + a single execution of the BasicSwap and Stochastic
transpilers, called directly and bypassing the pass manager.  Times are in seconds.
The Terra numbers for both NetworkX (done for reference) and RetworkX clearly show the
performance regression.  The QiskitC numbers do not and I assume that is because of how
I handle the gate library.  I don't know if what I did is easly back-ported to Python but
I can provide details if people are interested.
TranspilerPerformance.xlsx
