@qdev-dk/qcodes
I would like to hear your opinion on the following.
note II:
in python, creating processes from the main notebook / spyder notebook, which is what happens when using the multiprocessing module) has some subtle side effects:
For socket based communication, isn't it safest to open and close the socket after each communication, instead of leaving it open indefinitely? This solves the issue with the fridge software. Do any instruments really require the socket left open?
@giulioungaretti Maybe like in the case of the data storage, instead of posing a solution we could attack this problem from the "need" perspective and try to define an "@akhmerov style" user case scenario, and then figure out what the best solution would be?
Let's say in my experiment I have a multidimensional loop. I step a fictional parameter Apples while sweeping another parameter Bees. I then want to read the values of 2 different parameters, Calamari and Drones. In a basic framework this would look something like this:
Drones could e.g. be talking to a socket while Calamari is talking to a GPIB interface. Let's say Calamari takes 200 ms to acquire, and Drones takes 100 ms. The inner loop would then take 300 ms per iteration if this is done sequentially, as in the example. However, I want the Calamari call to be the only bottleneck such that the inner loop would take 200 ms per iteration.
In addition to this, I want to be able to run some kind of Monitor that periodically polls Calamari whenever there is no measurement running.
@majacassidy for now the default behavior is the opposite, @alexcjohnson  maybe have something to say on why, but I guess overhead may be an issue, because you go from one operation to 3 (open, send, close), depending on the latency of the network the first op could actually  take a non-negligible amount of time, especially if the data transfer is minimal.
The issue is not normal behavior but rather what happens when things go amok.
@guenp not sure I can follow your example. What's apples and bees ?
It looks like your comment is more of an implementation issue, i.e. blocking vs no blocking, which can be achieved with both thread processed and neither (ref: asyncio)  :D
@giulioungaretti yes that's exactly my point :)
regarding the üçé üêù , in my example they represent fictional parameters (values you can get or set).
edit: can the Monitor also be achieved with thread processes or asyncio? since it has to be running continuously in the background.
lol @guenp  but then I can't relate at all to the 3 questions, or any of the points in note II.
Or maybe it's just  sunday and I did not have enough üç∑ yet!
@giulioungaretti lol that was the point, I wasn't trying to come up with a solution but to phrase the problem first. let me try to answer them directly if that's more clear. üòÑ üç∑
Why should an instrument be its own server ?
No, it shouldn't have to be if there's a better, more light-weight solution.
Why should two or more instruments sit in one server?
If they share the same interface and it is blocking?
Does an instrument need to live in its own process ?
No, it shouldn't need to if there's a better, more light-weight solution.
note II:
No opinion on this, it seems more like a statement rather than a question, but good points.
I imagine the only things that matter for answering each of the three questions are resilience to failure, performance, and possibility of upscaling. Probably UI or ease of further development (power user interface) is also a bit important, but perhaps much less so.
How much does qcodes need to achieve in each of those? Does resilience to failure include using user-written buggy drivers along with the ones from qcodes? How many instruments can there be reasonably? 1e2 or 1e4?
As a reasonable goal I would imagine that it should be possible to run instrument software in a way resilient to failure in other instrument drivers.
This would suggest that at least sometimes instruments should be in more than one process. However it isn't always necessary.
Further I know of some situations that are within the scope of qcodes when more than one computer is involved in measurement. This suggests that there are situations when more than one server process should be involved in measurement.
I cannot think of good reasons to separate instruments into several servers beyond having several physical servers. Separating instruments into different processes probably makes it easier to increase failure tolerance.
I think qcodes needs to support both modes for instruments, as each has it's advantages and disadvantages. I'll list the advantages:
One process
Multiple processes
@giulioungaretti You are right that a process and a server are different things, but I think the process is the main thing to think about. Or do you see much arguments in favor of a single process - multi server approach?
@majacassidy Opening and closing sockets for each get or set to an instrument is not possible for doing fast measurements. The overhead already is quite high (too high from my point of view) and opening and closing will not help. Note that instruments can also call other instruments (e.g. virtual instruments), leading potentially to a chain of open-open-open-close-close-close calls.
@peendebak  great feedback.
When you say one process, you mean  n instruments sitting in one process, which is separated from main ? Or everything sitting in the main process? (which can be made non blocking in other ways than processes that is, since most of qcodes is IO bound rather than CPU bound)
