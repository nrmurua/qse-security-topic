I first prepared arbitrary adjacency matrix of a graph as follows.
matrix = np.array(
[[1,1,1,1,1,1,0,0,0,0],
[1,1,1,1,1,1,0,0,0,0],
[1,1,1,1,1,1,0,0,0,0],
[1,1,1,1,1,1,0,0,1,0],
[1,1,1,1,1,1,0,1,0,0],
[1,1,1,1,1,1,1,0,0,0],
[0,0,0,0,0,1,1,0,0,0],
[0,0,0,0,1,0,0,1,0,0],
[0,0,0,1,0,0,0,0,1,1],
[0,0,0,0,0,0,0,0,1,1]]
)-np.eye(10)
And then I fed this matrix into the module
s=hafnian_sample_graph(matrix,6)
print(s)
to see the simulated result of photo count with mean photon number of 6 at the output Gaussian state.
I have only changed the number of sample parameter in the module as follows to generate 10 samples
def hafnian_sample_graph(
A, n_mean, samples=10, cutoff=5, max_photons=30, approx=False, approx_samples=1e5, pool=False
):
But Implementing this line gave this error message
/Users/ryuminseok/anaconda3/lib/python3.10/site-packages/numpy/linalg/linalg.py:2154: RuntimeWarning: divide by zero encountered in det
r = _umath_linalg.det(a, signature=signature)
/Users/ryuminseok/anaconda3/lib/python3.10/site-packages/numpy/linalg/linalg.py:2154: RuntimeWarning: invalid value encountered in det
r = _umath_linalg.det(a, signature=signature)
/Users/ryuminseok/anaconda3/lib/python3.10/site-packages/numpy/linalg/linalg.py:2154: RuntimeWarning: divide by zero encountered in det
r = _umath_linalg.det(a, signature=signature)
/Users/ryuminseok/anaconda3/lib/python3.10/site-packages/numpy/linalg/linalg.py:2154: RuntimeWarning: invalid value encountered in det
r = _umath_linalg.det(a, signature=signature)
The code still generates output pattern, although I have to wait for quite a long time. But I doubt that this module of photo count pattern generation is reliable if it involves division by zero which can lead to numerical instability or incorrect result.
It occurs every time
The Walrus: a Python library for for the calculation of hafnians, Hermite polynomials, and Gaussian boson sampling.
Copyright 2018-2021 Xanadu Quantum Technologies Inc.
Python version:            3.10.9
Platform info:             macOS-13.4.1-arm64-arm-64bit
Installation path:         /Users/ryuminseok/anaconda3/lib/python3.10/site-packages/thewalrus
The Walrus version:        0.20.0
Numpy version:             1.23.5
Scipy version:             1.10.0
SymPy version:             1.11.1
Numba version:             0.56.4
No response
No response
Hey @minseok1999! Can you please edit your post and include the output of the following:
You can put this in the "System information" box. It would also help if you could include the full error traceback ðŸ˜„.
Hey @minseok1999! Can you please edit your post and include the output of the following:
You can put this in the "System information" box. It would also help if you could include the full error traceback ðŸ˜„.
I have edited as requested!
Hmm... I'm not able to replicate the behaviour you're seeing. Here are my package versions:
Slightly different from yours. Can you try those versions and see if it works for you?
Hmm... I'm not able to replicate the behaviour you're seeing. Here are my package versions:
Slightly different from yours. Can you try those versions and see if it works for you?
Here is the list of libraries that I imported
and I have changed the package version as follows
The Walrus: a Python library for for the calculation of hafnians, Hermite polynomials, and Gaussian boson sampling.
Copyright 2018-2021 Xanadu Quantum Technologies Inc.
Python version:            3.10.9
Platform info:             macOS-13.4.1-arm64-arm-64bit
Installation path:         /Users/ryuminseok/anaconda3/lib/python3.10/site-packages/thewalrus
The Walrus version:        0.20.0
Numpy version:             1.23.5
Scipy version:             1.11.0
SymPy version:             1.12
Numba version:             0.57.1
But I keep seeing this behavior
Can this be because of the specific property of the matrix that I fed into hafnium_sample_graph
as   s=hafnian_sample_graph(matrix,6) ?
@minseok1999 Let's stick with the simpler example here:
Can you provide the entire error traceback when you try to run this? Don't leave anything out ðŸ˜„
@minseok1999 Let's stick with the simpler example here:
Can you provide the entire error traceback when you try to run this? Don't leave anything out ðŸ˜„
I have tried your simpler form and I got
OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.
[[0 0 0 0 0 0 0 0 0 0]
[1 0 1 1 2 0 0 1 0 0]
[0 0 0 0 0 0 0 0 0 0]
[0 0 0 0 0 1 1 0 0 0]
[3 2 3 0 3 1 0 0 0 0]
[4 4 2 1 5 4 0 0 0 0]
[3 2 1 3 0 4 1 0 0 0]
[1 1 1 1 1 1 0 0 0 0]
[2 1 0 1 2 0 0 0 0 0]
[1 0 1 0 0 0 0 0 0 0]]
without the division by zero error anymore. Why is this like this? Should I not be fidgeting with the fixed library? Only change I made to the library was to change the number of samples explicitly in the definition of hafnian_sample_graph itself ðŸ˜…
And what is going on with this nested routine deprecation in this case?
He @minseok1999, I asked some other folks internally to try and replicate the behaviour you're getting, and nobody is able to â€” everyone can run this code without error. A couple things you can try:
Let me know if either of those work!
I have tried google colab as you advised and this works cleanly without error.
And by creating a new file without redefining library myself and reinstalling thewalrus library in that new file (pip install thewalrus) I could see that it works fine and I could get result of hafnian_sample_graph without error. (Before the renewing of the library using pip install thewalrus this nested routine deprecation message persisted)
I wish I could figure out why this message
"OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead"
or " divide by zero error"
occurs or locate where the clash happens when I copy and paste from the original library and slightly modify the definition itself in my own Jupyter Notebook, but I ain't an expert on how the library structure works in Jupyter Notebook so I'd better be satisfied with the clean result from sticking to your simpler code with renewed installation of thewalrus libraryðŸ˜…
Awesome! Glad you got this solved ðŸ˜„. Sometimes virtual environments get "messed up" and need a refresh just like anything else would ðŸ˜….
