The right output is 0.5, but got 1.0 when run at GPU. And run this code at CPU can get right answer. WHY ? ? ?
Hi,
As per your other issue (#209), are you setting the correct compute-capability for your GPU? To check you're setting it correctly, you should run the unit tests on the develop branch, via (replacing [here] with your GPU's compute capability, without decimal points):
There, I run only the correctness checks (not input validation checks) and exclude the slowest test. These tests will fail if you do not set GPU_COMPUTE_CAPABILITY correctly.
Finally, the QuEST API provides a precision-agnostic qreal type, which will resolve to float, double or long double depending on your compile-time configuration. Hence, I suggest you to avoid using float (which is not the default precision), and use qreal instead. That is, change
to
Let me know how you get on!
Thanks very much. I have run the unit test according to the command you provided. and all tests passed（My GPU is P100, the GPU_COMPUTE_CAPABILITY is set to 60).
Excellent, does this correct your issue (changing also float to qreal)?
Unfortunately，still get 1.0 when running on GPU. But run another program as follows, can get right answers.
Very strange. Maybe I need to know how QuEST works when using GPU
Is that precisely the correction I just twice nominated? In C, you shouldn't cast doubles (the default qreal) to lower precision (float). In QuEST, for precision agnosticism, use qreal
