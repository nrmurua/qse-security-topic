`import os
import numpy as np
import cudaq
from cudaq import chemistry
geometry = [('Li', (0., 0., 0.)), ('H', (0., 0., 1.5))]
molecule, data = chemistry.create_molecular_hamiltonian(
geometry, 'sto-3g', 1, 0)
cudaq.set_target('nvidia')
numElectrons = data.n_electrons
numQubits = 2 * data.n_orbitals
kernel, thetas = cudaq.make_kernel(list)
qubits = kernel.qalloc(12)
kernel.x(qubits[0])
kernel.x(qubits[1])
kernel.x(qubits[2])
kernel.x(qubits[3])
cudaq.kernels.uccsd(kernel, qubits, thetas, numElectrons, numQubits)
num_parameters = cudaq.kernels.uccsd_num_parameters(numElectrons, numQubits)
print("num_parameters: ", num_parameters)
optimizer = cudaq.optimizers.SPSA()
energy, params = cudaq.vqe(kernel,
molecule,
optimizer,
parameter_count=num_parameters)
print(energy, params)
When I comment out cudaq.set_target('nvidia'), the result is: = -4.703793
 = -4.758690
 = -7.863358
 = -4.931899
 = -4.906214
 = -7.863358
-7.863357621533178 [-1.17716665170367e-12, -1.17716665170367e-12, 1.17716665170367e-12, 1.17716665170367e-12, -3.5484976526133087e-12, -1.17716665170367e-12, 3.5484976526133087e-12, 3.5484976526133087e-12, 3.5484976526133087e-12, -3.5484976526133087e-12, -3.5484976526133087e-12, -1.17716665170367e-12, -1.17716665170367e-12, 1.17716665170367e-12, 1.17716665170367e-12, 1.17716665170367e-12, 3.5484976526133087e-12, 1.17716665170367e-12, -1.17716665170367e-12, 1.17716665170367e-12, -1.17716665170367e-12, 3.5484976526133087e-12, 3.5484976526133087e-12, -3.5484976526133087e-12, -1.17716665170367e-12, -1.17716665170367e-12, 3.5484976526133087e-12, 1.17716665170367e-12, -1.17716665170367e-12, -3.5484976526133087e-12, 3.5484976526133087e-12, -1.17716665170367e-12, -3.5484976526133087e-12, 1.17716665170367e-12, -3.5484976526133087e-12, 1.17716665170367e-12, 3.5484976526133087e-12, 1.17716665170367e-12, -1.17716665170367e-12, -3.5484976526133087e-12, 3.5484976526133087e-12, -3.5484976526133087e-12, -3.5484976526133087e-12, -1.17716665170367e-12, 3.5484976526133087e-12, 1.17716665170367e-12, 3.5484976526133087e-12, -1.17716665170367e-12, -3.5484976526133087e-12, -1.17716665170367e-12, 3.5484976526133087e-12, 1.17716665170367e-12, -1.17716665170367e-12, 1.17716665170367e-12, -3.5484976526133087e-12, -1.17716665170367e-12, -1.17716665170367e-12, -3.5484976526133087e-12, -3.5484976526133087e-12, -3.5484976526133087e-12, -1.17716665170367e-12, 1.17716665170367e-12, 3.5484976526133087e-12, 1.17716665170367e-12, 1.17716665170367e-12, -1.17716665170367e-12, -1.17716665170367e-12, -3.5484976526133087e-12, 3.5484976526133087e-12, -3.5484976526133087e-12, -3.5484976526133087e-12, 3.5484976526133087e-12, -1.17716665170367e-12, -1.17716665170367e-12, 3.5484976526133087e-12, -1.17716665170367e-12, 1.17716665170367e-12, 1.17716665170367e-12, -3.5484976526133087e-12, -3.5484976526133087e-12, 3.5484976526133087e-12, -1.17716665170367e-12, 3.5484976526133087e-12, -3.5484976526133087e-12, 3.5484976526133087e-12, -1.17716665170367e-12, 3.5484976526133087e-12, 1.17716665170367e-12, 1.17716665170367e-12, -1.17716665170367e-12, 1.17716665170367e-12, -1.17716665170367e-12]
`
but,When I uncomment out cudaq.set_target('nvidia'), the result is:
`
 = -4.103592
 = -4.103592
 = -4.103592
 = -4.103592
 = -4.103592
 = -4.103592
-4.10359188271741 [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
`
Download the cuda-quantum docker according to the documentation, then run the above code to reproduce the result via set_target('nvidia')
The gpu should run faster, and the result should be the same
Not a regression
No response
What GPU are you using? I tried to reproduce the problem on both an A100 and A6000 and I was unable to reproduce the different behavior when toggling whether or not the nvidia target was being used.
您使用什么 GPU？我尝试在 A100 和 A6000 上重现该问题，但在切换是否使用 nvidia 目标时无法重现不同的行为。
I am using Tesla T4 and A100 GPUs with CUDA version 12.2 and nvcc version 12.2. When I use the CPU to calculate the energy of LiH, the computed result is very close to the accurate value. However, when I use the GPU, the computed result differs significantly.
您使用什么GPU？我尝试在A100和A6000上恢复该问题，但在切换是否使用nvidia目标时无法恢复不同的行为。
this is demo_code

and this is cpu result

after, When I add set_target('nvidia')
gpu result:

Hi @Guogggg,
I cannot reproduce the bug on my system with A100 GPU.
My steps:
你好@Guogggg,
我无法在使用 A100 GPU 的系统上重现该错误。
我的步骤：
What version of cuda and nvcc are you using?
Need to download custatevec using pip?
Like @1tnguyen, I didn't need to install custatevec in order to run this test. Also, nvcc is not installed in the docker container image because it is not needed unless you are modifying cuda-quantum source code, but nvidia-smi (which is installed in the container and uses the underlying driver on the host system) reports that it is using CUDA version 12.2 on one of my systems and 12.0 on the other.
Like @1tnguyen, I didn't need to install custatevec in order to run this test. Also, nvcc is not installed in the docker container image because it is not needed unless you are modifying cuda-quantum source code, but nvidia-smi (which is installed in the container and uses the underlying driver on the host system) reports that it is using CUDA version 12.2 on one of my systems and 12.0 on the other.
docker:
docker run --gpus all -it -u root --rm nvcr.io/nvidia/cuda-quantum:0.4.0
cd /home/cudaq/examples/python
For any example, as long as I add cudaq.set_target("nvidia"),
the calculation results are incorrect.
Claims to be fixed.
@Guogggg We were able to reproduce this issue with V100 GPUs and fixed it in #696.
I'm closing this issue now but please feel free to file another if it doesn't work for you.
Thanks for reporting the issue.
