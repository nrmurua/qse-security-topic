I have a question:
Thank you,
Jenny
There are two separate issues here: parallel computation in the optimizer, and parallel (batched) computation in the objective function. The latter should available to all as all the optimizers request points in batches (which by default are serialized) although I have no tests for this (as-is, I've not had the luxury of access to more than one quantum computer at a time). As for the former, yes, NOMAD is the only one that itself supports parallel computation, namely OpenMP. Note, however, that there's a bad interplay between Python and C++ threads: Python requires the GIL to be acquired, thus if the objective function is written in Python, enabling OpenMP isn't going to make much of a difference. (Of course, Python can call C++ in turn and release the GIL just before doing so.)
Specific to some optimizations problems, you may also be interested in multi-start algorithms (running instances of an optimizer with different initial parameters), which is of course embarrassingly parallel. It's not built into the system yet, but we've had some good success with codes developed by our colleagues at ANL.
Perhaps you can explain in a bit more detail the use case? That might help narrow down the proper course.
Thank you for the explanation. Yes I mean the algorithm will support allowing multiple function evaluation in each iteration. From our previous experience, Nomad is a very powerful pattern search optimization algorithm. Previously we used Matlab interface (https://www.inverseproblem.co.nz/OPTI/) as Nomad wrapper, but it does not support parallel computing. As Python becomes more and more popular, we are looking for a Python wrapper, so I was wondering if scikit-quant will be a good option. Our objective functions are also written in Python language, also as wrapper even though the actual model can be in different modeling languages. Another thing we want to make sure is that the NOMAD implemented in Scikit-quant has the full features of original Nomad, for example, support categorical variables, bi-objective optimization, etc. Thank you!
First, note that if you're primarily interested in NOMAD and not in any of the other optimizers nor interfaces to e.g. Qiskit, you can install SQNomad independent of scikit-quant:
https://pypi.org/project/SQNomad/
In fact, if you install scikit-quant (with NOMAD option enabled), it will simply pull in SQNomad from PyPI for you, as a dependency, and it has an overlay to use NOMAD through a standardized interface. Other than the overlay, there is no difference in direct use.
Yes, it's the complete NOMAD, albeit beta 2 of v4, not v3.8 as the link that you reference shows.
As for the Python interface: I started by upgrading the old v3.8 Python interface to v4. That was upstreamed to NOMAD proper. For our own purposes, however, we do want the interface to be complete and the old Python interface never was. So, I removed the dependency on Cython and started working through the manual. That work, however, is not yet done. Once it is, I'll see whether upstream is interested in including this new interface into NOMAD (I'm optimistic that they will be) and then you can simply use the official release from Python. Regardless, even today the SQNomad Python interface is more functional than the original Python interface that is in the NOMAD repo. I'd recommend you try it and file bug reports for features that are not yet accessible (evaluation of options in NOMAD is deeply tied to the original C++ code), so they can be prioritized higher.
Right now, what would limit you remains the Python GIL. OpenMP is non-starter if your objective functions are written in pure Python. Furthermore, the current Python interface evaluates blocks of points by grabbing the GIL at the outset, then looping over the points in the block. So, what needs to be changed in your case is that instead of individual points, your Python objective receives the original block of points, e.g. as a numpy array, and then your objective can in turn release the GIL if the true objective is written in some other language and called through some wrapper.
(I've been thinking of using multiprocessing directly to avoid pushing GIL handling on the author of the Python objective function, but that will probably make things worse in the case the actual objective is in a different language as then you'd have to figure a way of streaming its state to another process.)
Thank you again for the detailed description. We are also interested in other algorithms in Scikit-quant if they are good at solving constrained nonlinear black-box optimization problems. Would you recommend any other algorithms? Can Nomad also be invoked through scipy.optimize interface? Also does SQNomad support all the options in original NOMAD, do you have examples of modifying those options?  Yes we can try it, but appreciate more detailed documentation and examples. Thank you!
Would you recommend any other algorithms?
The selection of algorithms was made based on the presence of noise in the objective function. The differences between the algorithms mainly depend on the noise characteristics, the optimization surface, and scaling (i.e. problem size). In fact, we found that a combination worked well (due to differences between global and local search capabilities). We documented our experience here:
https://ieeexplore.ieee.org/document/9259985
And all optimizers used, except ORBIT (which we've not found useful, to be honest), live in their own independent PyPI packages. See SQSnobFit, SQImFil, and Py-Bobyqa on PyPI.
Can Nomad also be invoked through scipy.optimize interface?
Yes, through an interop layer, see the documentation:
https://scikit-quant.readthedocs.io/en/latest/scipy.html
(All the layer really does is convert/reorder input and output types.)
Also does SQNomad support all the options in original NOMAD
In theory yes. The complication is that NOMAD generates its options with a utility which then uses heavy-handed templates to type check the types of options. Even in C++ this leads to portability issues, as on some platforms standard types (e.g. size_t) can be readily converted to specific builtin types and on others they can not. This gets worse on Python, b/c even as the option type system is draconially enforcing such differences between e.g. unsigned int and unsigned long (even on platforms, such as Windows, where both are the same 4-byte machine type), Python is blissfully unaware of all such types.
The upshot is that to deal with the plethora of options, without reproducing the options generator utility, the Python code converts, with a few exceptions, most options to strings and lets NOMAD reparse those strings. That's bound to throw up some problematic corner cases.
do you have examples of modifying those options?
Just add them as keyword arguments, e.g. SEED=12345, or as part of the options dictionary in the case of the SciPy interface.
Thank you for all the answers. We will try and provide additional feedback if we have. Your help is very much appreciated!
