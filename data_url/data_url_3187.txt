Currently readout correction relies on readout symmetrization to work properly.  The only symmetrization method currently provided is exhaustive symmetrization -- where all arrangements of bit flips are measured for any given observable that is to be measured.  This means that, for an observable with n qubits, we need to run 2**n different measurements to get a symmetrized expectation value.
This is particularly pathological when running something like DFE, which has constant overhead wrt number of qubits, but gets exponentially slower when using readout error mitigation.
Exhaustive symmetrization is not an altogether bad idea -- it is the more efficient way to symmetrize small programs. So we need this option to exist.
The fix would be to add another method to symmetrize expectation values based on random sampling of bit flips for the readout symmetrization.
Yet another improvement would be to have symmetrization happen at lower levels of the stack, see e.g., quil-lang/qvm#52
Note that this is the default behavior!
