Recently dealing with circuits with large numbers of U / U3 gates has become important.  When looking into the composition of U3 gates Optimize1qGates it was noted that (if you use U over U3 due to overheads in the latter) that Optimize1qGates.compose_u3, and in particular calls to Quaternion become the bottleneck.  It would be nice to push this bit of code down into Rust to get an easy 100x improvement in compose_u3.  Here is some example Cython code that is a drop in replacement for the current code, and is hopefully easy for someone to port over:
Thanks Paul - this is definitely a good candidate for moving into Rust.  I don't know if anybody external to Terra is using the Quaternion class. Perhaps we could move that entire thing into Rust, and everyone can have the speed-ups if so.
@HM0880: you mentioned you were interested in getting started on some Rust bits and bobs.  This might be another good choice for you, if you'd like.  No pressure, just flagging it so you know.
I have some interest in this improvement and could potentially try porting to Rust (at least the Cython snippet, not sure about all of Quaternion). Just to check first:
I think there are two different workstreams.  One is to do symbolic manipulation for special cases where it is possibly faster to do so.  The second is basically this issue here, where faster numerical manipulation is desired.  As such, I think it is fine to go ahead with this.
Moving the whole class to Rust seems like something interesting to try.  That would give performance somewhere between doing it all in one shot (as the code above does) and the current NumPy code; You would still have some NumPy array creation overhead, but not as much as is there now.
As was mentioned by @mtreinish , this particular piece of code is not used in the preset passmanagers.  Those rather use Optimize1qGatesDecomposition.  Unlike here, where the form of the matrix is defined by the U angles, Optimize1qGatesDecomposition works on arbitrary gates by first expressing their matrix representation and then performing multiplication.  This is more difficult to speed up then the case here.  Namely there are multiple NumPy arrays being created in the process, and that becomes the bottleneck; the __array__ method of the gates is near the top of the profiling.  Perhaps if each gate had its decomposition in terms of U gate angles as an attribute then that routine could see similar benefits.
As a general statement, we are working in kind of a worst case regime for using Python and NumPy as numerics because the overheads of function calls and array creation takes longer than the floating-point evaluations for such small matrices.
It would require a pretty major reorg of the circuit data structures, we could consider moving the parameters out of the gate instances and into a numpy tensor. Ie the circuit has a (n1,2,2) tensor for all the 1q gates, a (n2,4,4) tensor for all the 2q gates, etc, and the gate instances merely contain indices into the corresponding tensor. If we had that then the unroll-all-the-1q-gates-in-a-circuit type cases could be vectorized nicely and avoid all the numpy dispatch overhead: instead of the current (pseudocode):
instead have a (n, n, 2) tensor us of all the 1q unitaries and do the decomposition on all of them at once:
Some dirty tests with %timeit suggests about 200x speedup from this kind of vectorization.
I'm also assuming here that the internal working representation of gates would become the unitary matrix, which also saves a lot of time from the repeated conversions between unitary and euler representations we otherwise end up doing during compilation, delaying that to conversion just once at the final stage. I looked into using 1q unitaries internally a while back and it was complicated by UnitaryGate being in qiskit/extensions rather than part of the circuit library. Somehow this caused circular import problems or something - I don't remember the exact issue.
could consider moving the parameters out of the gate instances and into a numpy tensor
interesting idea, though that's a bigger project than I'm personally up for at the moment. ðŸ˜…
Since it sounds useful at least in the short term, here's a first draft of a Rust port of the Cython snippet above. It agreed with Cython on a set of random imports (further below). I have not looked at timing yet.
I ran the Cython code on 1000 random pairs of input u3 angles:
and found they equaled the results of feeding the same random_angles into the Rust function (function call not shown):

So remaining steps could be:
That looks like a good start it should be pretty performant there are no obvious performance red flags to me. To integrate it into qiskit it's pretty easy, you just leverage the #[pyfunction] macro from pyo3 to have it generate the python c api interface function and then add that to a module (either a new one or as part of an existing one). https://github.com/Qiskit/qiskit-terra/blob/main/src/sparse_pauli_op.rs#L63-L67 is a simple example of this (with the pyfunction use on L39). The only other thing to do is if adding a new module (instead of putting it in an existing one) is to add that to the root _accelerate module here: https://github.com/Qiskit/qiskit-terra/blob/main/src/lib.rs#L41-L48 and add the submodule path to qiskit: https://github.com/Qiskit/qiskit-terra/blob/main/qiskit/__init__.py#L23-L31 then you can just replace the compose_u3 function with the rust version from qiskit._accelerate.submodule.compose_u3_rust.
Thanks, hopefully I have it configured correctly now. Seeing 20-40x speedup (may depend on the random angles chosen). I guess I'll just remove the original function definition and make a PR.

The original Cython code gave around 60x, so seems about right.
