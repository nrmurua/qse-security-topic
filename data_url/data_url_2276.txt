If a user is confident their density matrix is valid, it would be good if they could calculate the expectation value without the additional overhead of an eigenvalue decomposition or numerical error causing this computation to error out (especially when the density matrix represents a nominally pure state). @peterse thoughts?
We have many linalg methods with check_preconditions=True on them. You could add such a thing to the method.
I'm a bit surprised that validating the density matrix involves taking an eigendecomposition. Shouldn't checking that it is Hermitian with unit trace be sufficient?
The eigendecomp is to check positive-definiteness. I'll go ahead and add something along those lines to both expectation methods in a way that makes sense.
Ah I see, the eigenvalues (-1, +2) or (-0.5, 0.5, 0.5) would pass the Hermitian-and-unit-trace test.
If you pick a random vector and multiply it by (D-I)^N where D is the density matrix and N is very large (use repeated squaring), the vector will diverge to infinite size iff there's any negative eigenvalues (note that there can't be any positive eigenvalues larger than 1 if there are no negative eigenvalues given the unit trace constraint). But unfortunately this is worse complexity than eigendecomposition.
https://scicomp.stackexchange.com/questions/12979/testing-if-a-matrix-is-positive-semi-definite suggests we should use the Cholesky decomposition https://en.wikipedia.org/wiki/Cholesky_decomposition https://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.cholesky.html
Performance certainly checks out, especially since the cholseky timing is the worst case for input validation:
