I'm running some simulations now that involve simulating feedback. I need to do this in a hacky way that involves running a circuit which involves a measurement, getting the output state, and reinitializing the system register again and continuing. If I do enough iterations I eventually get the error "ValueError: State is not normalized instead had norm 1.0000141". This is definitely due to the single precision simulator.
But more generally the single precision is frustrating because numpy defaults to double precision arrays. So whenever I feed the simulator an initial state I need to manually write ".astype(numpy.complex64)". This is showing up all over my code. Furthermore, I find it a bit annoying to see normalizations and expectation values that are things like 1.00000006 instead of just "1".
In short, single precision is just not what users expect, and I think it makes the experience worse. I imagine this is a fairly straightforward fix.
Making the precision configurable is a reasonable idea. I don't agree that the simulator should default to double precision. Sometimes people want to sacrifice the 2x speed benefits of using single precision in order to get more accurate results, sometimes they don't.  Actually, I almost feel like we should default to using half-precision instead of single-precision because half-precision has 10 bits of mantissa, whereas single precision has 23 bits of mantissa, and 2^-10 ~= 10^-3 is much closer to plausible hardware error rates than 2^-23 ~= 10^-7. (Except one must account for the fact that rounding errors occur per amplitude per operation instead of just per operation.)
As a side note, please don't say something is "what users expect" unless you've actually asked several users. Or preface it with "I think this is what users expect". If you have actually asked several users (preferably not the same ones every time), mention that. In my experience, expectations about speed-vs-accuracy differ by person and use case (e.g. one of my old coworkers used to say "why does double even exist? No one ever wants to pay the speed cost for using it.", though that was in the context of rendering).
@dabacon I think the "I have to say astype everywhere" is an example of why we should reconsider requiring the cast to be safe. Alternatively, we could use the type of the initial state as a hint on what precision to use (...on the other hand, that's very surprising that reducing the precision of the initial state would speed up the simulation!).
Note that switching to double will not fix "seeing values that are things like 1.00000006 instead of just 1". It just pushes the problem a few order of magnitudes down the road. Floating point calculations almost never return exactly 1, but it may be within few enough ulps that python or numpy just print the value as 1.
+1 to the idea of making sure precision is piped through simulators, though a bit more complicated at api.
@Strilanc myself, Jarrod and Ian are using Cirq for research and we've been discussing these things frequently. I think we're a typical user group. I'm opening these issues in response to frustration that I encounter while using the package. However, in the future I'll be careful to explain that this is my opinion.
Does using double precision really slow the code down by a factor of two? I would find that surprising. You're not dealing with vectorized instruction sets or anything, right? What are you doing that goes twice slow with double precision?
But in any event, you know what you're doing a lot better than me. Assuming that this would really slow things down by a factor of two, then I am in favor of not requiring safe casting. And if that is the case I don't even think it is necessary to add the option to use double precision.
myself, Jarrod and Ian are using Cirq for research and we've been discussing these things frequently. I think we're a typical user group
I think that's great and that the feedback you give is incredibly valuable and I do think you represent an important user segment. I just prefer you to say "myself" or "myself and Jarrod" or etc instead of "users". For the same reason I'd avoid saying "many researchers say X" in a paper without giving citations.
What are you doing that goes twice slow with double precision?
Just because it's twice as much memory to move around, and my expectation is that would be the bottleneck. I haven't actually measured whether this is true for cirq on a workstation.
Assuming that this would really slow things down by a factor of two, then I am in favor of not requiring safe casting. And if that is the case I don't even think it is necessary to add the option to use double precision.
Noted.
I believe our simulators now all support passing in a numpy.dtype.  Please someone open this if they know otherwise (of course Clifford simulator doesn't do this, btw).
