Is there a limit to the size of an array that can be used in a kernel method?  I have an experiment that is running in Artiq 3.6, on Windows 64 bit that creates an array, set's it's first element to zero on the kernel, but then never returns from the kernel method:
The experiment I'm running is:
Which never prints 'done' and the experiment stays running in the schedule window of the dashboard.  If I set the size to 70,000 the kernel method does return though, 'done' is printed and the experiment completes.
In either case, the last two debug messages in the logs are:
If I change self.data to a numpy array, that fixes it and the kernel method does return.
Should numpy arrays always be used instead of vanilla python arrays?
I would generally use arrays. But it shouldn't hang like that. Is there anything on the UART?
It almost certainly hangs in the type inferencer, which has to typecheck the entire 80000 elements. And yes, numpy arrays are preferred in kernels for this reason.
@whitequark @jordens @sbourdeauducq it would be very helpful if these sorts of distinctions (subtle issues that can dramatically impact efficiency of operation) could have some brief mentions in the compiler section of the manual.  I feel like a number of ARTIQ adopters might get very frustrated by issues like this and #709 and #804, and if it's in the manual as "known bug, fix in progress" that would help.
It seems that this is not an issue anymore with the current master.
