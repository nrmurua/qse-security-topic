Dear developers,
I'm trying to install CP2K version 2023.2 with the intel compiler, but I get an error. For installation I used the cloned version of cp2k, as well as the archive.
I used this command
./install_cp2k_toolchain.sh --math-mode=mkl --with-intel  --with-mkl --with-intelmpi  --with-openmpi=system --with-sirius=no  --with-cmake=system  --enable-cuda=no
After installing all the programs, compilation was started.
`MPI is detected and it appears to be OpenMPI
Compiling with 72 processes for target native.
==================== Finding GCC from system paths ====================
path to gcc is /usr/bin/gcc
path to g++ is /usr/bin/g++
path to gfortran is /usr/bin/gfortran
Found include directory /usr/include
Step gcc took 1,00 seconds.
==================== Finding Intel compiler from system paths ====================
path to icx is /home/quark/intel/oneapi/compiler/2023.0.0/linux/bin/icx
path to icpx is /home/quark/intel/oneapi/compiler/2023.0.0/linux/bin/icpx
path to ifort is /home/quark/intel/oneapi/compiler/2023.0.0/linux/bin/intel64/ifort
CC  is /home/quark/intel/oneapi/compiler/2023.0.0/linux/bin/icx
CXX is /home/quark/intel/oneapi/compiler/2023.0.0/linux/bin/icpx
FC  is /home/quark/intel/oneapi/compiler/2023.0.0/linux/bin/intel64/ifort
Step intel took 0,00 seconds.
==================== Getting proc arch info using OpenBLAS tools ====================
wget  --quiet https://www.cp2k.org/static/downloads/OpenBLAS-0.3.23.tar.gz
OpenBLAS-0.3.23.tar.gz: OK
Checksum of OpenBLAS-0.3.23.tar.gz Ok
/usr/bin/ld: warning: /tmp/icx-7d4acc/cpuid-b05c7a.o: missing .note.GNU-stack section implies executable stack
/usr/bin/ld: NOTE: This behaviour is deprecated and will be removed in a future version of the linker
./f_check: 96: [: Illegal number: # mark_description
OpenBLAS detected LIBCORE = haswell
OpenBLAS detected ARCH    = x86_64
==================== Finding CMake from system paths ====================
path to cmake is /usr/bin/cmake
Step cmake took 0,00 seconds.
==================== Finding OpenMPI from system paths ====================
path to mpiexec is /home/quark/Soft/OPENMPI_4_1_5/bin/mpiexec
path to mpicc is /home/quark/Soft/OPENMPI_4_1_5/bin/mpicc
path to mpic++ is /home/quark/Soft/OPENMPI_4_1_5/bin/mpic++
path to mpifort is /home/quark/Soft/OPENMPI_4_1_5/bin/mpifort
Step openmpi took 0,00 seconds.
==================== Finding MKL from system paths ====================
MKLROOT is found to be /home/quark/intel/oneapi/mkl/2023.0.0
libm is found in ld search path
libdl is found in ld search path
Step mkl took 0,00 seconds.
Step fftw took 0,00 seconds.
==================== Installing LIBINT ====================
wget  --quiet https://www.cp2k.org/static/downloads/libint-v2.6.0-cp2k-lmax-5.tgz
libint-v2.6.0-cp2k-lmax-5.tgz: OK
Checksum of libint-v2.6.0-cp2k-lmax-5.tgz Ok
Installing from scratch into /home/quark/cp2k_1/tools/toolchain/install/libint-v2.6.0-cp2k-lmax-5
Step libint took 282,00 seconds.
==================== Installing LIBXC ====================
wget  --quiet https://www.cp2k.org/static/downloads/libxc-6.2.2.tar.gz
libxc-6.2.2.tar.gz: OK
Checksum of libxc-6.2.2.tar.gz Ok
Installing from scratch into /home/quark/cp2k_1/tools/toolchain/install/libxc-6.2.2
Step libxc took 36,00 seconds.
==================== Installing Libxsmm ====================
wget  --quiet https://www.cp2k.org/static/downloads/libxsmm-1.17.tar.gz
libxsmm-1.17.tar.gz: OK
Checksum of libxsmm-1.17.tar.gz Ok
Installing from scratch into /home/quark/cp2k_1/tools/toolchain/install/libxsmm-1.17
Step libxsmm took 23,00 seconds.
Step scalapack took 0,00 seconds.
==================== Installing COSMA ====================
wget  --quiet https://www.cp2k.org/static/downloads/COSMA-v2.6.6.tar.gz
COSMA-v2.6.6.tar.gz: OK
Checksum of COSMA-v2.6.6.tar.gz Ok
wget  --quiet https://www.cp2k.org/static/downloads/COSTA-v2.2.2.tar.gz
COSTA-v2.2.2.tar.gz: OK
Checksum of COSTA-v2.2.2.tar.gz Ok
wget  --quiet https://www.cp2k.org/static/downloads/Tiled-MM-v2.2.tar.gz
Tiled-MM-v2.2.tar.gz: OK
Checksum of Tiled-MM-v2.2.tar.gz Ok
Installing from scratch into /home/quark/cp2k_1/tools/toolchain/install/COSMA-2.6.6
Step cosma took 70,00 seconds.
==================== Installing ELPA ====================
wget  --quiet https://www.cp2k.org/static/downloads/elpa-2022.11.001.tar.gz
elpa-2022.11.001.tar.gz: OK
Checksum of elpa-2022.11.001.tar.gz Ok
Installing from scratch into /home/quark/cp2k_1/tools/toolchain/install/elpa-2022.11.001/cpu
Step elpa took 143,00 seconds.
Step ptscotch took 0,00 seconds.
Step superlu took 0,00 seconds.
Step pexsi took 0,00 seconds.
Step quip took 0,00 seconds.
Step gsl took 0,00 seconds.
Step plumed took 0,00 seconds.
Step hdf5 took 0,00 seconds.
Step libvdwxc took 0,00 seconds.
==================== Installing spglib ====================
wget  --quiet https://www.cp2k.org/static/downloads/spglib-1.16.2.tar.gz
spglib-1.16.2.tar.gz: OK
Checksum of spglib-1.16.2.tar.gz Ok
Installing from scratch into /home/quark/cp2k_1/tools/toolchain/install/spglib-1.16.2
Step spglib took 7,00 seconds.
==================== Installing libvori ====================
wget  --quiet https://www.cp2k.org/static/downloads/libvori-220621.tar.gz
libvori-220621.tar.gz: OK
Checksum of libvori-220621.tar.gz Ok
Installing from scratch into /home/quark/cp2k_1/tools/toolchain/install/libvori-220621
Step libvori took 18,00 seconds.
Step libtorch took 0,00 seconds.
Step spfft took 0,00 seconds.
Step spla took 0,00 seconds.
Step sirius took 0,00 seconds.
==================== generating arch files ====================
arch files can be found in the /home/quark/cp2k_1/tools/toolchain/install/arch subdirectory
Wrote /home/quark/cp2k_1/tools/toolchain/install/arch/local.ssmp
Wrote /home/quark/cp2k_1/tools/toolchain/install/arch/local.sdbg
Wrote /home/quark/cp2k_1/tools/toolchain/install/arch/local.psmp
Wrote /home/quark/cp2k_1/tools/toolchain/install/arch/local.pdbg
========================== usage =========================
Done!
Now copy:
cp /home/quark/cp2k_1/tools/toolchain/install/arch/* to the cp2k/arch/ directory
To use the installed tools and libraries and cp2k version
compiled with it you will first need to execute at the prompt:
source /home/quark/cp2k_1/tools/toolchain/install/setup
To build CP2K you should change directory:
cd cp2k/
make -j 72 ARCH=local VERSION="ssmp sdbg psmp pdbg"
arch files for GPU enabled CUDA versions are named "local_cuda."
arch files for GPU enabled HIP versions are named "local_hip."
arch files for OpenCL (GPU) versions are named "local_opencl."
arch files for coverage versions are named "local_coverage."
Note that these pre-built arch files are for the GNU compiler, users have to adapt them for other compilers.
It is possible to use the provided CP2K arch files as guidance.`
Compiling the psmt version results in the following error
quark@quark-desktop:~/cp2k_1$ make -j 72 ARCH=local VERSION=psmp Discovering programs ... make -C /home/quark/cp2k_1/exts/dbcsr -f /home/quark/cp2k_1/exts/build_dbcsr/Makefile \ ARCHFILE=/home/quark/cp2k_1/arch/local.psmp \ LIBDIR=/home/quark/cp2k_1/lib/local/psmp/exts/dbcsr \ OBJDIR=/home/quark/cp2k_1/obj/local/psmp/exts/dbcsr \ USE_ACCEL="" \ ACC="" \ ACCFLAGS="" Removing stale archives for psmp ...  Removing stale archives ...  Resolving dependencies for psmp ...  Resolving dependencies ...  /usr/bin/env python3 /home/quark/cp2k_1/exts/dbcsr/tools/build_utils/fypp/bin/fypp -n --line-marker-format=gfortran5 /home/quark/cp2k_1/exts/dbcsr/src/utils/dbcsr_array_sort.F dbcsr_array_sort.F90 /usr/bin/env python3 /home/quark/cp2k_1/exts/dbcsr/tools/build_utils/fypp/bin/fypp -n --line-marker-format=gfortran5 /home/quark/cp2k_1/exts/dbcsr/src/core/dbcsr_timings_base_type.F dbcsr_timings_base_type.F90 /home/quark/Soft/OPENMPI_4_1_5/bin/mpicc -c -cc= -fPIC -fp-model=precise -g -qopenmp -qopenmp-simd -traceback -xHost -O2 -funroll-loops   -I/home/quark/Soft/OPENMPI_4_1_5/include  -m64 -I/home/quark/intel/oneapi/mkl/2023.0.0/include -I/home/quark/intel/oneapi/mkl/2023.0.0/include/fftw -I'/home/quark/cp2k_1/tools/toolchain/install/libint-v2.6.0-cp2k-lmax-5/include' -I'/home/quark/cp2k_1/tools/toolchain/install/libxc-6.2.2/include' -I'/home/quark/cp2k_1/tools/toolchain/install/libxsmm-1.17/include' -I'/home/quark/cp2k_1/tools/toolchain/install/COSMA-2.6.6/include' -I'/home/quark/cp2k_1/tools/toolchain/install/elpa-2022.11.001/cpu/include/elpa_openmp-2022.11.001/modules' -I'/home/quark/cp2k_1/tools/toolchain/install/elpa-2022.11.001/cpu/include/elpa_openmp-2022.11.001/elpa' -I/home/quark/cp2k_1/tools/toolchain/install/spglib-1.16.2/include -std=c11 -Wall -D__LIBXSMM  -D__parallel -D__MPI_F08 -D__MKL -D__FFTW3  -D__SCALAPACK -D__LIBINT -D__LIBXC -D__COSMA -D__ELPA  -D__SPGLIB -D__LIBVORI   /home/quark/cp2k_1/exts/dbcsr/src/acc/opencl/acc_opencl_event.c /home/quark/Soft/OPENMPI_4_1_5/bin/mpicc -c -cc= -fPIC -fp-model=precise -g -qopenmp -qopenmp-simd -traceback -xHost -O2 -funroll-loops   -I/home/quark/Soft/OPENMPI_4_1_5/include  -m64 -I/home/quark/intel/oneapi/mkl/2023.0.0/include -I/home/quark/intel/oneapi/mkl/2023.0.0/include/fftw -I'/home/quark/cp2k_1/tools/toolchain/install/libint-v2.6.0-cp2k-lmax-5/include' -I'/home/quark/cp2k_1/tools/toolchain/install/libxc-6.2.2/include' -I'/home/quark/cp2k_1/tools/toolchain/install/libxsmm-1.17/include' -I'/home/quark/cp2k_1/tools/toolchain/install/COSMA-2.6.6/include' -I'/home/quark/cp2k_1/tools/toolchain/install/elpa-2022.11.001/cpu/include/elpa_openmp-2022.11.001/modules' -I'/home/quark/cp2k_1/tools/toolchain/install/elpa-2022.11.001/cpu/include/elpa_openmp-2022.11.001/elpa' -I/home/quark/cp2k_1/tools/toolchain/install/spglib-1.16.2/include -std=c11 -Wall -D__LIBXSMM  -D__parallel -D__MPI_F08 -D__MKL -D__FFTW3  -D__SCALAPACK -D__LIBINT -D__LIBXC -D__COSMA -D__ELPA  -D__SPGLIB -D__LIBVORI   /home/quark/cp2k_1/exts/dbcsr/src/acc/opencl/acc_opencl_mem.c /home/quark/Soft/OPENMPI_4_1_5/bin/mpicc -c -cc= -fPIC -fp-model=precise -g -qopenmp -qopenmp-simd -traceback -xHost -O2 -funroll-loops   -I/home/quark/Soft/OPENMPI_4_1_5/include  -m64 -I/home/quark/intel/oneapi/mkl/2023.0.0/include -I/home/quark/intel/oneapi/mkl/2023.0.0/include/fftw -I'/home/quark/cp2k_1/tools/toolchain/install/libint-v2.6.0-cp2k-lmax-5/include' -I'/home/quark/cp2k_1/tools/toolchain/install/libxc-6.2.2/include' -I'/home/quark/cp2k_1/tools/toolchain/install/libxsmm-1.17/include' -I'/home/quark/cp2k_1/tools/toolchain/install/COSMA-2.6.6/include' -I'/home/quark/cp2k_1/tools/toolchain/install/elpa-2022.11.001/cpu/include/elpa_openmp-2022.11.001/modules' -I'/home/quark/cp2k_1/tools/toolchain/install/elpa-2022.11.001/cpu/include/elpa_openmp-2022.11.001/elpa' -I/home/quark/cp2k_1/tools/toolchain/install/spglib-1.16.2/include -std=c11 -Wall -D__LIBXSMM  -D__parallel -D__MPI_F08 -D__MKL -D__FFTW3  -D__SCALAPACK -D__LIBINT -D__LIBXC -D__COSMA -D__ELPA  -D__SPGLIB -D__LIBVORI   /home/quark/cp2k_1/exts/dbcsr/src/acc/opencl/acc_opencl.c /home/quark/Soft/OPENMPI_4_1_5/bin/mpicc -c -cc= -fPIC -fp-model=precise -g -qopenmp -qopenmp-simd -traceback -xHost -O2 -funroll-loops   -I/home/quark/Soft/OPENMPI_4_1_5/include  -m64 -I/home/quark/intel/oneapi/mkl/2023.0.0/include -I/home/quark/intel/oneapi/mkl/2023.0.0/include/fftw -I'/home/quark/cp2k_1/tools/toolchain/install/libint-v2.6.0-cp2k-lmax-5/include' -I'/home/quark/cp2k_1/tools/toolchain/install/libxc-6.2.2/include' -I'/home/quark/cp2k_1/tools/toolchain/install/libxsmm-1.17/include' -I'/home/quark/cp2k_1/tools/toolchain/install/COSMA-2.6.6/include' -I'/home/quark/cp2k_1/tools/toolchain/install/elpa-2022.11.001/cpu/include/elpa_openmp-2022.11.001/modules' -I'/home/quark/cp2k_1/tools/toolchain/install/elpa-2022.11.001/cpu/include/elpa_openmp-2022.11.001/elpa' -I/home/quark/cp2k_1/tools/toolchain/install/spglib-1.16.2/include -std=c11 -Wall -D__LIBXSMM  -D__parallel -D__MPI_F08 -D__MKL -D__FFTW3  -D__SCALAPACK -D__LIBINT -D__LIBXC -D__COSMA -D__ELPA  -D__SPGLIB -D__LIBVORI   /home/quark/cp2k_1/exts/dbcsr/src/acc/opencl/acc_opencl_stream.c /home/quark/Soft/OPENMPI_4_1_5/bin/mpicc -c -cc= -fPIC -fp-model=precise -g -qopenmp -qopenmp-simd -traceback -xHost -O2 -funroll-loops   -I/home/quark/Soft/OPENMPI_4_1_5/include  -m64 -I/home/quark/intel/oneapi/mkl/2023.0.0/include -I/home/quark/intel/oneapi/mkl/2023.0.0/include/fftw -I'/home/quark/cp2k_1/tools/toolchain/install/libint-v2.6.0-cp2k-lmax-5/include' -I'/home/quark/cp2k_1/tools/toolchain/install/libxc-6.2.2/include' -I'/home/quark/cp2k_1/tools/toolchain/install/libxsmm-1.17/include' -I'/home/quark/cp2k_1/tools/toolchain/install/COSMA-2.6.6/include' -I'/home/quark/cp2k_1/tools/toolchain/install/elpa-2022.11.001/cpu/include/elpa_openmp-2022.11.001/modules' -I'/home/quark/cp2k_1/tools/toolchain/install/elpa-2022.11.001/cpu/include/elpa_openmp-2022.11.001/elpa' -I/home/quark/cp2k_1/tools/toolchain/install/spglib-1.16.2/include -std=c11 -Wall -D__LIBXSMM  -D__parallel -D__MPI_F08 -D__MKL -D__FFTW3  -D__SCALAPACK -D__LIBINT -D__LIBXC -D__COSMA -D__ELPA  -D__SPGLIB -D__LIBVORI   /home/quark/cp2k_1/exts/dbcsr/src/acc/opencl/smm/opencl_libsmm.c icx: error: unknown argument: '-cc=' icxicx: : error: unknown argument: '-cc='error:  unknown argument: '-cc=' icx: error: unknown argument: '-cc=' icx: error: unknown argument: '-cc=' make[4]: *** [/home/quark/cp2k_1/exts/build_dbcsr//Makefile:262: acc_opencl_event.o] Error 1 make[4]: *** Waiting for unfinished jobs.... make[4]: *** [/home/quark/cp2k_1/exts/build_dbcsr//Makefile:262: acc_opencl_mem.o] Error 1 make[4]: *** [/home/quark/cp2k_1/exts/build_dbcsr//Makefile:262: opencl_libsmm.o] Error 1 make[4]: *** [/home/quark/cp2k_1/exts/build_dbcsr//Makefile:262: acc_opencl.o] Error 1 make[4]: *** [/home/quark/cp2k_1/exts/build_dbcsr//Makefile:262: acc_opencl_stream.o] Error 1 /home/quark/Soft/OPENMPI_4_1_5/bin/mpifort -c -fc= -fPIC -fp-model=precise -g -qopenmp -qopenmp-simd -traceback -xHost -O2 -funroll-loops   -I/home/quark/Soft/OPENMPI_4_1_5/include  -m64 -I/home/quark/intel/oneapi/mkl/2023.0.0/include -I/home/quark/intel/oneapi/mkl/2023.0.0/include/fftw -I'/home/quark/cp2k_1/tools/toolchain/install/libint-v2.6.0-cp2k-lmax-5/include' -I'/home/quark/cp2k_1/tools/toolchain/install/libxc-6.2.2/include' -I'/home/quark/cp2k_1/tools/toolchain/install/libxsmm-1.17/include' -I'/home/quark/cp2k_1/tools/toolchain/install/COSMA-2.6.6/include' -I'/home/quark/cp2k_1/tools/toolchain/install/elpa-2022.11.001/cpu/include/elpa_openmp-2022.11.001/modules' -I'/home/quark/cp2k_1/tools/toolchain/install/elpa-2022.11.001/cpu/include/elpa_openmp-2022.11.001/elpa' -I/home/quark/cp2k_1/tools/toolchain/install/spglib-1.16.2/include   -D__LIBXSMM  -D__parallel -D__MPI_F08 -D__MKL -D__FFTW3  -D__SCALAPACK -D__LIBINT -D__LIBXC -D__COSMA -D__ELPA  -D__SPGLIB -D__LIBVORI   -diag-disable=8291 -diag-disable=8293 -fpp -fpscomp logicals -free -D__SHORT_FILE__="\"dbcsr_array_sort.F\"" -I'/home/quark/cp2k_1/exts/dbcsr/src/utils/' -I'/home/quark/cp2k_1/exts/dbcsr/src' dbcsr_array_sort.F90  /home/quark/Soft/OPENMPI_4_1_5/bin/mpifort -c -fc= -fPIC -fp-model=precise -g -qopenmp -qopenmp-simd -traceback -xHost -O2 -funroll-loops   -I/home/quark/Soft/OPENMPI_4_1_5/include  -m64 -I/home/quark/intel/oneapi/mkl/2023.0.0/include -I/home/quark/intel/oneapi/mkl/2023.0.0/include/fftw -I'/home/quark/cp2k_1/tools/toolchain/install/libint-v2.6.0-cp2k-lmax-5/include' -I'/home/quark/cp2k_1/tools/toolchain/install/libxc-6.2.2/include' -I'/home/quark/cp2k_1/tools/toolchain/install/libxsmm-1.17/include' -I'/home/quark/cp2k_1/tools/toolchain/install/COSMA-2.6.6/include' -I'/home/quark/cp2k_1/tools/toolchain/install/elpa-2022.11.001/cpu/include/elpa_openmp-2022.11.001/modules' -I'/home/quark/cp2k_1/tools/toolchain/install/elpa-2022.11.001/cpu/include/elpa_openmp-2022.11.001/elpa' -I/home/quark/cp2k_1/tools/toolchain/install/spglib-1.16.2/include   -D__LIBXSMM  -D__parallel -D__MPI_F08 -D__MKL -D__FFTW3  -D__SCALAPACK -D__LIBINT -D__LIBXC -D__COSMA -D__ELPA  -D__SPGLIB -D__LIBVORI   -diag-disable=8291 -diag-disable=8293 -fpp -fpscomp logicals -free -D__SHORT_FILE__="\"dbcsr_timings_base_type.F\"" -I'/home/quark/cp2k_1/exts/dbcsr/src/core/' -I'/home/quark/cp2k_1/exts/dbcsr/src' dbcsr_timings_base_type.F90  ifort: command line warning #10006: ignoring unknown option '-fc=' ifort: command line warning #10006: ignoring unknown option '-fc=' make[3]: *** [/home/quark/cp2k_1/exts/build_dbcsr/Makefile:177: libdbcsr] Error 2 make[2]: *** [/home/quark/cp2k_1/exts/Makefile.inc:38: dbcsr] Error 2 make[2]: *** Waiting for unfinished jobs.... make[1]: *** [/home/quark/cp2k_1/Makefile:128: psmp] Error 2 make: *** [Makefile:123: all] Error 2 
Please tell me how I can install the new version of cp2k. Previously, using this scenario, I was able to install cp2k 2023.1 without any problems
System characteristics:
Intel oneAPI 2023.0
ifort version 2021.8.0
Distributor ID: Ubuntu
Description:    Ubuntu 23.04
Release:        23.04
Codename:       lunar
local.psmp.log
@Quark195 Remove the flag --with-openmpi=system and try to build from scratch again. With Intel oneAPI, also Intel MPI should be employed.
Thank you for your assistance. I managed to install the new cp2k successfully. However, I encountered an issue when performing calculations for a supercell. The program freezes, much like it did with version 2023.1. Interestingly, the computer appears to be functioning properly, and all CP2K processes are visible. Can you please advise on what might be causing this issue?
supercell.inp.log
supercell.log
I cannot reproduce that "freeze" with your input using CP2K 2023.2. The run proceeds smoothly beyond 6 iteration steps, although it shows no tendency of convergence even after 12 steps. A smaller ALPHA parameter (0.1 instead of 0.4) could help.
Thank you so much again for your help.
