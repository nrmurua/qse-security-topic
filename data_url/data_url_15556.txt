For moderately-sized systems where a deep ansatz circuit is used, the expectation value returned by sampling the circuit using CircuitSampler will return a verifiably incorrect answer. I first noticed this issue when running VQE simulations for moderately-sized systems such as H20 (14 qubits), NH3 (16 qubits), and N2 (20 qubits). When using a callback function to print out the function evaluations at each iteration, sometimes the objective function would evaluate to exactly 0.0 or -0.0 when it did not make sense to. The larger the system, the higher the probability that this would happen. I have been able to reproduce this phenomenon outside the context of VQE by simply taking the expectation value of the Hamiltonian with respect to some circuits. This happens, for instance, when the UCCSD ansatz is used, but not when a very shallow ansatz is used.
The following piece of code results in the bug:
This returns:
-0.0
If we un-comment the line ansatz = HF_state, so that the ansatz used is no longer the UCCSD ansatz, but just the HartreeFock circuit (much shallower), then it returns:
-132.16365914584333
In the first instance, we used the UCCSD ansatz with all parameters set to zero, but initialized with the HartreeFock circuit. Thus, the UCCSD part of the circuit should be equivalent to the identity. In the second instance, we are just using the HartreeFock circuit. These two circuits should be equivalent, but they return completely different expectation values.
I have tried this on my local machine (MacOS arm64) using the same Qiskit-terra version and have so far not been able to reproduce the bug. This leads me to believe that this issue could be specific to the Linux wheels published, although this is difficult to know for sure because the python environments on the two machines I tested this on likely do not have identical dependencies.
The nature of this bug also seems to be probabilistic in some way. It does not happen every time, but it seems that the deeper the circuit, the higher the probability that it occurs. If the above code needs to be adjusted in any way to ensure reproducibility, please let me know. (I think this is what algorithm_globals.random_seed is supposed to do, but I'm not sure.)
I see that you are using the AerPauliExpectation above - was this the same VQE whether explicitly using that expectation object or implicitly via id default with include_custom=True. As that latter flag may suggest the expectation is computed using a custom Aer instruction. You say you are using the same Terra version - how about Aer?
The random_seed setting will affect any aspects of the algorithms and opflow where it uses a random value, e.g for VQE that would be the case if it selects a random initial point. For the code above I don't see anything where it might come into play. Simulators have their own random seeds too for the simulation. But given you are using AerPauliExpectation custom instruction I don't think that ought to have any bearing since the outcome should be ideal and not randomly sampled.
For VQE simulations, I explicitly provide it both expectation=AerPauliExpectation() and include_custom=True.
The point about the Aer version is a good one. I should keep track of the qiskit-aer version more carefully and I am not sure which qiskit-aer version I used on my local machine. If I use terra 0.19.2 and Aer 0.10.2 on both machines, the test above results in the returned value of -0.0 for both setups, so clearly this is not specific to the Linux wheels. When I use Aer 0.10.3, the above test returns the proper value of ~ 132 for both setups. However, I am not entirely convinced that this demonstrates that simply using Aer 0.10.3 solves the problem because there seems to be an element of random sporadicalness associated with when this bug. Here is a more illustrative example of what I mean by that. When I run the code:
Note that this is slightly different than from the above test because I transpile the ansatz prior to passing it as an argument to VQE. The log output of this attached below as NH3_L_BFGS_B_transpiled_UCCSD.log and was run using qiskit-aer-gpu 0.8.2 (with device='GPU' for the simulator),  Qiskit-nature 0.1.3, and Qiskit-terra 0.18.0. (I have tried playing around with the versions a bit to try and see a pattern.) You can see that only a fraction of the function evaluations are evaluated erroneously. Note also that the optimizer in this instance is L-BFGS-B, so most of the adjacent function evaluations are supposed to be approximately the same because the finite difference method only perturbs the parameters slightly.
NH3_L_BFGS_B_transpiled_UCCSD.log
When I run this script, except this time with qiskit-aer 0.10.2 and Qiskit-terra 0.19.2, (without the GPU this time), I get the results in this log file:
N2_VQE_regularAer0102_AerPauliExpectation_L_BFGS_B.log
This also does not appear to be specific to AerSimulator or AerPauliExpectation. Consider the following VQE simulation of H2O, this time using StatevectorSimulator and expectation=MatrixExpectation(), include_custom=False. This was run using qiskit-aer-gpu 0.8.2, Qiskit-terra 0.18.0, and Qiskit-nature 0.1.3:
Note that here I transpile the ansatz prior to passing it to VQE. (I've noticed in the past that this can help with performance.) This results in the log file:
H20_VQE_StatevectorSimulator_MatrixExpectation_082_L_BFGS_B.log
Let me try and run some VQE simulations overnight using qiskit-aer 0.10.3 and see if I can reproduce it with that version. Even if this ends up being a bug that was fixed in Aer 0.10.3, this is still somewhat of an issue because the latest version of qiskit-aer-gpu is 0.10.2 and the bug definitely appears there as well.
So far anyway, it looks like this issue goes away when using qiskit-aer 0.10.3, so this was likely related to one of the bug fixes in that update. Are there plans to add these bugfixes to qiskit-aer-gpu?
qiskit-aer issues/code are managed in a different repository. Perhaps @chriseclectic or someone else from the Aer team can comment on the above.
Oh, thanks for the heads up, I completely missed that the gpu wheel build job failed on the last release: https://github.com/Qiskit/qiskit-aer/actions/runs/1819280467 (they take hours and forgot to circle back and check it). It looks like it failed because python3.10 (which was new for 0.10.3) uses a different base image and the cuda package we installed wasn't compatible with that OS version. I'll try to fix that today and get an updated wheel published
Great thanks! I'll close this issue for now then because it seems to go away when using the latest version of Aer. If it turns out I just haven't tried hard enough to reproduce it and it shows up again, I'll re-open it in the repository that seems most likely to be the issue.
Right now it seems that the fix most likely responsible for fixing this was mentioned in the 0.10.3 release notes as :
"Multi-threaded transpilations to generate diagonal gates will now work correctly if the number of gates of a circuit exceeds fusion_parallelization_threshold. Previously, different threads would occasionally fuse the same element into multiple blocks, causing incorrect results."
Just fyi the wheels for python 3.6-3.9 qiskit-aer-gpu are live on pypi now (as of yesterday): https://pypi.org/project/qiskit-aer-gpu/0.10.3/ the 3.10 wheels will take a little more time to get ironed out
