Hello,
I'm the Lead developer of netket, a jax-based framework for using Machine-Learning techiques to study quantum systems (open and closed).
We are finalising the next release and as I am a big fan of extensibility, I would like our two frameworks to coexist and provide a sensible, easy api to work together.
Mainly, what I would like to do is provide an easy-to-use no-documentation-needed to convert NetKet's types to Qutip, so that it becomes easy to use it to check our variational calculations.
TLDR: I propose creating and documenting a __qobj__ interface so that arbitrary objects having this method will support conversion to a QuTiP Qobj.
--
NetKet has mainly three types that are concerned: hilbert spaces, operators and variational states.
Hilbert spaces describe the space every object is defined upon, and can be easily converted to your dims format.
Operators are used to represent operators and super-operators acting on hilbert spaces. We use a very custom format roughly corresponding to a lazy kronecker product. Those object satisfy the numpy __array__ interface and can be converted by calling np.array(netket_operator) or np.asarray(netket_operator). We can also obtain sparse representations (but there is no nice api to do that, so we simply provide a method netket_operator.to_sparse().
Variational states can also be converted to vectors or matrices (kets and density operators) as they also support the __array__ interface.
I would like our users to be able to call Qobj(netket_operator) or Qobj(netket_state) and obtain the corresponding qutip object. We could, in principle support a netket_operator.to_qobj() conversion method, but I am strongly opposed to that as this is an ugly design pattern: a way to construct a Qobj already exists, it's Qobj(...), and the simplest-to-use api is, in my opinion, to overload this constructor to perform the conversion.
This is a standard design pattern in Julia, which I believe has the best ecosystem inter-compatibility thanks to a standardisation of this pattern through (multiple)dispatch.
Numpy too, does the same, through the __array__ interface: any object that defines a __array__(self, dtype=None)->np.ndarray method will be supported by np.asarray and np.array.
Proposal: I would like QuTiP to support a __qobj__ interface, meaning that your Qobj constructor should check if an object has this method, and if it has, then use it to convert it to a Qobj.
It should be relatively simple and involve adding another else-if in your constructor
The only thing to do would be discussing the interface itself and document what it should return.
This will allow other software in the future to integrate with qutip, too, and I believe will help shape the ecosystem.
edit to put the positivity up top!: This is a very exciting prospect to me, and I'm always happy when other libraries want to interact with QuTiP!  In the interests of inciting more discussion, I've got thrown in some more discussion points below - I'm 100% sure they're all solvable, but it also seems like there isn't one way that's unambiguously correct to do them, so they're worth discussing.
In principle I'm happy to implement this, though I don't really agree with your assertion that othertype.toqobj() is bad style!  It might be so in Julia, but Python doesn't have all the same multiple-dispatch niceties that Julia has, so at the end of the day, we have to add in a method with a "magic" name somewhere, and it all just comes down to choosing the name of the method.  The downside to having a magic name is that it means we have to eschew proper namespacing; what if another library one day wants to call their interface the same thing?  Then it's completely impossible for a downstream library to interoperate with both.  Having conversions be a non-special method of the downstream class, and leaving our constructor unaware of them alleviates that issue.  Numpy can get away with squatting the __array__ name because they're huge, but I would argue that if we do it, we could actually harm the quantum software ecosystem in the long-run - what happens when a package better than QuTiP comes along that wants to call its objects Qobj as well?  Let's face it - it's a pretty straightforward name!
All that said, I am very aware that not everyone agrees with me on this, and I am a big fan of interfaces.  Python doesn't give us the tools to do it properly, but we can emulate it, like you suggest.  I have a few more considerations to add to a discussion:
Just in the interest of completeness, let me also just bring up some of the sweeping changes we'll bringing in in QuTiP 5.0 as well, which massively overhaul how Qobj is constructed, and how its data is stored.  These aren't directly applicable to the current discussion, but they're worth keeping in mind since they're a huge overhaul of how things will be handled, and may have some implications for how implementors of this interface might behave.
The new Qobj will no longer have the same fast_csr_matrix type as its data attribute, but instead will have an extensible data type.  The two that will be distributed with the library will be Dense and CSR (which simply do what they say on the tin), and all linear algebra operations between multiple Qobj are handled by a custom multiple-dispatch system that allows additional specialisations to be added in a similar way to Julia.  Say you want to define matmul between Dense on the left and CSR on the right to produce a CSR output (a specialisation that we likely won't ship with because it's unlikely to be efficient).  You'd write your function
and then because unlike Julia it's not built-in, you just manually add it to the dispatch table for matmul:
QuTiP then knows about it, so it'll get used when appropriate.
You can also add entirely new types to the dispatch table by adding them to the "cast" table qutip.data.to, giving at least one method to convert the new type into an already-known one, and at least one method to convert an already-known type into the new type.  QuTiP will then be able to use the entirely new type as Qobj.data for every single operation within the library (though it won't be super efficient until you add the linear algebra specialisations you use most).
This actually goes a bit beyond what Julia does (at least as far as I know), because QuTiP's new system "completes" the dispatch table for all known types automatically; when it's asked to do say kron on two types it doesn't have a specialisation for, it'll cast the inputs through a path of least weight into a specialisation it does know, and then use that.  The desired casting rules and preferred output types can be altered dynamically at run-time as well.  While I put a lot of effort into making this as fast as possible (and naturally a constant-time operation with respect to the number of known types and specialisations), of course the penalty we pay is a small run-time cost of type look-ups and dispatch (<1µs, but that's dwarfed by the cost of the operations themselves).
We will have a hook for creating "data-layer types" out of arbitrary inputs, but we weren't heavily focussing on this at all; it seems rather too special a case to have another magic interface for, and we can basically just reuse __array__ for it - "data-layer types" are essentially just "matrix-like" objects.  It also isn't appropriate for the situation you're describing here, because your own objects have additional "quantum-specific" attributes associated with them, similar to the extra stuff that Qobj contains.
If you want to see more of this, it's in the dev.major branch.
Defining an interoperable new public interface I think is quite a big task, since it's inherently got to be future-proof.  I'm definitely +1 on us having one, and having some discussion about it before a 5.0 release.
I'm most concerned with how we can do it in a manner that's useful without stymieing our own ability to iterate and improve. It's harder for downstream packages to support multiple versions of a magic interface than it is for them to changing call QuTiP library functions; with deprecation warnings we can have multiple valid methods for doing the same thing alive in the library at once, but we can't detect what version of an interface a downstream package requires (not keen on the idea of a __qutip_qobj_api_version__ flag!!).
Oh, one thing that I'd like to suggest we don't do: use this interface to implicitly create Qobj inside our functions.
__array__ was also originally meant as a method for allowing Numpy's ufuncs to act on other types.  This actually caused us rather annoying problems in QuTiP when they decided to change up its semantics a little bit in version 1.20, which is in part is why I'm very cautious around this topic.  Since we weren't super careful when we introduced Qobj.__array__, we allowed things like np.sin(qutip.sigmax()) which we shouldn't have, and then the Numpy 1.20 changes completely altered how ndarray(dtype=object) arrays behaved when containing objects that all implemented __array__.  To get around some of these problems, they've introduced __array_function__ and __array_ufunc__, though to me at best these are bandages.
Those two concerns aren't immediately applicable in QuTiP, but they're sort of indicative of potential problems when using a __qutip_qobj__ method implicitly in functions like Qobj.__add__.  These are where it becomes very evident that Julia-style programming doesn't apply in the same way in Python. Python is only a single-dispatch language, so a + b will dispatch using the table of a predominantly, whereas b + a will dispatch on b.  In a proper multiple-dispatch library the rules are separate to the classes, so neither class is called preferentially, there's just one rule and either library can define it.
My point with this is that if Qobj.__add__ has a case where it handles Qobj-like types, then we prevent the other library from overriding the method.  Multi-methods like this simply don't work the same in Python as they do in Julia, so even if Qobj implements interfaces from a variety of other libraries, we'd never get good consistent behaviour with functions like this.  Operations that ought to be commutative like + would become dependent on operand order.  To some degree, implementing the interface would be a guarantee that an object would always be able to follow QuTiP's semantics, otherwise it would just be annoying to users - sometimes an object would be able to be used implicitly, sometimes not.
I know the "Python way" is supposedly "try it and see", but if you're doing any serious development, that quickly becomes unreasonable if a type works some times, but not others.  The other part of the Python way is "explicit is better than implicit", and here having an explicit type conversion to me is just being explicit about which library's semantics you want to follow, which is easier to read and easier to debug.
1 - we can't have proper namespacing, but let's at least make the magic name qutip_qobj so we realistically prevent any chance of a clash
I think this is a good idea. Indeed jax uses the same trick (they define the __jax_array__ interface). While I think that Qobj is a very qutip-like principle, I see no problems in namespacing.
2- having the check in init
Again, I think that your observation is right. I thought about it only after I submitted the post above. The way numpy does it is that __array__(self, dtype) takes only one argument, but I think we can do better and better respect the API set by qutip.
That is why I was suggesting that object.__qutip_qobj__ should not return a Qobj directly, but rather the data needed by QuTiP to construct a Qobj, and qutip should be free to re-organize it afterwards as he likes.
3 - we need to take care to do this in a way that still allows QuTiP to iterate and improve Qobj.init between major versions.
You could for example require that __qutip_qobj__(self, version, *kwargs) takes in a version of the API? I believe that is what numpy does in __array_interface__.  And it's on implementers of the interface the burden of checking the api version and throwing an error if it's not supported.  Or the inverse, where implementers return whatever data they return and a version of the API they are using, and qutip can throw an error if that is an older version.
The latter would make it harder to support multiple versions of qutip in the implementers, but I would not worry too much about it. You can throw an error saying that this other package is not supported and you should either nag it's developers or downgrade qutip.
I'm not particularly worried about the blame: even if the error is thrown from qutip, if the message is clear enough it will be clear that the fault is in the downstream implementors of the API.
--
About keyword handling: copy-pasting the list of kwargs of Qobj...
For the case of the usage that netket would have, our objects already define the Hilbert space they are acting on (so dims and shape). copy doesn't really make sense for us, because we would be building the representation
The way I see it, Qobj(other_pkg_obj,**kwargs) should behave like Qobj(qutip_obj, **kwargs), so __qutip_qobj__ should return the matrix data, shape and dims if possible, and qutip will handle it from there.
About your future 'dispatch like' system:
I personally like dispatch because it makes everything more easily extensible (and/or hackable) if package authors agree on a common denominator and they are careful to rely only on that interface and on nothing else.
As all our operators are lazy, we already implement lazy operatordense and operatorsparse multiplication.
It might be interesting for us, in the future, to define dispatch rules for our operators, so that we don't even need to convert them to Qobj. But for now I'd focus on having an easy and extensible way to convert our objects to qutip format.
(Ideally, it would be nice if we could give qutip solvers our operators, which are not Qobj, provided they define the right dispatch rules, but I imagine that this would be complex and require significant effort on your part).
Hi Simon,
No we do not have time-dependent operators at the moment and focus on ground state/steady-state/dynamics of fixed hamiltonians or liouvillians.
Actually nobody has (yet) studied with neural networks time-dependent systems as far as i know.
However, our foundations do not prevent us to work with time-dependent objects.
We simply will need to write the relevant class.
It's really too early to know, and I know little of the structure of QobjEvo.
From the little i know you keep a sum of standard operators with a time dependent prefactor, right?
We will probably go for something similar. Since we are storing the single operators in an hamiltonian (like \sigma_x*\sigma_y) and their domains, we can easily insert a time dependence in front of every operator for a negligible cost.
However this representation is very different from the dense/sparse representation in QuTiP, as we need to support hilbert spaces with order of 100s spins and have a very different usage of the matrix elements during the computations.
But again, this is very premature... I doubt we'll get to time-dependent objects before an year or so.
Higher on our priority is  representing circuits.
I had a quick stab at this by adding a Metaclass to Qobj (I tried doing this within __new__ but could not get it to work. If it's possible I accept suggestions).
I am also unsure if your constructor Qobj is supposed to be called with positional, kwargs or a combination of both. If it was only kwargs the implementation could be more terse.
I assumed that the copy argument gets passed as part of __qutip_qobj_interface__, as in the conversion it might be necessary to copy anyway so the downstream implementor is responsible for taking care of the copy if requested.
I'm quite sure this implementation can be improved, however.
On the NetKet side, the implementation is very simple. At the moment we only support operators from H->H.
This already is quite nice and allows for quick and simple interoperability.
Some comments/questions:
Anything we do will be made on the dev.major branch, where the constructor is much simpler and easier to work with, which hopefully should make things rather easier for you.  The dimensions objects will probably change a lot before then as well (they should in principle accept any type, it's just historical that they only accept list).
The Qobj constructor is intended to allow the first argument to be passed positionally, but all others are expected to be keyword-only.  We'll probably start enforcing those semantics from 5.0 onwards (we need to issue deprecation warnings before we change behaviour).
Answers to questions:
For tensor products, we use the same ordering as np.kron.  The column-stacking convention is about the conversion of operators into operator-kets when moving to the superoperator formalism.
In theory it should recognise a suitable dims, but right now construction will be faster if you provide type='super' as well. Construction speed is hugely improved in dev.major.  You only need to define superrep if you're giving us a Choi (superrep='choi') or chi (superrep='chi') matrix instead.
No, it should really be any indexable quantity (requiring list is a historical artifact, not a conscious choice). The entire parsing structure of dimensions objects are going to change in 5.0 (though the list structure will still work).  This should even give you more freedom, if you need it - I've got some plans for vastly improved handling of restricted-entry Hilbert spaces (basically spaces that are small embeddings into a larger space that's all 0).
I am very strongly against accepting this (like I said above):
Oh, one thing that I'd like to suggest we don't do: use this interface to implicitly create Qobj inside our functions.
To me, this is absolutely one of the mistakes that Numpy made in their implementation, and we shouldn't be copying it.  You can see that it didn't work as intended, because they've had to add __array_function__ and other additional methods on top to start to make it work, and it's still not perfect - even scipy.sparse have/had problems implementing them.  While it might work in your particular case, making sure that nothing funny happens in the abstract across all possible implementors of the interface while still having it do something useful is a very tricky problem, as evidenced by Numpy.  Any conversion is going to be lossy for some people (perhaps not you, but it will be for others), and that means the behaviour for users will be surprising in some cases.  In my opinion, if we're going to have a __qutip_qobj__ interface, the interface should be defined for one operation only, and should never be called implicitly.  I'm not entirely close-minded to alternate views here, but given the problems Numpy had (whose team I have no doubt are much smarter than I am), I'm really not enthusiastic about any implicit conversions.
I really do appreciate the interest, and I am keen to let us have better compatibility with the rest of the community, but there are a lot of design concerns that we're going to want to work on our side first - I just want to caution you in case you're trying to work towards a PR, because I'm not close to being happy to accept one, yet.  If we're going to do this (and we haven't decided if we will yet), we're going to need to get a lot of wide-ranging input from many different libraries, and we'll want to write out a proper design document and get approval of it before we get deep into the implementation.
The latter would make it harder to support multiple versions of qutip in the implementers, but I would not worry too much about it. You can throw an error saying that this other package is not supported and you should either nag it's developers or downgrade qutip.
I'm not particularly worried about the blame: even if the error is thrown from qutip, if the message is clear enough it will be clear that the fault is in the downstream implementors of the API.
I'm concerned from a user's perspective.  QuTiP has a wide user base, and we're beyond the stage where "iterate fast and break things" is ok for us (though of course it's fine and even good for pre-stable libraries, to avoid getting weighed down).  We've got to be concerned with backwards and forwards compatibility; what if a user wants to install and use QuTiP and a different library in the same environment without using them together, but can't even have them coexist because of version incompatibilities in optional conversion features?  That's frustrating for users, even though it's not really anybody's fault.  Bugging developers is fine when people want to use packages that are still maintained, but I'm sure we've all come up against times in research when you get to trying out a package to do one specific thing that's been abandoned for a while.  Again, this certainly isn't an unsolvable problem: having versioning in the interface API is one solution to some of these problems.
For greater discussion, here's an alternate approach: instead of objects defining __qutip_qobj__, instead we expose an entry-point qutip.Qobj.register_conversion_function(converter, type, priority, version=None), and downstream libraries register functions rather than defining methods on their classes.  The logic inside the Qobj constructor remains approximately the same as what you suggest.   I think TensorFlow does something a little more similar to this?  (I'm not very familiar with it at all.)
Advantages of this over a __qutip_qobj__ magic method:
Disadvantages that I can think of:
Apologies that I'm not responding super quickly to everything - I'm not the only main QuTiP dev (and I can only work on QuTiP occasionally anyway), so I'm giving others time to read and think about the proposals as well.
By the way, if you're organising your next major release right now, I wouldn't wait for us before you release it - we certainly won't define any interface until at least QuTiP 5.0, and we don't expect to even be in the first alpha until around September.
—
Let me begin by saying that I completely understand your concerns. I am not trying to enforce a view on the QuTiP project, but rather as I see
I would like the various frameworks in the vast ‘quantum’ ecosystem to
coexist in such a way that makes easy for users to jump from one tool to the other easily.
I personally envisage an ecosystem where one can write down an hamiltonian in the tool of choice, obtain the exact time evolution with qutip, and maybe have a look at it’s semiclassical trajectory. Jump into netket and check if a variational representation can properly capture the correlations. Trotterize the hamiltonian and get a circuit, without worrying about how to convert from one framework to the other.
I want to start the discussion on this topic eagerly because I am aware that it will take a fairly long time. If there is anything I can do to make your future internal discussions easier, do let me know.
I just want to caution you in case you're trying to work towards a PR
Indeed. I was just trying to play around with this.
If we're going to do this (and we haven't decided if we will yet), we're going to need to get a lot of wide-ranging input from many different libraries
I completely agree with your approach. I’m simply trying to push for this to be something that will come out in a reasonable timeframe and not be something forgotten.
We've got to be concerned with backwards and forwards compatibility; what if a user wants to install and use QuTiP and a different library in the same environment without using them together, but can't even have them coexist because of version incompatibilities in optional conversion features?
I do understand your point, and I see how you want to be backward and forward compatible, however I  don’t think that my proposal would break different tools in the same environment. What I propose would simply prevent qutip.Qobj(otherlibraryobject) from working (with an explicative error message) if otherlibrary does not support the same qobj interface version. Everything else would work the same. You can still import and use the two libraries independently without issues.
It’s indeed possible to design around this and supporting at the same time different versions of the interface, however, and there’s value in doing so.
To me, this is absolutely one of the mistakes that Numpy made in their implementation, and we shouldn't be copying it.
I don't know enough of the history behind numpy current api, but I see your point. however I'd like to reiterate that this is not what I am proposing.
I think there is considerable difference between supporting arbitrary operations new_obj = Qobj + netket_operator*5 (though if you are going to export dispatch hooks in 5.0, this would be possible in a consistent way, I think) and qutip.mesolve(netket_operator, ...).
In the first, I do agree with your point that the nature python's __add__/__radd__ is not commutative, leading to surprising behavior. From my point of view, no package really owns + so any conversion would be implicit.
But qutip.groundstate(netket_operator) is in itself an explicit cast. I am explicitly asking to qutip please give me the ground state of this object. I do expect to get a Qobj out, and qutip to make an effort converting this object to whatever format he internally wants to work with. Same goes with time evolution.
For greater discussion, here's an alternate approach: instead of objects defining qutip_qobj, instead we expose an entry-point qutip.Qobj.register_conversion_function(converter, type, priority, version=None), and downstream libraries register functions rather than defining methods on their classes
I do prefer such an approach. I just did not think that was an option in QuTiP.
In fact we have redesigned NetKet to allow for something similar using multiple dispatch. (I’m not familiar with Tensorflow either.)
I do agree with all your points, especially the first.
As for your last point, about downstream packages having to import qutip: This is indeed a potential issue. I’ll try to investigate this: maybe there is a solution whereby a callback executed on package load can be registered with importlib?
Bump.
Has this been discussed internally between QuTiP developers?
Would you consider it?
@PhilipVinc Hello! Apologies for the long wait -- I think this got lost in people's holidays and other goings on.
I realized a few things while re-reading the long issue discussion:
We need to define clearly what we want to propose. E.g. Initially the request was just for the constructor to work, i.e. Qobj(netket_operator), and later in the discussion it expanded to include all operations and methods, e.g. qutip.groundstate(netket_operator), qobj * netket_operator, ... . These are proposals of quite different scope.
There clearly isn't a huge advantage either way to having Qobj(netket_operator) vs netket_operator.to_qobj() except perhaps that people don't need to remember to what kind of thing netket_operator is exactly if they are swapping between libraries.
It is already almost possible to implement Qobj(netket_operator) on top of QuTiP v5 (i.e. the dev.major branch) without any changes to QuTiP itself and it might be beneficial to close that slight gap for multiple reasons.
Posting example implementation in next comment.
Example implementation of Qobj(thing) with caveat noted below:
Example usage:
Explanation:
Caveat:
Bonus:
Thoughts?
Hi @hodgestar, thanks for chiming in!
What you posted here looks exactly like what I initially asked, so I am very much in favour of it.
I'm just slightly confused about what _call_qutip_qobj should return: in your example I assume .data is just a numpy/scipy matrix, so the dims data` is completely lost?
I am thinking about the (standard) use-case of netket users writing a lattice-hamiltonian like $\sum_i \sigma^x_i$.
QuTiP's dims attribute is our hilbert.shape attribute, but of course the matrix representation has a different shape.
If I am not mistaken in your example above this would result in the hilbert shape information being lost?
Is there no way we can preserve this information in some way?
Hi @hodgestar, thanks for chiming in!
What you posted here looks exactly like what I initially asked, so I am very much in favour of it.
I'm just slightly confused about what _call_qutip_qobj should return: in your example I assume .data is just a numpy/scipy matrix, so the dims data` is completely lost?
_call_qutip_qobj should return an instance of qutip.core.data.Data (i.e. an object that implements QuTiP 5's data layer protocol).
QuTiP's dims attribute is our hilbert.shape attribute, but of course the matrix representation has a different shape.
If I am not mistaken in your example above this would result in the hilbert shape information being lost?
Correct.
Is there no way we can preserve this information in some way?
My proposal is we should allow this information to be preserved. Some possible options I can see:
To properly implement what I was asking, dims should be preserved.
I'm not familiar with QuTiP's internals, but I agree with you that 2 is not feasible.
Implementing 1 might require more changes to quips internals that you'd like to do
To me it looks like 4 could be the ideal solution: you can add a default fallback that calls the current code-path, but allows others (netket) to override the qobj creation.
I'm sorry I don't have a huge amount of time at the moment, but just to add an extra point (that it looks like I didn't think about before): if we do add this, then any method that requires an unconditional import qutip in downstream packages probably isn't a suitable solution - import qutip already takes far too long (though a lot of this is importing various parts of scipy, which another library might do on our behalf), and it means that they'd have to do their own import checking to handle optional dependencies.  In that sense, (ab)using Python's duck-typing with a magic method might be the best way to break the dependency/import problem.
I'm definitely still against implicit conversion to Qobj in pretty much any situation - I can imagine we could define a safe, fairly forward-compatible interface for letting people do qutip.Qobj(x), but as it stands, that's the limit that I'd want the interface to be used for.  I particularly am really against the idea of implicit conversion. I don't see an advantage to allowing QuTiP functions to act implicitly on other objects; it means our own functions are slower (because we have to explicitly test inputs on everything), and it restricts us more from improving Qobj's internals, because we have to maintain compatibility with the interface.  We'd never really be able to output anything other than a Qobj without this, so there's no reason not to just have the user convert the inputs to Qobj explicitly themselves - that isolates the efficiency penalty so you only pay it if you need it, and it'll likely be clearer in the end anyway, because explicit is better for following the logic than implicit.
@jakelishman, about the two issues you raised:
A drawback of this implementation is that it requires the conversion method to be defined on the object itself.
The dispatch-like solution, as was proposed by @hodgestar, is easier to play with, can be defined in a separate file, can be added to a separate package like netket_qutip_interop or even using setuptools entry points, though that would add complexity.
Again, I'm personally not biased. I would go with option 1 because it's simpler, but I do like the organisational beauty of option 2 (that is used throughout the jax ecosystem).
I'd then like to state that
All my proposal was about was having a way to play well with your Qobj constructor.
It seems to me you were eventually favourable to this, so I propose we focus the discussion only on this point, and leave aside implicit or explicit conversion discussions.
I'll gladly open another issue to discuss implicit conversion, if you want, or we could organise a small round table among a bunch of developers to talk about this on skype, but for now, all i'm asking, is to agree on the design of an interface to allow easy conversion of objects to qutip objects.
Apologies for another long delay. I'd be happy to hop on a video call sometime to discuss the design.
I think the __qutip_qobj__ interface is likely to remain fairly simple and be just:
and we can figure out how to make that work on our side.
How that looks under the hood depends quite a bit on whether the Data object will grow dims support or not. We have another use case for dims on the data layer (a tensor network data backend that we're starting work on) but it is a bit of a philosophical shift in what the Data layer is, so we'll need to think carefully (e.g. all Data operations would have to keep track of dims which is a big change; and it's also a bit strange because the operations themselves are just 2D matrix operations, where dims are meaningless).
@PhilipVinc I'm not sure if we discussed this before, but do you have some short code snippets showing how you see this Qobj support being used in user code? Apologies if I missed such examples elsewhere in the discussion already.
That looks exactly what we'd need!
@hodgestar I'll post some snippets tomorrow morning. Right now my brain is too tired...
As for a video call, I'm all in on that idea. You can just send me an email at my email address (it's on my GitHub profile page) and we can agree on a time?
