In my initial testing, using a specialized strategy to implement gates gives significant speedups. Even the Hadamard gets faster.
The strategy I went with was for the magic method to take both the target tensor and also a buffer of the same shape and type, while allowing the method to either put its output in the buffer or to modify the target inline.
Here are a few example implementations.
RotXGate (3x faster than einsum on 2x2 matrix):
RotZGate (5x faster than einsum on 2x2 matrix) (CZ is basically the same; 30x faster than einsum on 4x4 matrix):
HGate (25% faster than einsum on 2x2 matrix):
If we allow _apply_unitary_effect_to_tensor_ to return the result and a scalar that the result needs to be eventually multiplied by, which the simulator accumulates together until a final multiplication at the end, the Hadamard gets 40% faster instead of 25% faster. In general, it seems like this optimization could save one sweep through the state vector per gate (unless that gate is a permutation gate or a diagonal gate).
For example, to perform the rotation gate [[cos(t), -sin(t)], [sin(t), cos(t)]] you could instead perform [[1, -tan(t)], [tan(t), 1]] * cos(t) (unless t is near a multiple of pi).
