This issue is to open up the discussion about some details of specifying objectives:
Currently, we specify the control objectives for Krotov's optimize_pulses by giving a list of Objective objects, where each Objective contains an initial_state, information about the dynamical generator (H, c_ops), and a target_state. This design mimics the QDYN implementation. Furthermore, it reflects that Krotov's method inherently can be parallelized across the propagation of different states (which we typically index by subscript k). The Python implementation already supports the parallelization of these independent "control trajectories".
For large classes of control problems, it is also natural to have a specific target_state associated with each specific "control trajectory". The assumption is that for every initial_state, the optimization goal is reached when the dynamical generator evolves it into the target_state. Examples include gate optimization, where the initial_states are the basis states and the target_states are the result of applying the gate to the basis states; and "robustness optimization", where multiple copies of the same initial_state/target_state are considered, under different dynamical generators.
As a side note, for gate optimization, there is a possible alternative that QuTiP's GRAPE implementation follows (probably due to its Matlab roots), where the "state" is the time evolution operator. That is, the initial_state is the identity and the target_state is the gate. Our Krotov implementation supports this setup as well, although the ability to parallelize is lost. In any case, it doesn't fundamentally alter anything.
There are some control problems where the use of a target_state is not natural. The only examples that I'm personally aware of are a gate optimization with a local-invariants functional, or the optimization towards a perfect entangler. Since we don't know in advance which locally-invariant gate or which perfect entangler the optimization will converge to, we cannot specify a target_state to which each basis state should be go.
I propose to allow the possibility to have the value None for the target_state attribute of an Objective. The target_states are not actually used for anything essential inside the Krotov implementation: It only uses the initial_states for the forward propagation. Then, the user-supplied chi_constructor routine that determines the boundary states for the backward propagation receives the entire list of objectives as an input, and can use it in any way it wants; the chi-routines for the standard gate-optimization functionals do look at the target_states defined in that list, but this is not a requirement. The chi_constructor routine can even bring along its own data separate from the objectives, e.g. via closures. This will be required for the local-invariants optimization, where the target gate will be stored inside the chi_constructor, not anywhere in the objectives.
The Python Krotov implementation currently uses the target_states for one thing: it calculates tau_vals as the complex overlap of the forward-propagated states and the target states. These values are passed to the info_hook and are also stored in the Result object. The motivation for calculating these is that for all optimizations where the definition of target_state makes sense, these quantities are extremely informative independent of the functional that is used, and indeed the standard functionals can usually directly be defined in terms of these tau_vals (thus saving work in the info_hook). However, the tau_vals are in no way essential to the algorithm, and we can easily handle the situation where the target_states are None by also setting the tau_vals to None.
In #4, @Basilewitsch made the point that it might be desirable to allow the initial_states and target_states to be defined in different Hilbert spaces, e.g. the initial_state on a bipartite system and the target_state in a subspace. This is currently prevented by the calculation of the tau_vals, which requires both states to be in the Hilbert space. My initial thought was that this is the way it should be: States are ultimate always in the full Hilbert space in which the dynamics take place, and since the chi_constructor can do whatever it wants, it is free to project/partially trace as appropriate. However, I also think that it is perfectly reasonable for a user to expect to be able to settarget_state in exactly the way @Basilewitsch was intending. I would propose to add an (optional) attribute transform to the Objective class to handle this. If set, the (callable) transform will be applied to the forward-propagated state before taking the overlap with the stored target_state. The transform could use QuTiP's eliminate_states method to change the shape of the state, which would solve the problem at hand.
The transform could also handle at least one other use case that we have in QDYN, but haven't considered in the Python implementation: the transformation between the rotating frame and the lab frame when optimizing in the rotating wave approximation. In this case, it is natural to want to write the initial_states and target_states in the lab frame, and to use the standard chi_constructor routines also written in the lab frame. For this to work, the forward-propagated states must be transformed from the rotating frame to the lab frame before calculating the chis.
So, while the transform is very strictly superfluous, it gives an elegant solution to at least these two problems, and possibly more, so I think we should include it.
Lastly, QDYN includes the possibility to use the functional J_op for "optimization of the expectation value of a sum of operators". I think this was added by @danielreich a long time ago. It seems to me that this is just another example of an optimization where target_states are not appropriate, but where the operator(s) whose expectation value should be maximized can be contained in the chi_constructor, just like the gate in the local-invariants optimization. Thus, there is no need to change the definition of Objective. Maybe @danielreich can confirm this?
In summary, my proposal at this point is the following:
This sounds like a good solution to me. It is not introducing any difficult to use functionality and solves most of the mentioned problems.
The expectation value for a sum of operators is not very different from other types of functionals. It is true, however, that "target_states" as a term does not make a lot of sense in that context. The information required for such an optimisation is an initial state and an operator / a set of operators (technically speaking there is no difference between an operator and a sum of operators due to linearity of the expectation value). These two objects together could be called the "objectives" and then the situation very much resembles, for example, the local invariants optimisation.
I agree with @danielreich that it is very natural and also very useful to have the option of optimizing an expectation value. A relevant example is minimizing the system energy (as Tommaso & Co have done for a many-body system). Combining both types of objectives sounds like a good solution to me.
The solution is even simpler than I had originally thought:
rename Objective.target_state to Objective.target, and place no limitations on what can be stored in target whatsoever.
99% of the time, it will still be the target state, but for PE it can be the string 'PE', for LI it can be the gate we want to reach up to single-qubit operations, and for the maximization of the expectation value it can be the operator. This way, the Objective actually contains all the information about the physical control objective, as it should.
calculate tau_vals as the overlap of the forward-propagated state and the target only if target is a state in the same Hilbert space (otherwise, set it to None).
There's no need for a transform then: if something like the projected tau_vals were required, they could be calculated inside the info_hook or the chi_constructor as necessary.
Of course, there still needs to be a shared agreement between what gets put in Objective.target and a specific chi_constructor routine (which implicitly contains the functional, distinct from the physical objective). However, by not limiting what target can be, we achieve maximum flexibility, and keep the code clean and simple.
very nice solution!
