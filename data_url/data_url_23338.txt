We would like to move from old dataset structure in CPH for cQED measurements. I believe almost everything is in place except for plotting functionalities that is currently implemented in show_num and a metadata viewer.
The functions in question are:
I only had a brief look at plottr so it is possible that some of these are already implemented but I believe at least the first point is missing.
Also is it clear from which repository we should be cloning plottr to have the latest updates?
@jenshnielsen @WilliamHPNielsen (@wpfff adding you to keep you in the loop).
so far my 2 cents:
High priority
Low(er) priority
another for lower priority:
@nataliejpg could you expand more on your requests (also, you can edit your first comment to incorporate the "another lower priority" item ;) ) in the following way:
thank you for your input @astafan8
you are very welcome, @nataliejpg !
@astafan8
@astafan8
so to clarify you are saying that it's not feasible to expect better labelling than this by default?
also just to be extra clear that while I do find the plotting very important the biggest thing for me right now is that the MultiChannel alazar parameter can't be saved. For me this is number 1.
yes. unless.... did you have a fix/workaround for the overlapping labels before (meaning, when you were working with the old dataset)? If so, could you give me a link?
@astafan8 it can't be true that qcodes solved one issue with the old dataset that we now have to convince you can be solved again for the new dataset. Changing to the new dataset should not put more work on us compared to the old dataset - otherwise we will just keep using the old one.
https://github.com/qdev-dk/qdev-wrappers/blob/master/qdev_wrappers/plot_functions.py
@ThorvaldLarsen please, do not get me wrong. With my questions to Nathalie about the "overlapping labels" issue, I'm trying to understand if it is purely the problem of the plotting utilities of the new dataset, or the plotting utilities of the old dataset had them as well. As I mentioned above, most probably, adding automatic "rescale axes to uV/nV/GHz/etc" (that you requested some days ago) for the new dataset (yes, this feature exists for the old dataset) will also help with "overlapping labels" because the labels will effectively become shorter.
When multidimentional arrays are stored in the dataset they are not completely converted to individual datapoints. Only the outer most dimension is unrolled. This is fixed by #1207
@jenshnielsen do I understand correctly that right now (before merge of #1207) you really can't use the array paramspec or is it that you can if you use it with this get_data_by_id function? Also what is the motivation for having load_by_id and get_data_by_id?
It only works correctly for 1d arrays before that pr is merged. get_data_by_id  is as fast as possible because it loads the data as is in the database but get_data_by_id is more convenient but we should probably get rid of this
I've summarized the descriptions for each of the mentioned items, and added them to our VSO. Soon they will be done :)
With all my understanding and respect, @ThorvaldLarsen and @nataliejpg , please, next time, make 1 github issue per 1 request/discussion. The set of issues above (because it is a set) was quite challenging to discuss and manage.
@astafan8 is there any sort of ETA for the alazar parameter one (or the others)? Thanks
