It would be really nice if qutip coud support the numba jit compiler (https://numba.pydata.org/) in some future releases. This would also enable, to perform calculations using the GPU very easily.
I would assign this to @quantshah due to expertise with GPU although I vaguely recall some discussion on Slack about this that went in an unfavorable direction for numba support.
I guess one road blocker is the missing scipy i.e. scipy.sparse support in numba.
Since a few months there is numba_scipy which currently only supports scipy.special. Their discussion what to prioritize is here: numba/numba-scipy#10
I'm not entirely sure what's being asked of us here, because the code numba supports is to do with the numba developers, not us?  numba is a compiler for Python code accessing NumPy arrays in ways other than internal NumPy compiled C code.  The benefit to QuTiP users even if numba were to add support would be minor, because a) we use custom sparse matrices which numba couldn't currently target to a GPU efficiently and b) almost all of our heavy code is compiled C, which is already as the same target as standard numba.
We aren't going to convert (e.g.) Qobj to a numba jitclass because our entire library is written in Cython, and besides, the speed-ups come from the internal Qobj.data attributes, which we are already low-level.  GPU-based sparse matrix routines are an interesting side-note, but will require very specialised data structures and accesses.  This is more possible in the new data-layer added in 5.0, but still would require a huge amount of work.  We're not likely to achieve this by using numba, but instead to use specialised GPU-enabled data structures like cupy instead, since that fits into our data model better.
