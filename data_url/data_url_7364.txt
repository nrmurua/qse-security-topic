Hi, I'm trying to run a simulation which will give steady-state polarization of a two-atom system driven by classical field, in presence of correlated decay. I was trying to run steadystate.master but it seems to be broken..
The time-evolution using timeevolution.master seems to give proper result:


This means that tracedistance from the initial state converges, approaching the steady state.
However, when I try using steadystate, the first error I encounter is:

I tried lowering hmin values to 1e-10  by
it runs without error, but the job seems to be running forever. Would you mind looking at steadystate.master to check if there's any bug?
Thanks in advance.
Hi there!
First off, the hmin error you get is caused by the default value of steadystate.master which sets it to 1e-7. In the usual master equation hmin is chosen according to the provided list of times,

As for the large amount of time it takes for the steadystate function to solve the problem, this might be caused by the default accuracy being too high. Try changing the kwarg eps above its default value of 1e-3. Additionally, steadystate.master calculates the tracedistance between rho(t) and rho(t+dt) at every step, which will also slow it down a bit.
How large is your Hilbert space dimension? For only two atoms it might be best to simply diagonalize the Liouvillian by using steadystate.eigenvector. Note, though, that there is currently no implementation of this for correlated decay, so you would have to use the diagonaljumps function as a workaround.
I hope this resolves the issue for you.
