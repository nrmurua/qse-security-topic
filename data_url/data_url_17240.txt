In several tests, we would like to run the same tests with different inputs (and their cartesian product). For example, in test_mappers we want to test swappers x circuits. In #2559 we want to run the test_all_examples with all the examples (in general, that's true for any property-based test).
The two competing ways are subtest and ddt (or similar). Let's take and extreme example, in which we want to run transpile on optimization_level x backend x circuits (from here).
With subtest:
With ddt (from 2532):
I prefer the ddt way, because allows to run the tests independently. Please, discuss.
My issue is that I don't really understand what ddt offers over subTest, to justify using a 3rd party library that is kind of sub-standard. ddt would be great in a pre-Python3.4 world where subTest was not supported, but why not use the standard library when it exists?
In different threads I saw two arguments for ddt:
1- Cleaner API:
But in the implementation of #2532, the API is not really ddt's, as you have created your own decorator for cartesian products (which I'm surprised is not natively supported in a library that has this one job?).
Simple nested for loops give you the Cartesian product without having to rely on extra decorators.
2- Independent tests:
While it is true that subTest treats success as a single success, it does quite clearly show multiple failures and what input caused failure (see example below). So again I don't understand what ddt buys us here.
How can I run only the case n=11? I need to debug it and our subtests are radically different. In ddt, tests are created.
So I can run n=11 by
Our "subTests" are more complex. They cover very different parts of the code and have very different call sequences. The proof of that is that we have very different issues for, for example, different optimization levels. That's way I need to run them independently.
Ok I'm convinced. This gives easier-to-debug tests and still retains a compact way to describe them.
Awesome, thanks!
Let me close this by saying that I don't see ddt and subtest as opposites. Sometimes, when the tests are very similar in terms of the code they exercise (like transpiling in different backends), subtesting does the job and will reduce the execution time. Hopefully, we will find a good combination of these two approaches!
