Thinking forward to adding multiple parameterizations of algorithms (e.g. #80) or multiple implementations of the same algorithm / parameterization (e.g., clean C, AVX2, ...):
There will probably be a lot of duplication.  If I think about Frodo or Kyber or probably others, the clean implementations of different security levels are exactly the same, except for the params.h file which contains the compile-time macros defining various sizes.
And if we start to do optimized implementations in other subdirectories, we probably have even more duplication, as in many cases it may be only one or two files that have been heavily optimized, the rest unchanged.
For example, in Frodo, there are 6 parameterizations {level 1, level 3, level 5} x {AES, SHAKE for matrix generation}.  All files save params.h and matrix.c are the same.
I suppose one solution to ensuring consistency would be to add some metadata somewhere saying which files are expected to be identical, and then add CI tests that check those files remain identical...
How about using symlinks?
Possibly problematic.
I've just realized it's even worse: all functions are namespaced according to the parameterization, so duplicate files are only identical modulo namespacing.
I've been working on another security level of Frodo, and have tried adding a check for duplicate consistency across schemes as follows:
Discussion agreed that consistency checks are the way to go. But they should be moved outside of the META.yml file so that those files remain simple for consumers of the code.  I'll move this information somewhere, probably into files inside a new directory test/duplicate_consistency.
Fixed by #83
