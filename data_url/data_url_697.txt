Hi,
I didn't find any obvious way to do a bitwise inner product between two basis ket, for Deutsch-Josza algorithm.
To be clear : |0101> dot |1001> = 0*1 + 1*0 + 0*0 + 1*1 = 1
A simple way to get this would be to have the inverse of mket()
You can use std::vectors, then qpp::mket out of them to produce the kets, and then std::inner_product to compute the inner products. Otherwise we should treat computational vectors on a different footing, which we tried to avoid.
I can't see how to do it with std::inner_product from the kets, other than the dot product in the Hilbert space, which is not what I want.
Otherwise we should treat computational vectors on a different footing, which we tried to avoid.
Yes I thought so. Using the index b of the computational vector is ok, as long as it's guaranteed that
For now, I've implemented it two ways : using qpp::n2multiidx and using c++20 std::popcount
If there's no other way to do it with q++'s API, I'd like to use the latter. On the other hand, I'm wary of how it's based on assumptions on q++'s implementation.
What I meant is to do something along these lines when one needs inner products of computational vectors:
Does it make sense?
Of course, if you don't know in advance the computational vectors, then this doesn't work, and the only way is to "extract" the bitstring out of them provided you know for sure the vector is in a computational basis. This can be done by simply pulling out the components >0 (they may not be exactly 1 due to precision issues) from the correct locations. So perhaps a "zket2bitstring" function may be useful, what do you think?
I've spent some time thinking about this... and my conclusion is that implementing such a function may not be worth it.
My use-case is checking that the Deutsch-Jozsa algorithm is computed as expected. In this case, a bitwise inner product is needed to check the result of the Hadamard transform. And I guess it won't be used anywhere else...
I have after all implemented qpp::zket2dits,

Assumes the state is in the computational basis. If it's not, returns an empty vector. Ideally, we'd return an std::optional, but I prefer to still keep compatibility with C++11.
Great thank you !
I'm not a big fan of std::optional, so returning an empty vector seems good to me. I'd rather test result.empty() than write (*result)[0] later (one test vs many uses).
Have you considered using Eigen::VectorX<idx> instead of std::vector<idx> ?
I thought about, and decided to use Eigen types only for quantum objects (i.e., states, density matrixes etc. that require linear algebra operations). This was due to the fact that I preferred the other objects (e.g. vectors of probabilities/indices etc.) to be compatible with C++ standard iterators (and now ranges), so you can do algorithms from the standard library on them. Unfortunately Eigen doesn't support the C++ standard iterator interface; even something as simple as std::find(Eigen_matrix...) won't work...
Actually it does ! Since version 3.4 (rc1 has just been released)
https://eigen.tuxfamily.org/dox-devel/group__TutorialSTL.html
And there's a lot of good things in this version ! I like the new slicing and indexing API: https://eigen.tuxfamily.org/dox-devel/group__TutorialSlicingIndexing.html
Finally! That's good to know! I think I can consider it for a major release (i.e., qpp 3.0), since it may break down the current API.
