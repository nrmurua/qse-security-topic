Hi, there are gradient errors when I want to train with keras using  tfq.math.inner_product(). I think you can only define gradients for tfq.layers unlike in tf.math where there are no such gradient issues.  Is there a fix for this? Thanks
I have used inner_product and fidelity in gradient operations before, so I imagine something else is going on in your code that is causing the errors. As an example, here is a simple code that takes the gradient through inner_product (and uses other tf ops) and successfully optimizes the fidelity:
Output:
Thanks I see you can achieve this with tf.GradientTape(). However, if I just use tfq.inner_product as as layer in a keras model, say analogously instead of keras.layers.Dot(), it says the gradients don't exist (the model also works with any tfq.layers in place of the inner product).
Well everything you can do with model abstractions you can do with GradientTape (or at least, most things I think). That being said, you can also use tfq.inner_product in layers. Here is an example with no gradient tape, that uses classical layers and TFQ layers and successfully minimizes (it is a weird model, but it is just to demonstrate that the gradients can successfully flow through inner product and other classical and quantum layers). You won't be able to just substitute keras.layers.Dot() due to the input differences, but it should be possible to use IP in layer/functional models. I think it might just be a problem in your code.
Output:
Ok, thanks for the help!
