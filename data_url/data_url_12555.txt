I am trying to create a QML model using PQC but as an output, I want to retrieve the whole state.
For instance, if I am working on a 2-qubit circuit. Then the final state is a superposition of |00>, |01>, |10>, and |11> eigenstates. I need the estimated probabilities of each eigenstate as the output. Currently, PQC supports only separate measurement over each qubit.
I also tried using State layer thinking that it can serve my purpose. Because it does return the complete final state. But it seems like it doesn't work the same as PQC. Can it take an input and run it over my_QML_circuit and finally return the output states? Can State layer contain trainable parameters?
My code looks something like this:
Thank you.
Ok there's a lot to unpack here:
I need the estimated probabilities of each eigenstate as the output. Currently, PQC supports only separate measurement over each qubit.
If you are only operating on a small number of qubits or only want a small subset of the eigenstates, it's possible to supply projector operators  to PQC and Expectation layers. One can isolate the probability of getting |00> on qubits a and b by doing something like:
PQC supports any cirq.PauliSum which covers more than just separate measurements over each qubit (unless I'm misinterpreting what you mean here). You can specify any operator you want on any qubits you want using the paulis. Using this method, everything is differentiable (since you aren't doing anything you couldn't do on a real QC). I will again emphasize that this is not scalable if you want all of the probabilities from the state and will only work if you need a small number of them.
Can it take an input and run it [tfq.layers.State] over my_QML_circuit and finally return the output states?
Can you help me understand what you mean by this ? I'll guess that you just want to be able to compute the state vector of my_QML_circuit with some parameter values from tensorflow placed inside of the symbols. If that is the case I'd suggest checking out some of the snippets here: https://www.tensorflow.org/quantum/api_docs/python/tfq/layers/State .
Can State layer contain trainable parameters ?
Yes and no. Since calculating the full State vector as a function of the circuit parameters is not a process you can do (very quickly) in real world QC we did not provide differentiability for this layer. So if your compute graph incorporates a tfq.layers.State layer inside of it, there is a requirement that you either define a @tf.custom_gradient for that layer OR ensure that gradients are not needed to flow backwards through that layer in order for your training to take place.
Does this help clear things up ?
Thank you, Michael, for clarifying my doubts in such great details.
What I am working on is a QML model where both the input and the output are quantum states. I have figured out a way to encode the input quantum state, now what I need is a way to retrieve the output state back or at least the probabilities of each eigenstate. I believe a real quantum computer will be capable of giving us estimates of such probabilities by taking multiple shots over the quantum neural network circuit. And yes, I do want to work with a larger set of qubits. I wrote 2-qubits just as an example.
You are right about using the Expectation layer for computing the required parameters. It never struck me. Thanks for that. Similarly, I found out that Pauli Sum can do the job as well. But, they are not scalable.
Another way to go could be defining my own custom_gradient for the State() layer. I will work on it and let you know if I reach somewhere.
Thanks a lot.
