There are a lot of extra tools that DifferentialEquations.jl provides that I want to be able to use (e.g. sensitivity analysis and optimal control, which I would prefer to do directly, instead of having them wrapped into something specific to QuantumOptics.jl).
Looking at some of the timeevolution objects, it seems those objects are not really abstracted away and easily available to the user. How receptive are the developers of QuantumOptics to introducing:
If this is acceptable, I might be able to volunteer making these changes myself. It would drastically expand the problems in which I would be using QuantumOptics.
I really like this idea. I've actually been thinking about this myself for a while now, but never got around to actually doing it. I'm not sure yet what the best way to do this is though.
ODEProblems: We could implement a constructor for each of the timeevolution functions, e.g. SchroedingerProblem, which is internally constructed when schroedinger is called, but which is also part of the public API. This gives users easy access to the ODEProblem. One question I don't have an answer to yet are the custom container types (such as Ket) that are used to store the results. Currently, we use a SavingCallback which wraps the vector in a Ket. This callback needs to be passed to solve though, so if you construct a SchroedingerProblem you input a Ket but get a Vector as output if you just call solve on it. Not sure how to deal with this. One option might be to unwrap everything internally so you just end up with pure Julia vectors and matrices. So if you solve with schroedinger you get Kets, but if you construct the SchroedingerProblem you get Vectors. This would also give you as much "freedom" as possible, but you can't use other QuantumOptics functions on the output. I'm not sure how to deal with this yet. Any ideas?
ODEFunctions: Depending on how we do ODEProblems this might be already given because you can access the ODEFunction from prob.f. Otherwise I think it's a good idea to make dschroedinger, dmaster, etc. part of the API.
It would be awesome if you could take a stab at this! Let me know if you need help.
Concerning the wrapping in Ket: that might not be necessary, as the DiffEq library is supposed to work on any object that defines a few simple interfaces. Are there any immediate argument against that?
"Simple interfaces" might have overstated it a bit, but here are a few more details https://discourse.julialang.org/t/juliadiffeq-with-custom-types/16294
Are there any immediate argument against that?
Getting DiffEq to work directly on QO types would be ideal. Not sure how easy it is to do that. It's easy enough thinking about the simple matrix*vector Schrödinger equation, but there are other cases such as semiclassical and also lazy operators such as the FFTOperator which aren't represented by matrices.
Just for reference, after #306 gets merged you can just do something like this:
That will give you an ODEProblem with standard Julia arrays. The upside is that you don't have to worry about performance here. The downsides are that you can't directly work with QO types afterwards (though you can just do something simple like ψt = [Ket(b,u) for u ∈ sol.u]). It also won't work with non-array data types (lazy operators, FFTs), but you can just rewrap the state u as Ket before calling dschroedinger to get around that (that's how it's done internally).
Would it be possible to change the signature of dschroedinger(u, Data, du) to something more standard, like dscroedinger!(du, Hdata, u)?
@PhilipVinc certainly. It's not part of the public API yet, so changing it should be fine. Maybe we should add it to the API afterwards. Also, if we go for this option it might make sense to add some convenience function that defines the derivative function needed by DiffEq for you, rewrapping things as Ket if necessary (for non-array types).
After #312 gets merged, the syntax will be
It's actually rather simple to work with non-data operators as well. You can just use the recast! function (which is also used internally). For example:
That's a pretty solid way to do this as it works with any type QO.jl implements and it will be just as fast as the functions from timeevolution. The only difference to calling timeevolution now is that there is an additional SavingCallback rewrapping the result in a Ket. I'm not sure if you even want that if you want to work on the ODEProblem directly.
The only thing that might still be missing now is a neat way to define such an ODEProblem.
@Krastanov What do you think? I'd actually prefer this approach here as we don't have to worry about performance - as opposed to what we started in qojulia/QuantumOpticsBase.jl#16
I think it is important for both features to be implemented. Julia is supposed to provide zero cost abstractions and these recast! and dscroedinger! functions, while extremely useful, look more like some C code. In particular, I am writing some code that on the fly decides the best way to simulate something (e.g. jumping from stabilizer formalism, to pseudo-probability stabilizers, to kets and density matrices). I want it to work seamlessly with QuantumOptics and to be natural to write ODEProblems without knowing the internals of QuantumOptics (I claim recast! is not natural and it is a sign of code that would be difficult to interoperate with and that implementation details are leaking out instead of being abstracted).
So, while the example from the last comment seems like a great improvement, it falls short from a truly natural interface like:
On the other hand, my complaint can be sidestepped by simply implementing multiple methods for dschroedinger!. Especially given that I have not had time to work on qojulia/QuantumOpticsBase.jl#16
What is your opinion on this suggestion:
The reason I believe point 3 is important, is because it drastically simplifies the ODE code in this library, which makes it much easier to use the advanced features of the ODE solvers. One extremely important example is autodifferentiation: currently it is extremely painful to get autodifferentiation to work with QuantumOptics, which makes optimal control tasks unnecessarily difficult to write (exactly the thing that julia is promising should not be a problem). Another reason is so that we can run QuantumOptics on a GPU. These and many other interoperability features will become possible once the interfaces for point 3 are implemented.
I am excited to see #312 merged. If my point 3 above works, it would just make recast! unnecessary (which would make it easier for autodiff and GPU use and saveat callbacks).
As a side note: things should already run on GPU. The .data type can be anything, so CuArrays can also be used. Dispatch should take care of the rest so that the appropriate mul! methods are called. Autodiff is another story, though. As you say, this won't just work on QO types.
Hi!
What is missing for this to be merged? Is there any way I can help with it?
Is there a way to do the same for a time-dependent Hamiltonian? If I run something similar:
I get the MethodError:
@oameye You're missing this part where we wrap the update function in an outer function that "recasts" the raw vector to a Ket.
I think we may want to consider having our own "Problem" type rather like Bloqade is doing.
That way we can have a solve method that takes care of messy things like recasting.
@amilsted Thank you! Looking into the source code worked out for me. I needed this to utilise the ability of threading with OrdinaryDiffEq.EnsembleProblem. Ones this feature is implemented, it would be cool to explain the functionanlity in the docs.
