The existing GCP documentation details how to set up a GCP VM to run Cirq circuits with qsimcirq, but only covers CPU-based execution. Now that GPU support is available at the qsimcirq level, we should also document how to use it on GCP.
Key details to cover:
CC @jrossthomson
CC @cognigami
It would also be helpful to have a diagnostic that a user can run to determine whether GPU simulation is actually enabled for qsimcirq (some script that fails with certainty if run on a device without GPUs or appropriate drivers).
It would also be helpful to have a diagnostic that a user can run to determine whether GPU simulation is actually enabled for qsimcirq (some script that fails with certainty if run on a device without GPUs or appropriate drivers).
@peterse you can run pytest qsimcirq_tests/qsimcirq_test.py -k gpu_sim to check this. test_cirq_qsim_gpu_simulate will pass if the GPU is available; otherwise, it will be skipped.
Copied from the external thread:
If you're using qsimcirq v0.10.2, it's not using GPU - we haven't cut a release with the support yet.
Once qsimcirq GPU support is released (or if you're using the prerelease version of qsim), you can run
from the command line to determine whether qsim is using GPU. If GPU is not in use this will print None, and if GPU is in use it will print the module descriptor for the qsim-GPU pybind module. This descriptor is not None, and looks something like <module 'qsimcirq.qsim_avx2' from '{...}/qsim/qsimcirq/qsim_gpu{...}'>.
One final note: because GPU support requires local compilation on a machine with GPU support, a fresh release of qsimcirq isn't particularly helpful here, since anyone using GPU is presumably already cloning from master.
Sorry for the runaround here!
This has been resolved by #435. Further improvements to the GPU usage process are currently tracked by #430 and #450.
