Currently our C++ op implementation for circuit simulation does this:
This works fine for smaller systems. but if you want to simulate larger systems and have limited memory this breaks down. Doing something like this:
Would be friendlier on memory for larger number of qubits. While this may not be as fast as the first method it would certainly be more memory efficient. What do you think @jaeyoo and @zaqqwerty ?
#221 is Related. Rotosolve optimizer would benefit greatly from second parallelization scheme
This is resolved. We opted to go with Our original method for circuits with < 25 qubits. With circuits with more than 25 qubits we opted for the new method.
Hi @MichaelBroughton, I am trying to test this behaviour by running 500 slightly different circuits (each has 6 qubits) in a batch. But it seems that only one thread is actively running. I have attached the test code below.
Test code:
Hmmm you are compiling a @tf.function with no input. Chances are the autographer is just compiling this down into a constant expression. I ran this on my end and changed a few things and definitely saw full use of all threads. Could you try running this version and see if you still only see one thread being active ?
Thanks @MichaelBroughton . I think now I understood it. The issue is actually in tfq.convert_to_tensor(circuit_list), which takes up a significant chunk of the time, and the actual execution of circuit in layer is fast and makes use of all the threads. But because the long conversion time which uses only one thread, the later spike in multi-threads usage got unnoticed.
