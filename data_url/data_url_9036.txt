In the last section of Getting started file it seems that the logical errors counter is assuming that the correction in surface codes must find the exact errors that happened in order to fix them.
But this is not the case for surface code. as long as find the right path between 2 vertexes that caused the error, you can apply correction even if you do not know the exact path, and can just apply any path between them.
Therefore, difference between original error and assumed error by Minimum Weight Matching, is not the key to show the rate of ligicals errors.
You can read about it in This Notes page 45 for example
Where do you think that it's making this assumption? I can confirm it's not making that assumption, but I'm interested to know any misleading sentences.
The reason it isn't making this assumption is because all that's really being counted under the hood is how many times the matched paths go over an edge marked as flipping the error frame. Specifically it cares whether the count is even or odd. The marked edges form 2d surfaces splitting the 3d matching graph into two connected components. So it doesn't matter what path is taken through the graph when matching detection events, only whether that path crosses between the two connected components and even or odd number of times.
In more complex situations, such as performing S gates using twists, it may no longer be the case that there are two connected components. But the path independence property will still hold, though often only for paths with lengths less than the code distance.
It seems that for surfacce code benchmarking, you are using:
which is using the following function that is trying to predict the error that happened using the minimum weight method.
this function might find an error chain that happened and is different from the real original error, but also a possible solution.
and then count_logical_errors will see that they are different, and claim it to be an error.
What am I missing? I also might be wrong, but I actually did not understand how your answer match what's happening in the code
That function is doing is running a simulation, separating out the detection event data and the observable-flipped data, then asking the decoder to predict the observable-flipped data from the detection event data.
Maybe the key thing I'm failing to communicate is that in a memory experiment there's only one observable bit per shot? The decoder is only predicting whether or not the complete final logical measurement of the observable was inverted. It's not separating the observable into many parts and predicting each part individually, which must then individually match what occurred in the simulation.
You don't get one bit per measurement added via OBSERVABLE_INCLUDE, you get one bit per observable index. Consider this circuit:
This circuit does not produce 5 observable bits (due to 5 rec targets), it produces 2 observable bits (because there's an observable index 0 and an observable index 1).
In more complex experiments there may be multiple observables. For example an experiment that prepares a Bell pair, preserves it, and then measures it, would have two observable bits instead of one. And a 7-to-1 S state distillation factory would have perhaps 8 observables.
Closing this as working as intended, unless there's some specific improvement to make to the docs.
