It would be a very useful feature to be able to reason about "Circuit structures". Supporting this feature would mean that we would roughly need to be able create an op to do the following:
My current thinking is that we do something like this:
have the following inputs:
Outputs:
What do people think ?
Going to leave open for discussion with @vprusso and others.
Is this something a first timer could work on or does it require a deep understanding? (I have a few PRs on cirq, but no further background in QC (though I'm about halfway through Nielsen and Chuang) or ML/TF, though a bit of compiler experience which may or may not be relevant).
This would take a bit of know-how in making new TF ops. You would also need to understand how Cirq circuit serialization works pretty well in order to design an op that can go from a circuit to a meaningful structure tensor and back again. This issue has been open for a little while now so if you're interested in trying you're hand at it feel free.
It looks like there's already a from_tensor operation that gives you the entire original circuit. So now I'm confused what's needed here. Is it that that operation doesn't work well, or that it's too slow for extracting basic information, or something else?
Also need to consider how this works with subcircuits.
It looks like there's already a from_tensor operation that gives you the entire original circuit. So now I'm confused what's needed here. Is it that that operation doesn't work well, or that it's too slow for extracting basic information, or something else?
What we want is some kind of op like this one that lets us do:
So in this snippet we want the ability to go from a serialized cirq.Circuit that lives in a tf.Tensor to a bunch of numbers in a different tf.Tensor that uniquely represent that circuit (and be able to go back again). We want this to be a high performance operation that you can do in the compute graph ( C++ ops only). Like our append_circuit op we know that you could just call from_tensor add on the circuit you want and then re-serialize the circuit, but that takes way too much time to execute. Because our append circuit op uses C++ it can parallelize, it's compatible with things like @tf.function and in general is the go to way to do performant operations on tf.Tensor objects in compute graphs. We want those some perks with this "circuit structure" op.
Also need to consider how this works with subcircuits.
We are pinned to cirq 0.9.1 right now which doesn't do subcircuit serialization. It's likely an important consideration for future proofing the implementation, but I don't think it'll be a concern at this very moment.
Does this help clear things up ?
Yes, it clears up why from_tensor isn't an answer. So now I'm trying to understand exactly what needs to go into the structure grid and why we want this. Let me try to offer my best interpretation from some playing around and looking at the code and see if it's anywhere close. I'll number my assumptions so we can talk about them individually.
Assuming all that is correct, I'm a bit lost on the gate alphabet. So are we storing the gate itself in the array that we create, or are we storing an integer that represents the gate in some lookup table? If the former, I don't understand the point of the alphabet. And if the latter, would that lookup table be included with the tensor, or is that something that would only be maintained by the user?
Also for e.g. CNOT gates, do we need to store whether q is the control or controlled qubit? Does the design above account for that?
Right, those are all good assumptions. What we want ultimately is to have an op that would support the workflows used in places like: https://arxiv.org/pdf/2005.10811.pdf ( see figure 2 ).
Assuming all that is correct, I'm a bit lost on the gate alphabet. So are we storing the gate itself in the array that we create, or are we storing an integer that represents the gate in some lookup table? If the former, I don't understand the point of the alphabet. And if the latter, would that lookup table be included with the tensor, or is that something that would only be maintained by the user?
Probably the latter. I imagine somewhere the user will have to specify what values they want specific gates to be converted into so they can have some idea of what is in the tensor the op spits out.
Also for e.g. CNOT gates, do we need to store whether q is the control or controlled qubit? Does the design above account for that?
We probably do need a way of distinguishing control vs target for multi qubit gates. The design above does not account for that. Given the complexity of this "encoding problem" it might be worthwhile to tinker with different designs and approaches in pure python and find something that everyone can agree on before moving onto making a full blown C++ op.
As it stands this issue is pretty open ended and we aren't at the point where we know exactly how things should look yet, so any design proposals or mini-python api designs are more than welcome
My initial thought is we'd want to hard code the gate alphabet into an enum so it's consistent. User doesn't have to maintain a mapping. The tensor can be serialized and shared without also having to share a mapping. Multi-qubits gates can be accounted for by different enums. So enum gates { NONE=0, X=1, CNOT_CONTROL=2, CNOT_TARGET=3 } etc., and arrange it such that a global bitmask lets you identify all the other parts of the gate easily MASK[X]=0xffff; MASK[CNOT_CONTROL]=MASK[CNOT_TARGET]=0xfffe;. This wouldn't account for custom gates, but IDK if supporting them is a big need here. They can be decomposed for now, and maybe we add support for an optional custom gate lookup in the future. Thoughts?
For the parameter array, should those all be a specific length, or variable based on the gate? Or, consistent within a circuit based on largest gate, but variable across circuits? Is there a maximum number of parameters we'd expect on any gate? Multi-qubit gates would end up needing those arrays duplicated across all the [moment][qubit] cells they apply, but that's probably fine.
The other question I have is, should this array representation be alone its own tensor, or should it be packaged with the original proto too? The way I'm picturing it, if these are two separate tensors, then users would have to pass both of them around everywhere: the proto to send to simulators, and the array to analyze. So instead, should it be a single tensor that contains both?
