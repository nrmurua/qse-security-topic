If one of the source files contains characters such as "‚àÇ" (in a comment) make test will fail:
It seems to me that there is no harm in allowing arbitrary characters in the comments if the compilers can handle them. Also, using UTF-8 as the encoding should not affect the ASCII symbols.
Works fine: make -j 1 ARCH=local VERSION=sopt
Fails: make test
I agree, especially now that we're using python 3 exclusively which is unicode native by default. It should be enough to drop the following line:

or rather, replace C with C.UTF-8 or en_US.UTF-8 instead, since we still want any generated error messages to be in english for when people are reporting them.
... and tools/conventions/analyze_src.py also needs to be nerfed.
üëç  should I create the pull request?
Yes, please go ahead and prepare a suitable PR.
I hope I understood correctly that the check in tools/conventions/analyze_src.py is not necessary at all. #996
if the compilers can handle them.
Maybe this is a bit late, but are we actually sure that all compilers can handle unicode comments?
if the compilers can handle them.
Maybe this is a bit late, but are we actually sure that all compilers can handle unicode comments?
UTF-8 unicode is specifically designed to not contain any ASCII characters (0-127) in a multibyte sequence. We are therefore safe if we stick to \n as a newline delimiter and UTF-8 encoding. Meaning that the compiler can safely treat everything after an unquoted ! as a single character byte ignoring the encoding completely and be able to find the line termination.
the compiler can safely treat everything after an unquoted ! as a single character byte ignoring the encoding completely
True, but are all compilers actually behaving this way?
resolved with a4c43d8
