TBD.
The move to use the Rust SDK Python bindings necessitates making at least a small part of pyQuil async. The Rust SDK itself is async, and so the bindings it produces are also async. Thus, wherever the bindings are used, we’ll need some async.
For example, the pyQuil function quil_to_native_quil() will call into the Rust SDK using the async function compile() (or whatever we end up calling it). So within quil_to_native_quil() we need to handle the async call. This is usually done by prepending the call with await which then requires the function itself to be defined with async so now we have
Fair enough. Now, anything calling quil_to_native_quil() must also now deal with the async nature of the function. And so you backtrack through the call stack, making more functions async def and using await. In this example, this change causes at least
In theory, those changes seem reasonable. If you make core parts of your code async, that will naturally reach out towards the public part of the API. To get a feel for how the API/async changes would affect pyQuil users, we can rework the example code from the documentation. The first example we see in the docs is
Making this async and self-contained (i.e. the user can copy-paste this into an interpreter and run it without issue) looks something like
The addition of the two await isn’t so bad. But the extra work to get async to actually run (with async def main() and asyncio.run(main())) feels super awkward, and likely something we would hear complaints about.
I think the primary desire here is to have the change be as transparent as possible to the users. We can’t get away from the fact that we need some async somewhere, but maybe we don’t need to async-ify the current interface (or maybe we do, and users should just deal with it.)
So, alternative (1) is to provide async counterparts to the API. For example, where we currently have QuantumComputer.compile() we would add QuantumComputer.compile_async(). The async stuff is then opt-in (from an API perspective — it will still be async under-the-hood).
A more pleasing API might introduce an pyquil.api.async module, and a get_async_qc() helper function. Under pyquil.api.async you’ll find the usual QuantumComputer, AbstractCompiler, &co, but with async. Then the original QuantumComputer (under pyquil.api) would present the sync interface (but under-the-hood it’s using the async version).
Alternative (2) is to not present any async API. The pyQuil API is unchanged, but, again, under-the-hood, the async is managed automatically by running the async functions on a asyncio.AbstractEventLoop held by the respective objects (and optionally provided by a user).
Yeah — how does asyncio work with multithreaded workloads? The benchmarking folks do a lot of multithreading, and anything we change shouldn’t make that more complicated for them.
The top-level get_qc function accepts an optional asyncio.AbstractEventLoop (or creates one itself) and passes it down through helper classes so that program translation, execution, and fetching results.
I think it makes sense to convert everything that uses async to be async, as it's supported by JupyterLab without any extra configuration and all of these functions are preforming some sort of out-of-process or off-host I/O.
I also don't think it makes sense to have counterpart sync functions because that would require manual asyncio.get_event_loop management which is on it's way toward depreciation. asyncio suggests using one top-level asyncio.run which seems to be best managed by the user.
We were able to create sync versions of all the qcs-sdk-python async functions in qcs-sdk-rust#252, so we don't need to async-ify pyQuil.
