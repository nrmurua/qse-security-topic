First of all, thank you for creating this, it is incredibly useful!!! Not the least as a reference for other code writers!
I am the developer of QuantumClifford.jl, which implements some useful Clifford circuit tools. It does not have the elegant Pauli frame tracking that enables your ridiculously high speeds, and generally, it has not been hand-tuned, but it is fairly fast and it has its uses elsewhere ;)
I made some recent improvements in the inner-loop methods (the Pauli multiplication method) that were inspired by your work and wanted to see how it compares against stim. I was surprised that in one (very restricted) micro-benchmark the pure julia code was faster than your C++ SIMD code.
Here is the example:
The results are basically the same, except for larger (really large) Pauli's, julia is faster by a factor of 2ish. I do not know whether this is just some slowdown caused by the python interface. Or it might be due to the version of gcc/llvm that was used to compile stim.
Just to be clear, I am not claiming that my julia library is generally faster: its aim is somewhat different from the aim of Stim and I am certain that, holistically, Stim blows everyone out of the water for the task for which it was designed. But given how crazy fast Stim is, I assumed that you would want to know that there might be still some more optimizations to be done. I can try to dig up the machine code that julia compiles if that would be of use. Here is the julia code performing this operation, which is fairly similar to your C++ code.
Very cool!
In the C++ benchmarks for the latest commit, doing a 1M multiplication takes 9us which is four times as fast as what you're seeing python side (could be machine do differences though, also these are inplace mult benchmarks):
It might be that there's an additional copy being made as part of giving the result to pybind? It is almost certainly relevant that stim implements its out of place multiplication using a copy then an inplace multiplication, which requires iterating the memory twice.
I do not know how to run the perf.cc benchmarks. Could you point me to the documentation for the framework used -- I can then run comparisons on the same machine?
The in-place julia code takes 27μs on my device
It's just custom code included in the project. You run it with cmake . then make stim_benchmark then out/stim_benchmark.
On the same machine now, for 1M qubits, in-place multiplication in Julia is 27μs, while in Stim it is 15μs. It seems any other delays are due to the python interface. This was fun!
I will close this issue as it lacks direction. Hopefully the minor slowdown in the python interface would be a fun micro-optimization.
