Link to Colab: https://colab.research.google.com/drive/1g6BFapSuG0-WCQzxlrDsPKCcmaGemB9f?usp=sharing
Please use emails connected to the GitHub account for request - I'll accept it.
Notebook is related to my graduation project and I don't want the work to go fully public yet.
I created a custom layer with quantum circuit in quantum_circuit() to represent 8x8 image - 4 readout qubits with two H gates, connected to 16 qubits by ZZ**(param) gates for each of 4 readouts. (8x8 extension of what can be found in MNIST Classification example.
The image is divided into 4 4x4 pieces, each connected to single readout qubit.
The data is represented similarly to what can be found in the example (X gate if normalized_color > 0.5).
I attached a softmax layer directly to quantum one for classification using tf.keras.Sequential model, since I want to extend it further - up to all 10 digits.
I compiled the model and I tried to fit it.
The model should start to iterate over given number of epochs.
Epoch 1/10 is displayed, but nothing else happens.
for both:
No GPU involved.
When I try to run the notebook with compressed_image_size = 4 everything works as intended. I've checked my quantum_circuit() and it seems to be working as intended for version 8x8 - it generates circuit with desired architecture.
When I tried to trace down the error I found out that:
data_adapter.py:
enumerate_epochs() yields correct epoch, but the tf.data.Iterator data_iterator has AttributeErrors like
in
and:
I'm not sure if this is relevant.
colab-jupyter.log
There is really a lot going on in the code. Do you have any ideas where I could place my breakpoints and focus? Is there any easier way to trace the source of this bug?
I've just sent a request (using my @google.com email). Will be able to look more closely into things once you can share the notebook with me. I will be sure to not share any details of the code here and just focus on the bug itself.
Thanks for the interest!
I've just given you the editor permissions. If you have any questions or concerns fell free to ask.
No problem. So at first glance I think you've solved your own problem in your comment on the side there.
The compressed_image_size is too big with a value of 8. Quick review on quantum circuit simulation:
Simulating n qubits takes 2^n memory. So looking at your code:
compressed_image_size=8 => compressed_image_shape = (8,8)
Then in the line: qubits = cirq.GridQubit.rect(*compressed_image_shape) => len(qubits) == 64
Mathing that out really quick gives us a state vector with 2^64 complex amplitudes where one amplitude is 64 bits means you requested 147 Exabytes of RAM. A bit too much :). In general simulations cap out around 30 qubits unless you've got some serious hardware and you might be able to push things up to 35-40.
My guess is that the malloc call didn't fail gracefully on that size which is a bug we should probably look into. Does this help clear things up ?
Yeah. This totally explains the behavior. This was the first thing that came to my mind, but I couldn't find any errors related to hardware, so I assumed everything was correct.
Nevertheless some error message would be really helpful here. It shouldn't pass silently :)
Thanks!
I wanted to contribute and add the error handling, but I got lost in the codebase... ðŸ¤¯
Anyway... I finished and published the thesis. It even got highlighted by IEEE and there is a followup paper presented on CORES'21 going public soon.
https://www.researchgate.net/publication/353074126_Simulation_of_quantum_neural_network_with_evaluation_of_its_performance
I hope you enjoy it.
In case of questions or anything, please contact my by the GitHub email :)
That's awesome! Always happy to see more publications making use of TFQ!
Any updates on this issue @rafalpotempa or can it be closed?
