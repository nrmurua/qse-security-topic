When starting to build a toolchain which fails somewhere in the middle and then continue to build it with different flags or when changing the flags after a successful build are the setup script and the arch/ files sometimes inconsistent.
Example when starting with a toolchain-provided OpenMPI and then restart/continue with the system-provided one (linking against the toolchain-provided OpenMPI, but not adding mpirun to the $PATH in the setup):
Yes, the toolchain certainly has some rough edges....
Are you still planing to replace it with Spack or should we continue to invest in it?
To it's defense, the toolchain does cover many use-cases. So, maybe Spack will never fully replace it?
Yes, I still plan to replace it with Spack. Nevertheless, reporting bugs is a good way to figure out what we have to test the new toolchain for.
Wrt plans for Spack: They've introduced a new feature called "Environments" where they can pick up a package configuration (packages to install with defined options) from a working directory without further intervention. Meaning: we can write a spack.yml with the required dependencies depending on what features the user wants in CP2K and then do a spack install environment + module load.
The only drawback to our current toolchain will be that Spack will install more than what we're currently doing (they usually only use the system compiler by default, nothing else).
The only drawback to our current toolchain will be that Spack will install more
So, how much longer do you expect a Spack installation would take compared to the toolchain?
Is there a way to call Spack several times and have it only install a few packages? Then we could make each of these invocations a Docker Layer and take advantage of the build cache.
Is there a way to call Spack several times and have it only install a few packages? Then we could make each of these invocations a Docker Layer and take advantage of the build cache.
Would be possible I guess, but at that point I'd leave the dependency resolution (which is currently somewhat replicated inside the Docker files) and rebuilding decision to Spack instead and start caching the Spack packages instead. Docker's cache will then still be used to determine whether or not to invoke Spack at all (based on a COPY spack.yml ...).
It's a trade off solution. I agree that the toolchain Dockerfile is not beautify. However, getting the Spack build cache to work within the CI will probably require even more hackery. I also don't expect much of a speedup because the Docker build cache already kicks in most of the time. Hence, I'd suggest we start without modifying the CI and see how far we get.
It seems most of the problems have been mitigated by a942b54. While there are certainly still cases where a toolchain re-run failes, I think for now we have done all we can. Since this issues is no longer actionable, we should close it. Do you agree @dev-zero?
Not yet unfortunately. When trying to upgrade a toolchain with a942b54 to the latest master I see the following in install/toolchain.env (build not yet finished):
The environment I used to run it did not contain /users/tiziano/work/cp2k/cp2k/tools/toolchain/install/cmake-3.18.0/bin in the PATH, hence the toolchain scripts must have gotten it from the already installed version of cmake.
For cmake it doesn't matter since the new path overrides it, but it illustrates that the toolchain still picks up data from previous versions of packages.
