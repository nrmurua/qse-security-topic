The apply method of the TensoredFilter's use of parallel map uses too much memory copying large result objects in each thread.
Running this on my laptop (which has 32GB Ram, 6 core CPU) for a Result object with 144 2-qubit experiments in it, it spawns 6 Python subprocesses and each processes memory usage increases to over 20GB of ram usage. I have to kill the python process to get it to stop since it will never finish.
Parallel Map should either not be used here, or used in a way that it isnt copying the full list of raw_data to all processes and over allocating available memory.
One thing that can be done is to abandon parallel_map and directly create a multiprocessing.Pool that gives us a bit more flexibility. For example, if there are large objects that are constant between all workers and needed on each worker process we can avoid the serialization overhead by leveraging initializer and initargs. We'll still end up with each worker process having a copy of the data, but it copies the data but done at fork (or spawn) time without having to serialize and deserialize to pass data between processes at runtime.
