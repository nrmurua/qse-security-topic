Description of the issue
While testing QED-C's Shor benchmark code, I happen to replace the measurements with identity gates. The circuit I use is attached in this issue: shor_15_11.json.gz.
How to reproduce the issue
Would result in a norm of 0.99993384
Cirq version
More context on where I use this: in a procedure similar to sample_state_vector, choices = np.random.choice(len(probs), size=shots, p=probs). cupy errors out when probs is not normalized: https://github.com/cupy/cupy/blob/32a88a52a4629693033b8670f9eac28db863f24e/cupy/random/_generator.py#L1089. np.allclose has a rtol of 1e-5 by default.
Is this a precision issue? Did you try using simulator = cirq.Simulator(dtype=np.complex128) instead?
Yeah, with simulator = cirq.Simulator(dtype=np.complex128), I got norm 0.9999999999998377 (though qsim, the one I mainly use, doesn't have a complex128 simulator). I was worried that since float32's precision is 6 digits, and according to https://stackoverflow.com/questions/39134956/accuracy-of-float32, for 1e-1 to 1e0, the max relative error should be 1e-8. But given that the circuit has sufficiently large number of gates, an error of 1e-5 is expected, I suppose.
I think for this issue, I can sleep well with just renormalizing the probabilities. Sorry for the false positive.
But given that the circuit has sufficiently large number of gates, an error of 1e-5 is expected, I suppose.
Though I can't explain why the bulk of the gates don't accumulate to an error of 1e-5 (with the norm of 0.9999989), yet the identities at the end cause it to go >1e-5.
