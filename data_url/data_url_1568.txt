Description of the issue
We should avoid these kind of tests if possible, the probability of this test failing is larger than desired.
@asmuzsoy
https://github.com/quantumlib/Cirq/pull/4424/checks?check_run_id=3315034286
Cirq version
v0.13.0.dev
Okay, that's a fair point. Perhaps I can rewrite the test using a random seed?
Well, seed kinda works, but it is an easy way out to make the test pass but the problem is that then it is hard to interpret it - how would you set the bounds then?  We could say that for that given seed 12324, we know exactly the sequence of answers the prng will give in prng.random() and prng.choice() so we will know that the number of 1s is 44. Is that a meaningful test? Maybe, but we don't know too much about this seed, it kind of raises some extra questions that make the test less focused.
The thing we want to test here really is that whether the noise_model gets applied or not. I would just choose a deterministic noise model, it's simpler to reason about it:
Alternatively you could pass in a Mock noise model and test whether the act_on() method was called with the exact state vector...but I think that might be a bit overkill here, especially that that requires understanding the internals of how the Simulator() works...so again, takes away from the focus of the test...
@MichaelBroughton I fixed this a while back, just increased the accepted range by a few sigmas.
@daxfohl Can we close this then?
Marking as pre-1.0 until we can verify that this should be closed.
Yes, go ahead and close. It's not as thorough of a fix as what Balint suggested, but it's one in 900 million flake. 
