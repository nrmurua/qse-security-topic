I am trying to run the qaoa algorithm with the 'mlpack' optimizer. The cost function is not getting optimized. NLopt is working fine though.

How to fix this?
Thank you!
Can you post the code snippet ( or is it just the python qaoa_example.py with the optimizer string set to mlpack?)?
Most of the mlpack backend solvers require OptFunctions that produce gradients. By default the qaoa algorithm will use vqe without gradients. We have new support as of a couple of days ago to turn gradients for vqe, but have not tried it out for qaoa. My guess for your issue is that mlpack is looking for the gradients and not getting them.
I am trying qaoa_example.py with the optimizer string set to mlpack. is it possible to get gradients using parameter shift/finite-difference?
Hi @aswanthkrishna,
A couple of suggestions:
XACC does give you an option to select a specific optimization method via the mlpack-optimizer   key, see https://xacc.readthedocs.io/en/latest/extensions.html#mlpack
For example, a gradient-free optimizer such as Simultaneous Perturbation Stochastic Approximation (SPSA) can get your QAOA optimization iteration going:
It's worth noting that it may or may not give the same stepping quality as Cobyla (the default of nlopt)
I hope that it helps.
QAOA now supports computation of gradients with parameter shift. The example in python/examples/qaoa_example.py illustrates how to use it. Add the key "gradient_strategy" with value "parameter-shift-gradient" in the dictionary that has the parameters for the algorithm. Also, be aware that this example starts from random initial parameters, so parameter shift may not be enough for convergence.
Great! thank you @danclaudino  @tnguyen-ornl  @amccaskey
