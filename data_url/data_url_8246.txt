Travis only runs 5 test suite in parallel. Each tested commit have 6 to 8 test suite (add 3.8 and 3.8 for mac) and each test take 20 to 30min. So if many of us are working at the same time, automated test can take a few hours to run (like today).
I propose:
While this will probably not speed up for when only one PR is done, it should help when many are lined up.
(2) could be done by adding new marks for the tests. @jakelishman, will this cause conflict with your unmerged PRs.
For point 2: adding marks right now will cause conflicts, but if #1181 gets merged then it'll be much simpler.  The main issue is that a lot of the testing structure has changed for tests up to test_mcsolve.py alphabetically, and so in general the tests are just not the same.
The principle is pretty straightforwards - just like #1181 introduces a requires_cython mark, we would add uses_cython, uses_mkl and uses_openmp marks.  These would be even simpler to add than requires_cython because unlike it, they don't require any test-generation logic at all.
The change would simply be to add them to pytest.ini, mark the requisite functions and then change the pytest invocation of the specialised test to pytest -m "uses_cython" or whatever.  As far as I'm aware, the only parts of their codebase which modify their behaviour based on whether Cython is available is QobjEvo.  The other parts (like brmesolve) just don't work if Cython isn't there.
The MKL tests would become very short; by my reckoning, MKL is only used by steadystate and countstat.  OpenMP is much more pervasive, as sesolve, mesolve and brmesolve all use it, and parts which depend on those are generally the slowest tests.
The short tests could just become pytest -m "not slow"?  That's not super speedy, but it takes about half the time, maybe.  If you want more, then a good starting point is pytest --durations=0 which will tell us which tests are the slowest (perhaps that was what you already did when marking the slow ones?).
I am hoping to save more time with "not slow", about a 3~4x faster. Maybe I will remove 3.6 to save more time. Other test that need mark will wait for #1181 for now.
So I ran the tests with pytest -m "not slow" (on my current #1181 branch) with profiling on, so I've got the following additional slow tests that we could mark to cut down the total time.  Here are the tests that took longer than 1 second:
We need to be careful not to remove too much, we need keep the tests meaningful, with a good coverage.
The first 2 are quite rare cases and could be marked as slow. Or at least one of them since they are quite similar.
Tests in QobjEvo could be rearranged to limit the number of compilations.
Yeah, definitely there's no point running tests that aren't really testing the package properly.
I would hope that if we're much more aggressive about converting time-dependent lists into QobjEvo objects inside mesolve, mcsolve and sesolve (or the class-based versions of them), we could significantly reduce the amount of testing that needs to be done with them.  Most of the tests of time-dependent formats would then occur in the QobjEvo tests.
We could still test all the configurations of the solvers without too heavy a time penalty.  If we only use a small number of different time-dependent operators, we can compile them all only once, and have pytest manage the resources through shared fixtures.  That would really cut down the run times, especially for the current "slow" tests.
Another avenue for cutting down run time is if we could merge say the MKL and OpenMP tests into one Travis job - the setup time for one job is about 2.5 minutes, and that's before any tests have run at all.  I would hazard a guess that having MKL but not OpenMP is a pretty rare case (maybe more common on high-performance clusters where people submit single-cpu jobs?).
Our tests could still be shortened, but right now the pytest.mark.slow marker does allow for a reasonable run time without sacrificing too much, and we have reduced our Travis load to only 5 concurrent tests by merging MKL and OpenMP tests.  With Coefficient on dev.major we have a lot more scope for re-using compiled coefficients, which are typically the slow parts, but for now I think our testing is much faster than it was when this issue was first opened.
