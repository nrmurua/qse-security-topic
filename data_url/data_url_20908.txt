The README.md specifies a META file. Have we got any specs for that? I assume we want to track roughly the information in the liboqs docs files and the liboqs OQS_KEM and OQS_SIG structs.
Format wise, I would suggest Yaml, because it is both easy to read and easy to parse.
This suggestion assumes that a single META file will cover multiple parameter sets.
I'm not completely certain what the purpose of these files is, but taking the OQS files as a starting point seems reasonable. Two points;
We will put the SHA3 hash of output of the testvectors into META, to be able to verify consistency between platforms.
I like the idea of using Yaml for the metadata.  @cryptojedi and I had talked about a directory structure which would have different parameterizations in different directories (crypto_kem/kyber512, crypto_kem/kyber768, etc.) which would necessitate different Yaml files for different parameterizations.  But we should probably plan for metadata about different implementations within the same Yaml file (corresponding to directory structure crypto_kem/kyber512/clean, crypto_kem/kyber512/avx2, etc.).
Perhaps a block like:
But I'm not sure what exactly should go there. For example, license should already be specified in a LICENSE file in crypto_kem/kyber512/avx2. Actually, it's probably a good idea to have this to also specify if some item can't run on a certain target (e.g. don't test crypto_kem/kyber512/avx2 on ARM).
I would not include sizes in the Yaml file; those area already in api.h and I don't like duplicate information.
I don't like duplicate information, but I also like machine-readable information, and Yaml is more machine-readable than C preprocessor macros.  Basically I'm thinking of code transformation tools that will generate stuff around PQClean implementations, and they may be easier to do if they get keysizes in Yaml metadata rather than having to extract it from C preprocessor macros.
@joostrijneveld proposed verifying the META.yaml specified sizes with what's specified in api.h.
By the way, if we want to do any form of linking, then #define macros are not sufficient to keep those values in the code...
Actually, I forgot that api.h of course is included. For FFI interfaces, you will still need to copy the constants into your file; but you need to (manual or generator) work there anyway, because you'd also need to define the namespaced (e.g. crypto_kem_kyber768_clean) function names in your bindings definition, per scheme and implementation.
but you need to (manual or generator) work there anyway, because you'd also need to define the namespaced (e.g. crypto_kem_kyber768_clean) function names in your bindings definition, per scheme and implementation.
Not necessarily; isn't this covered by the "All exported symbols are namespaced with PQCLEAN_SCHEMENAME_" requirement? For the PySPX FFI we avoided copying these constants by creating functions that expose them, but including/requiring such functions may be out of scope for PQClean (and is off-topic in this thread, in any case).
And for OQS we had a data structure for each scheme that exposed the constants.
For our purposes, yes, a hash of the expected test vectors would be okay.  But there had been a desire expressed at the workshop last week to have a collection of test vectors, in a reasonable format.  I don't think a hash would not sufficiently helpful to someone else wanting to check their own implementation, because they'd have to reproduce our hashing operation as well.
I've written a script that verifies a specification for YAML files. It may appear a bit complicated at first, but it allows you to write a specification of the yaml file and then recursively validates it. The specification should pretty much speak for itself. The script should give clear errors.
As an example, this is what the META.yml files should look like from now on:
