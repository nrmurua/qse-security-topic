Until recently, the program below would not schedule "rym90" in parallel with "ry90". After  recent changes to scheduler.h the "wait" seems to be ignored and the instructions are scheduled in parallel (scheduler=ALAP, scheduler_uniform=no, not resource constraint).
The log file does show the following, which may be related:
The program:
It seems that this can be worked around by waiting on all defined qubits instead of just a subset
It should also work even when you are waiting on single qubit.
@wvlothuizen you can still get the old behaviour by setting the option:
opt_name2opt_val["scheduler_post179"] = "no";
@jvansomeren can you please look into it.
I already tried
opt_name2opt_val["scheduler_post179"] = "no"; 
but that does not seem to help
The current semantics of wait {set of qubits} value is that dependences are created only for the operand qubits with a duration of value (multiplied by a cycle length in nanoseconds). Somehow the old semantics got lost in the update; what was it?
In the old semantics, calling kernel.h function "void wait(std::vector<size_t> qubits, size_t duration)" with duration=0 would finish operations on  before other gates are performed, also see the opening example of this issue. This seems to be in line with the only documentation I could find (in openql.i) states "inserts explicit wait on specified qubits.".
I don't necessarily object to changing the semantics, but I do think the change and the new behaviour should be well documented.
the intent is not to change this semantics. essentially wait instruction with duration = 0 is a barrier.
Wouter wrote about the documented semantics of wait:
inserts explicit wait on specified qubits
while he seems to imply in his remarks that he expects it to be:
insert explicit wait on all qubits ignoring the specified qubit list
I am confused now  on the meaning of the list of qubits given to the wait.
The quoted semantics implies that the rym90 on z gets in parallel with the measure (ALAP)
or the y90s (ASAP), since the z is not mentioned in any wait qubit list.
This behavior is what was implemented in the pre179 and is implemented in the post179 scheduler.
So I fail to reproduce his specified behavior.
When the wait semantics would be:
insert explicit wait on all qubits ignoring the specified qubit list
then the rym90 would not be in parallel with anything.
But this is not the behavior of the old and of the new code
so would mean a change of semantics.
I don't have a clear idea on what the semantics were exactly, neither on what they should be. I just had the problem that I had a program that used to work, and stopped working after the new scheduler became part of OpenQL.
In this particular program the wait was present to force the scheduler to move all subsequent gates into a different bundle, and that worked. The intended behaviour can now be obtained by waiting on all qubits.
So I do have a work around to get what I want, but I do need program changes to obtain that. Other users using the wait in the same way might see their code break by the new version.
@wvlothuizen I just tested the code snippet you posted as:
The complete test is available on branch bug/222-wait-semantics in test_wait.py with the name test_wait_barrier_222.
This generates the following scheduled cqasm for ALAP:
which is as per definition of barrier/wait as we are not waiting on q[5] so it is scheduled ALAP.
Similarly, the ASAP scheduled cqasm is:
which is also as expected as we are not waiting on q[5] so it can be scheduled ASAP.
Just to verify my original reason for submitting this issue, and to point more explicitly to the problem, I reran my test program from 2 old commits:
Still working:
Build en run:
completes without error
Failing:
Result:
The failure occurs in tests/cc/test_cc.cc::test_qec_pipelined() because the 'rym90 11' conflicts with 'ry 90 *'. Note that the CC backend uses cc_light_schedule() here, not cc_light_schedule_rc(), so resource constraints are not taken into account.
Between the two commits quoted, nothing significant was changed to the test program or the CC backend, but the scheduler was changed extensively, as can be seen by a 'git diff 9dc5f2b'
Regarding the scheduled qasm, I recently found out that that is generated by a scheduling function (i.c. program.h::schedule) that is different from that used by the backend, so there may be differences with respect to the actual scheduling.
PR #228 documents and tests variants of waits and tests. IMHO we can close this issue.
no problem, since the original test program works with a small change, and I also recently verified a large part of our pycQED test suite to still work (with the CC backend that is)
