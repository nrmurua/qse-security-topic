Currently when we do a loop.create_task in execution.py we essentially end up executing each electron sequentially since all of our executors are synchronous.
We might want to rethink whether we want these electrons to be executed in parallel - using multiprocessing, or even multithreading, or we want to do a "submit" of jobs and retrieval of result later - using asyncio.
Both the solutions have downsides - multiprocessing will create a separate process which is not worth it if your function's execution is going to happen on a different machine, and asyncio will need each executor.execute function to be async aware - which means changing all the executor plugins we've created and the ones that the user will create (which I don't think is a desirable way).
Using multithreading may be our best bet but it also comes with problems of race conditions and such, we may want to have a longer discussion in how we want things to be.
