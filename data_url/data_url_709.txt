Suppose I have this:
auto m_16x16 = gt.MODMUL(a, N, 4);
I hope there is another function to achieve this:
I want to get diff=0. That would be so nice to work on those 2x2 matrices on each of the 4 qubits.
I understand it would be very difficult to process an arbitrary unitary. But, for this particular gt.MODMUL(a, N, n), is it easy for you to implement it?
@DevelopDaily Unfortunately that will imply that the modular multiplication is a product operator, like A \otimes B \otimes C \otimes D (for e.g. 4 qubits), which is not the case. Unless I'm misunderstanding the question...
I will open another issue before I come back to clarify my question because the clarification of my next issue will help this one.
You're right. That cannot be written in the tensor product as I asked for.
Now, I will rephrase my question to make a weaker statement. Can gt.MODMUL(a, N, n) be decomposed to cx gate and single qubit gates such as ry and rz in an efficient way?
Sorry for being vague on "efficient". Let me explain myself. My question is motivated by this idea championed by Delft University. So, I know any unitary matrix can be decomposed to those three gates. Since they use the eigenvalue decomposition, the algorithm will still overwhelm the memory and CPU of a regular PC. Well, that is perhaps the best they could do, considering they have to deal with an arbitrary unitary.
I am wondering if you have a shortcut to a decomposition algorithm just for this particular unitary gt.MODMUL(a, N, n), say when n=32. It is understandable that it will still take a lot of time. But, can it be done with 32GB of memory?
@DevelopDaily This is what quantum compilers do (using e.g. Solovay-Kitaev or newer more efficient algorithms). This particular gate can definitely be written "efficiently", see e.g.. https://arxiv.org/pdf/1611.07995.pdf. I don't think I'll add any "compiler" support in qpp, as I want to keep the compiling part separated from the engine/executor (qpp). We can add more compiling support in staq though.
Interesting info. Thanks for the clarification!
