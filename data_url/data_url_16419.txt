Performing a standard VQE-qUCCSD calculation for a chemical system requiring ~20 qubits takes many dozens of hours using Qiskit for several computational platforms and simulators. By comparison, performing RHF, MP2, CCSD,  DMRG or FCI for a system of 20 spin-orbitals on a classical computer requires ~1 minute. This severely slows down research on quantum applications in quantum chemistry and materials science.
The issue appears to be related to the fact that Qiskit parameter evaluations are performed in serial, rather than in parallel. Qiskit contains optimizers that are taken straight from SciPy and do not support parallel gradient evaluation. These optimizers need to be rewritten to enable parallelization of the evaluation of gradient components.
Such an issue can be evaluated with the code shown below involving the simulation of a molecule requiring 22 qubits with VQE-qUCCS, which has greater than 1400 parameters and takes ~300s (5 mins) per evaluation on a simulator:
{'qiskit-terra': '0.14.2', 'qiskit-aer': '0.5.2', 'qiskit-ignis': '0.3.3', 'qiskit-ibmq-provider': '0.7.2', 'qiskit-aqua': '0.7.3', 'qiskit': '0.19.6'}
VQE (and the other variational algorithms in Aqua) already support generating circuits together for parallel gradient computation. The following parameter sets this up.
max_evals_grouped (int) – Max number of evaluations performed simultaneously. Signals the given optimizer that more than one set of parameters can be supplied so that potentially the expectation values can be computed in parallel. Typically this is possible when a finite difference gradient is used by the optimizer such that multiple points to compute the gradient can be passed and if computed in parallel improve overall execution time.
We tried initially with a flag to do the parallel gradient computation or not. On bigger molecules, with their larger circuits, it was easy to run out of memory hence we switched to this. Here it in effect says how many points on the gradients to cluster (group) together in a set, and pass to the backend to run in one go, such that they can potentially be run in parallel where the backend supports this. Aer has various parallel execution capabilities for this.
Thanks woods-ibm.
I've altered the code to make use of max_evals_grouped on a 64 core machine via the following
However, this has not improved the timing of each parameter evaluation. Is this the correct way to use the keyword given the number of cores on the machine?
The parallel options for Aer are listed here https://qiskit.org/documentation/_modules/qiskit/providers/aer/backends/qasm_simulator.html  Does it look like the cores are being used?
Also perhaps use the faster Aer snapshot mode by setting include_custom=True on VQE to have it use this custom Aer capability automatically or explicitly set expectation=AerPauliExpectation() .
Bear in mind too each evaluation can comprise a list of circuits and its more at this level the parallelization is done. Grouping more evals adds more circuits into each 'experiment' that is executed. I.e. we execute a list of circuits, which is normally one eval, but that list can grow when you have max_evals_grouped since we will concatenate them all together in a single list for execution.
This issue is highly related Qiskit/qiskit-aer#874
Thanks  woods-ibm.
I've tried the include_custom=True option and that hasn't helped.
Thanks for pointing out the related issue Qiskit/qiskit-aer#874
Ok, with only 1 shot on the qasm simulator maybe the speed is comparable. Chris would know more what the difference is. But 1 shot is not going to do much in practice in sampling from the output, for each evaluation, to do a real ground state energy computation whereas the AerPauliExpectation will return an ideal result for each evaluation.
I will note that this PR qiskit-community/qiskit-aqua#1206 should speed things up a little as well once it is merged. A performance plot is shown in the PR.
Is there a profiling anywhere to show that it is the optimizer that it is the bottleneck here?  1400 doubles should not be too bad for the Fortran based solver used in the example.
During gradient computation a number of points in the locale are computed (one in each dimension). Since each point needs an energy evaluation, and many of these are needed to do a gradient, the idea is to be able to do these in parallel when doing simulation. So rather than computing say 100 evals in sequence for 100 points to do a single gradient, do these in parallel if possible when using the classical simulation. So the bottleneck is more the simulation needed than the optimizer itself.
This is rather old now and things have changed considerably over the years since, with primitives being the main execution point now. VQE still supports max_evals_grouped, which though must be now set directly on the optimizer being used. This will result in a call to the Estimator with a list of points - at this stage what and Estimator does with that in terms of execution is down to the provider, that supplied the primitive, and its implementation.
I know I indicated this in the past too https://medium.com/qiskit/improve-the-performance-of-your-multi-circuit-simulations-using-qiskit-aer-with-dask-clusters-b4e47fad6cf0 which could be of interest.
Anyway since this is so outdated, and with algorithms also being imminently moved out of Qiskit, I am going to close this. If you feel its something that is still needed maybe a new issue that is more contemporary - maybe more geared towards Aer and the Aer primitives if that's the environment/parallelization desired. With the Estimator its also arguably easier nowadays to roll your own VQE so maybe there is some way to parallelize things more as an end user by having something more custom.
