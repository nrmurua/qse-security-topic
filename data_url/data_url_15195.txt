Right now transpiling large circuits at optimization_level=3 can be dominated by the consolidate blocks pass, the majority of that time is spent constructing the unitary of the block using the Operator class. There is a fair amount of overhead in the operator class as it's designed to be more general. For the compiler pass we just need to work with the raw matrix which we can get directly from the matrix. A similar thing was done for the 1q decomposer ~2 yrs ago: #5909
For some concrete data, running:
yields the following profile

Similarly scaling up to 100 qubits with:
returns:

In that case ~40% of the transpile() time in the profile is spent constructing Operator objects (between consolidate blocks and unitary synthesis).
Lol apparently I already opened this in #8779
