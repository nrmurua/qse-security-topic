Whilst trying out several deployment scenarios I found that both the qengine and qfusion layer crash on more then 30qubits. qunit & qunit-qfusion are not affected AFAIK. I found this to happen on both ARM64 and AMD64 builds.
For scaling purposes it would be nice to be able to go beyond that point. As 30 qubits only occupies Â±4% of the runtime memory of a 340 GB Memory host.

Used scenario: k8s with compiled qrack container https://hub.docker.com/r/twobombs/qracknet

Reproduce steps:


Thanks for opening the issue! I'll try to look at this tonight.
No, this is not a planned limitation. While the memory required would be unattainable for the QEngine and QFusion types in particular, the software was designed to accommodate 64 qubits, should sufficient resources ever be available. QUnit with or without an intermediate QFusion layer Schmidt decomposes its representation, such that it will tend to allocate much less RAM, until it approaches "full entanglement."
I'll spin up a cloud VM tonight with sufficient resources tonight, and I'll try to figure this out.
I'm working on a big enough instance, and I notice that QEngineOCL doesn't seem to crash. It's just QEngineCPU that does. Are you seeing the same?
I have a clear but general idea what the problem is: QEngineCPU uses a state vector wrapper interface that QEngineOCL doesn't need/use. This is probably a small bug, once I find it.
(By the way, the wrapper is there to let QEngineCPU use an optional sparse state vector. Usually, this would be an ineffective optimization, but that's not true when used with the QUnit layer. Though, it adds complication that I now realize I need to test in cases like this, like >30 qubits.)
@twobombs, Please see #235.
I see that without OCL the ./benchmarks command gets stuck and never passes the first test and is hard to kill, even with -9. With OCL I see that qubit 32 and on causes segfaults and sigaborts.


With OCL qubit=31 seems to work a bit: that process also hangs without OCL.
My guess is that this is due to our use of signed literals in other places where we should be using unsigned literals, or else ambiguity between 32 and 64 bit integral types. I've noticed, this can lead to for loops that don't terminate, because loop control variables overflow before exceeding the maximum iterations.
A quick, temporary fix might be to swap out bitLenInt with a 64 bit unsigned integer type, rather than an unsigned char. This is easily done, in two places where it's defined, one for host code and one for the OpenCL. Not sure if this will work, but there's a good chance. It's not an optimal solution, but it might be a temporary fix, and the extra RAM used as a result will probably not be really significant. I'll be able to try this tonight. I'm hindered by lack of a 64 GB personal machine, at least, but breaking the 32GB barrier would hopefully get us scaling up to as many qubits as you have RAM for.
I know you see the lack of RAM utilization, but consider using Qrack::QUnit in general, with or without a Qrack::QFusion layer, as QUnit is designed as a major optimization on top of QEngine types. The worst case, of maximal entanglement, will ultimately require QUnit to allocate about the same amount of RAM as QEngine types, but you often just won't hit this case, if you implement efficiently. We've tried to cover a lot of cases where representational entanglement can be avoided, and even the arithmetic methods can often avoid fully entangling their registers and flags, now. You might get better speed with less RAM needed than you think. I am looking to ultimately debug the QEngine types, though, and I'm actively working on it.
I'm thinking about it, and I don't know whether left shifts from unsigned char only promote to 32 bit integer types, signed or unsigned. You'd hope that, in the ideal, they would promote to a 256 bit type if available, but (since it basically isn't ever) the largest native integral type for the system, otherwise.
If the kludge I suggested works, of changing the bitLenInt definition, the ultimate fix is to cast to bitCapInt before (unsigned) left shifts, in all cases. This might actually not be that hard. I'm speculating, but I have some prior experience, to think this.
The amount of RAM is just something I look at when benching to see delta's ( between layers and OCL usage, amount of qubits starting the benchmarks ) Full entaglement tests and results are scheduled when qubit scaling works, when the compute blocks with entanglement are orchestrated, data collected, mixed, displayed, etc. But that will require some more work by me on my container image(s).
The reason that I'm hawkish on memory usage is because of NUMA node bandwith constraints. It is a scaling thing. However, assuming that a char promotes itself to a 256 bit type this would increase the memory usage, but when the constraints of an unsigned char are just too narrow for a left shift using a larger type before the shift occurs might indeed be a good thing in more then one way, IMHO it would save the time needed for a translation to a different type, and because that var needs that space in the first place there is no real memory 'loss'.
@twobombs The work so far tonight might already fix the OpenCL engine. I'm still hanging on QEngineCPU, but not on QEngineOCL. If you get the opportunity to test QEngineOCL, it'd be good to know whether you're seeing the same.
Never mind. The timings aren't right on 31 bits. The problem is likely with exceeding 32 bit integral type accuracy, but it's going to take more work. I might need a RAM upgrade for my personal machine.
@twobombs The last push I made on the PR was to experiment, but it actually might do the trick, at least for the QEngineCPU type, and it points the way to the OpenCL fix. It's seems fairly obvious, all considered, that the problem is 32 bit integer overflow. For the past couple of days, (and apparently for a long time,) I was getting hung up on some simple confusions about typing differences in OpenCL versus C++(11).
In the C++ standard Qrack uses, (and I think every later C++ standard to date,) firstly, 64 bit unsigned literals are ULL, unsigned long long. (Duh, apologies.) UL, in effect, are the same as U. I assume this is due to C++'s legacy from before the time when 32 bit integral types were standard. So, in "host code," I'm trying to pull all bitCapInt literal 1 instances behind a ONE_BCI definition, which is generally 1ULL, unless we're on a pure 32 bit system.
OpenCL, on the other hand, is a younger standard. In a historically fortunate position, its standard defines uint as unsigned 32 bits and ulong as unsigned 64 bits. Correspondingly, it's bitCapInt literals should be UL for 64 bit systems and U for pure 32 bit systems. I gave the OpenCL program the corresponding definitions, as with the C++ code.
There's one more catch, which you personally might be aware of, but other people referencing this issue might not be: there's a max global RAM allocation for any OpenCL device. (Check it with clinfo.) Generally, it's not necessarily maximum system RAM. Further, there's a maximum global allocation, which is typically even less than that, even for a CPU. Basically, maybe depending on the dimensionality of the physical RAM chips on your (SO)DIMMs, or maybe your mapping hardware or firmware, a system isn't necessarily capable of making a single allocation across the entirety of system RAM. So, just because you rightly know you have the RAM, does not mean a single QEngine can glom it, or even half of it, (at least for now).
I'll be playing with the limits of my biggest personal machine (and more cloud instances, if necessary) to develop some confidence as to whether I have the OpenCL fixed. At least, I have a bit more confidence, already, that we have a fix for QEngineCPU.
Code works, bounces into OCL limits @ 33qubits ( using 33% or 147 GB Memory )
OCL with 34 qubits gives this:

Without OCL qrack @ 34 qubits works, fills 68% (256GB) memory

Initializing took quite some time: latency explodes at those levels. Some hardware related scaling trouble also arises, which is to be expected as you can see this already occur at 30 qubits.
At that point it might be practical to lower the amount of iterations by a magnitute ( or 2 ) ....
Both qengine and qfusion have been tested and worked.  Performance was similar. [edit: qfusion seems to have an edge]

thanks for fixing this !
Thank you for reporting and testing, @twobombs! Couple of notes, to close this:
Unfortunately, I found out, your 33% figure exceeding the OpenCL limits sounds about right. If it were 25%, you might just barely hit or miss the typical maximum allocation. Can you squeeze an extra one or two qubits out of OpenCL on the system? Depending on the implementation, sometimes, yes. However, this is the intended limit of the standard, in my understanding. If someone is using a GPU, while I've found that you can run those extra 1-2 qubits, it's essentially a wash, and not efficient, because my system, for example, seems to end up double-allocating a redundant representation on both general heap and in device RAM, which costs you at least 1 qubit globally and can't be electrical power efficient. (Also, it's not safe, for totally general use of Qrack, to allocate a single state vector greater than somewhat shy of 50% of available RAM, so it's really a total wash at best, but you could restrict your use of the API to basically single bit gates and controlled single bit gates, to stay below the limit.) If you have a GPU on the system as well, you're better off running at least two engines, one for GPU and one for CPU.
Also, I opened a new pull for a controlled phase gate edge case optimization, last night, in which I accidentally included the work for this issue. However, conveniently, Benn ended up reviewing this for code standards and other factors last night. So, we're all good to merge that branch for both parts!
(See #236.)
