Using a tapered PauliSumOp as the input to a VQE results in the following runtime error:
Below is a minimal code snippet to reproduce the issue:
I would expect that the VQE is able to compute the minimum eigenvalue just like for any other opflow operator type.
A simple solution would be to make the z2_symmetries argument of TaperedPauliSumOp.__init__ optional. However, this may lead to other unwanted side-effects.
Another possible solution would be to make the TaperedPauliSumOp look more like a PauliSumOp (at least in this context). But I am unsure how to achieve this given the __init__ call which is raising the problem is obtained via self.__class__. And I don't think we should hack the behavior of this internal object.
@ikkoham I am tagging you because (if I recall correctly) you mainly worked on the two-qubit-reduction and tapering code.
Thank you for finding the bug. I have checked only qasm_simulator.
