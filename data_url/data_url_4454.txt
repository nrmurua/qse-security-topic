There are two issues with the DepolarizingChannel.
First, it is not backend agnostic. The unitary of a circuit is calculated during initialization and this operation initializes the GlobalBackend. This is not in line with the fact that gates and circuits should be backend agnostic so that we can easily switch from simulation to hardware (we did a large refactoring for this). For this particular case, I think we can delegate the calculation done with the circuit to numpy which is the fastest choice when it comes to small array operations and is used for all other gate preparations.
Second, there is some performance issue when using multi-threading with qibojit. This can be benchmarked with the following script:
In my laptop numpy takes 0.0005sec while qibojit around 0.7sec. If I force qibojit to use single thread using the enrvironment flag OMP_NUM_THREADS=1 the time drops to 0.02sec. This issue appears only with density_matrix=True.
Multi-threading and qibojit are expected to be slower than numpy when simulating small circuits (less than 10 qubits) but not that slower. This issue affects #702 because it makes qibojit tests noticeably slow.
Thanks @stavros11 for spotting these issues. I propose a solution for the first one in PR #725  As for the problem with qibojit, I have been able to reproduce the issue on my computer. Numpy takes 0.0004 sec, qibojit (multi-threading) 0.57 sec, qibojit (single-thread) 0.003 sec and qibojit (gpu) 0.008 sec.
I have found that similar times are obtained when using the UnitaryChannel with the unitaries and probabilities corresponding to the depolarizing channel defined in your code.
Reopening because the first point (backend independence) of this was solved in #725, however the performance issues with qibojit multithreading should remain. I do not think it is very urgent though.
