If you run the documentation build twice, you will get several megabytes of diff between the two runs.  This is a problem for us deploying to the website, because our website is managed in a git repository, and updates to large binary files need to persist in the .git directory forever.  Our .git directory for qutip.github.io is getting huge as it is (257MB on my machine right now), and it gets bigger every time we change and rebuild.
The biggest problem I can think of immediately is that there are lots of graphs and images in the QuTiP guide that rely on generating random data (the mcsolve guide, for example).  This means that the graphs generated each time are subtly different, but since they're binary files, git mostly has to store a complete change.  This adds up to several megabytes of changes to be stored every time the docs are deployed to the website.
We could do with fixing all random seeds, probably for every single plotting command, so that the pictures are byte-for-byte exact between runs.  This is a separate problem to #1539; that's about setting up some sort of static CDN/hotlinking to heavy resources.  This one is about ensuring that the resources we create don't arbitrarily change every documentation build.
