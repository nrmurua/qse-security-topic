Matrix exponentiation is a costly operation. See [1]Nineteen Dubious Ways to Compute the Exponential of a Matrix, Twenty-Five Years Later∗.
In a quantum optics, the displacement operator is one of the most basic. It is used to create coherent states from vacuum and forms one of the two gates for universal control of a cavity (Displacement + SNAP gates) [2] Efficient cavity control with SNAP gates.
When we want to write an optimisation routine that finds best displacement parameters in a routine similar to the paper above [2], it would be nice if we can compute the operator faster without doing matrix exponentiation as qutip does now:
https://github.com/qutip/qutip/blob/master/qutip/operators.py#L732
I have some notes from a colleague who calculated an analytical formula to compute the matrix elements of the displacement operator without having to do matrix exponentiation [3]:
Displacement_operator.pdf
A PR to implement this in QuTiP would be great. We could first write a _displace_analytical function that calculates the displacement matrix using the Scipy Laguerre polynomial and have it as an option as displace(N, alpha, offset, method=analytical )
Could it also come in handy for optimal control? @ajgpitch
In the paper above [2], the authors use gradient descent to fine tune the parameters of a gate sequence containing displacement gates and SNAP gates to target some Bosonic quantum state.
We wish to do similar things for @araza6 s GSoC project.
The scipy Laguerre polynomial will be very inefficient for constructing the entries because it's linear in various inputs, and we need a quadratic number of entries for it, so it ends up being cubic.  I have some code for an old project of mine which calculates them all as a nice recurrence relation though, which cuts the timing back down to quadratic.
There was an issue on the Google groups recently about something similar: https://groups.google.com/forum/#!topic/qutip/ZtOiO7e9zNk, though the code I supplied there doesn't save the actual recurrence terms, so it would still be cubic (and I'm pretty sure there's still a complex number sign-error bug in it still, because I didn't take very much care when I did it...).
You have to be careful, though, because constructing the displacement operator that way will result in an operator which is not unitary for any truncated subspace.
Here's one proper recurrence relation implementation of Laguerre polynomials.  I made this one for a particular use-case in constructing ion trap Hamiltonians, so the actual recurrence relationship used might not be the best one for this use case, but it illustrates the principle.
Looking back at that (I wrote it two years ago), that code can definitely be sped up.
Does it give the results for a displacement operator in a truncated Hilbert space?  If it just matches textbook results that are computed in an infinite dimensional space then we can’t use it.
No, that's my last point.
@quantshah I will open a PR for this tomorrow
I was just thinking about this again and came up with a good speed up for the truncated Hilbert space.  I can't think of any method to get analytic closed-form solutions for the truncated space, though, so this is just a more efficient numerical method.
First we take the generator of the displacement operator G, such that exp(G) is the displacement operator we're looking for.  G is anti-Hermitian, and so it shares its eigensystem (up to scaling of the eigenvalues) with the Hermitian i G and consequently is diagonalised by a unitary formed of its eigenvectors.  Now S = i G / abs(alpha) is a tridiagonal Hermitian, and with a similarity transformation we can find a real-symmetric tridiagonal T = P^-1 . S . P for some diagonal unitary P (which is easy to calculate).  The reason for scaling out alpha here should become clear at the end.
The main diagonal of T is all zeros, and the first sub- and super-diagonals look like
[sqrt(1), -sqrt(2), sqrt(3), -sqrt(4), ...]
and the diagonal of P looks like
[i, e^(-1i arg(alpha)), i e^(-2i arg(alpha)), e^(-3i arg(alpha)), ...]
Now this real-symmetric tridiagonal form is the basis of Hermitian eigenvalue solvers, and has direct entry points in LAPACK (e.g. ?stemr), which allow us to pass only the main diagonal and the first subdiagonal.  Scipy provides convenient wrapped access in Python by scipy.linalg.eigh_tridiagonal.  This lets us get the full eigensystem of T, which is related to that of G by dividing the eigenvalues by the scaling factor, and multiplying the eigenvectors by P to transform them into the correct basis.
We now have a diagonalised matrix G = Q^-1 . D . Q, so exp(G) = Q^-1 . exp(D) . Q, which is now trivial because D is diagonal.
Putting all this together allows us to use our knowledge of the problem domain to convert the matrix exponentiation problem into a much simpler real-symmetric tridiagonal eigensystem problem, which gets us a nice big speed up, and it's equivalent up to the tolerance of the eigenvalue solver (~1e-14).
Even better for you, a lot of the hard work is done in the eigensystem solver, and I scaled out alpha at the start, so we can do a good chunk without fixing alpha.  That means we can pay the computational cost only once at the start, and then get faster calculations from then on.
If I make a totally fair test, and simply replicate the full functionality of qutip.displace (including creating a Qobj at the end), my method is ~4x faster on small matrices (1 <= dim <= 20) and it only goes up from there (I found it's about ~10x faster at dim = 1000, and beyond that qutip.displace is too slow to bother).
If I store the calculation of the eigensystem, and output an ndarray instead of converting to csr_matrix (and so don't produce a Qobj), then I find speed ups in getting the operator for a new alpha as ~100x for small matrices and ~25x for large ones.  The larger a matrix is, the more the computational time is dominated by the dense dot product at the end.
Code:
While the analytic closed-form solution of the eigensystem is difficult, you may be able to express the eigenvalues as some function of the roots of a constructed orthogonal polynomial - you can create a recurrence relationship for the determinant of the characteristic equation of the system, and that typically ends up producing orthogonal polynomials.  I didn't pursue this very far because it looked difficult, and eventually you'd still need to calculate the eigenvectors anyway, which I didn't have many ideas for.  Unfortunately my copy of Numerical Methods is still in my office, and I can't get to it!
My GSoC project will end up meaning that dense matrices can be happily stored as usable data types within Qobj, so QuTiP won't have to pay the nonsensical dense-to-sparse penalty for this kind of extremely dense system any more.
Ok, the analytic solution for the eigenvalues is just the roots of the probablists' Hermite polynomials.  That was nowhere near as difficult as I thought it might have been.  The eigenvectors might still be tricky, though.
Thanks Jake this is brilliant. This conveniently lets us construct the displacement operator repeatedly for new alphas with the one-time cost incurred in the beginning to solve the eigenvector problem. I think if we fix the Hilbert space cutoff in the beginning of a calculation, this should be fine. Actually, the reason why my colleagues (and even myself) are interested in this is to let optimisation routines run on a series of displacement operations. I suppose now it will become easier to compute gradients wrt "alpha" using some automatic differentiation tool such as Jax which was previously kind of complicated : google/jax#2062
For large matrices (dim > ~500), the dense matrix dot product is still a pretty large cost, but you're still saving a fair amount.  That said, at that kind of dimension, the analytical formula may do you well enough.
If you want derivatives wrt alpha, you should be able to get analytic ones from my method - there's no "black box" numerical work that goes on in __call__, everything is just matrix multiplication.  Given that it appears non-linearly in a possibly large multiplication, though, and I would imagine the derivatives are pretty smooth, you may well just be faster just numerically approximating it with finite differences (I don't know anything about autodifferentiation).
If you're so inclined, you can sacrifice some speed for higher accuracy in the eigenvector calculations, as we can find the eigenvalues semi-analytically.  There are a few places in numpy and scipy that can find the roots of the Hermite polynomials for you (i.e. get the eigenvalues), which will be found exactly wrt double precision (I believe).  You can then call out to the LAPACK routine dstein to get the eigenvectors from the eigenvalues.  dstein is slower than dstemr/dsteqr (which is what scipy uses, I think), but it allows us to supply the eigenvalues, removing some numerical error.  I didn't test that very thoroughly though.
Thanks @jakelishman. I think for now we can use your method and move ahead. @araza6 would like to make a PR about this and probably we should link this discussion in the documentation and make you a co-author (https://medium.com/faun/how-to-give-credit-in-git-commits-ccd6485678c3).
A technical issue here is QuTiP mostly has function based API. This presents lots of problems when you want to re-use objects, e.g., in this displace function. I had proposed to slowly move to classes, eg., Solver class (#962).
A possible implementation here would be making a fresh Displace class  in qutip.operators which would work like this:
@qutip/core-workers What do you think about making some class based operators?
I wouldn't fracture the user-interface like that, personally.  Instead, make the alpha parameter in qutip.displace optional, such that qutip.displace now effectively supports partial application:
Now there's a single entry point for the user, but you get all the same benefits as before.  The user can now do qutip.displace(100) and get a reusable partially applied object, or do qutip.displace(100, 0.5j) if they only need the one number.
This is a smart idea, but even here it starts to break the functional API. We can slowly start migrating to class-based API starting from displace.
I don't think it breaks the functional API at all - in fact it almost makes it stronger, since everything is a "function" at every stage.  This kind of partial application is classic part of functional programming.
Perhaps I don't understand why you want to move to a class-based API?  I'd be quite strongly against having the user have to instantiate classes to do very simple parts like creating operators.  Certainly in Python programming, I don't think a class-based interface is de facto the right sort to aim for, and procedural is much more "Pythonic".
For one, it's a lot of unnecessary boilerplate for simple operations. It adds cognitive complexity for the advanced user to decide "should I use displace or Displacer?", and in the strong majority of use-cases, the operator creation is not a computational bottleneck so we'd be adding it for no gain.  A lot of operators have no meaningful reason to live in a class, like sigmax and so on, so now you have a split between operators that need a class and operators that don't, or you do something really crazy like requiring the user to do
when all they wanted was qutip.sigmax(), qutip.sigmay(), qutip.sigmaz().  Obviously that example is a bit facetious, but what benefit does the user derive from having to write boilerplate to access simple functionality?
All the operators already share a class in Qobj, and things like displace and sigmax are factory methods of Qobj.  What shared functionality do the factory methods possess that means they should be classes?
Hi @jakelishman, I like your implementation but this will sometimes return a Qobj and other times a class instance when you call displace(). I am not in favour of that just out of the principle that functions should be simple and do one thing only as you also point out.
I would say if we do not want to break the user-interface, we keep the same implementation as displace() returning a Qobj (even if internally it calls the faster private _Displace method).
Users who want to use the class anyway can dig in and find _Displace. The use case here for moving to classes is rather specific and related to optimisation/control. We want to compute this operator very fast with multiple values of alpha, independently, on multiple cores (this was why we needed the faster implementation to run a GPU optimisation routine). Of course for sigmax(), or sigmay() we do not have any parameters to optimise and it is overkill to make them into classes. I do not suggest that at all.
I understand the inclination to be functional. It is how QuTiP was written and is supposed to be used, mostly. But one of the arguments for classes is that for some solvers, or operations we needed to re-use information, eg. qutip.piqs or the heom solvers where we had to make classes anyways.
I would propose just having a private _Displace method which is called by displace but not changing the output to be conditioned on alpha. Later on, if we incline a bit more towards classes we can make Displace public. Any other thoughts and opinions? @qutip/core-workers
Ok, that makes sense to me.  As long as you're making its constructor public, it shouldn't start with an underscore (i.e. just be class Displacer or whatever), but other than that, I can certainly go along with what you're saying.
