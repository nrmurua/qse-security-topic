The variable *qubits-required-for-parallelization* is statically set to 19, which means that as soon as 19 qubits is reached in a computation, the computations will be parallelized.
This isn't ideal for all machines. Sometimes parallelization provides gains with values lower or higher than 19. The goal of this issue would be to search for that crossing point and optimize accordingly.
Problems that must be solved in order to solve this issue:
Note that PR #31 allows this parameter to be controlled at the command line.
Hello, I'd like to give this a shot!
A first approach could be a simple binary search over the range of possible values for *qubits-required-for-parallelization* defined by parallelization-limit in config.lisp, and running a benchmark on one - or perhaps a set - of parallelized algorithms at each point in the search.
The first hurdle for this ticket would be deciding what parallelized code should be benchmarked. A first pass could focus on a single thing, and later be expanded to include others. @stylewarning What do you think would be worth focusing on?
Additionally, should this benchmarking happen as part of the entry-point.lisp setup when no command line limit is supplied? Should there be an additional flag for taking a best guess from a benchmark?
I think there should be an option to benchmark-type that allows this measurement to happen and it prints the results to stdout. After that (in a separate PR) it should probably be configurable with a persistent file or something.
As for the measurement to be done, I'd suggest doing some calculation that applies a 1q gate, and an operation that applies a 2q gate, and calculating 0.8*1q + 0.2*2q or something.
