The sigmoid and relu functions under pytorchbackend should use torch.sigmoid() and torch.relu() instead of torch.nn.Sigmoid() and torch.nn.Relu()
python=3.10.8
tensorcircuit=0.6.0
torch=1.13.1_cuda11.6
thanks for the report! sigmoid has already been fixed in the latest commit before and will fix relu as well, should release a new version of tc in the following days
Will be fixed in the next version of tc
