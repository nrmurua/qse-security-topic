I don't speak computer completely fluently but yesterday we had a bar discussion about how to run a single experiment with several computers, for example one for each ATS card one has. I agree, this sounds cumbersome but if the software was written by default to run as a server and the user interactions (function calls, scripts etc.) would be send to it, then one could run an experiment on two computers where one just passes function calls on to the other. This wouldn't necessarily be noticed by the user with a single computer, but opens up some nice possibilities. For our multi qubit experiments this might be a nice solution sometimes. Also, one could measure remotely without using TeamViewer. Data could be both sent back and stored on the measurement computer. In many cases, the fridges have a second computer that could run qcodes. Ultimately a remote computer running qcodes would not be so different from any other piece of hardware in our setups.
Yay bar discussions :) I am very much in favor of the idea of running qcodes on a server that is a completely independent machine, and then connect to that with a measurement computer (or even a laptop) to control it. data storage can then be local and available on the network s.t. the data can be retrieved from anywhere as well.
I'd be a big fan of this!
I'm also a fan üëç , maybe it should also be noted that QTLab already supports this, the Diamond group in Delft used this to connect their different setups used for the loophole free bell test.
@AdriaanRol @cdickel  me no speak no QTLab üíî  (did it pass .py files around, or how did it do it ?)
But no it's not  cumbersome, it does require some infrastructure changes (read, probably not version 1).
AFAIK, this is the future  ‚è≥ !
There's a few things to keep in mind:
But I love the idea.
(and note we live in 2016 and whatsapp manages their billions message per day with one 16cores server, so this is totally doable, just my 2 üí≤ )
