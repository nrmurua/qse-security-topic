Windows tests appear broken
https://travis-ci.com/quantumlib/Cirq/jobs/231923888
it looks like this broke it
#2063
I wonder how the build passed with failing tests.
Error log:
Notice that it stops before 99%.
@dstrain115 has also seen this failure, but on one of his PRs. Based on his description, it seems to randomly come and go. I suspect debugging it will require quite a lot of bisecting and repeating.
--actually-quiet is that burying the actual error messages?
I got a job to fail with the verbose flag: https://travis-ci.com/quantumlib/Cirq/jobs/231970083
It fails right after cirq/work/pauli_sum_collector_test.py::test_pauli_string_sample_collector_extra_qubit_x The command "check/pytest --benchmark-skip -v" exited with 3.
So helpful: "Exit code 3: | Internal error happened while executing tests"
The test after that is cirq/work/sampler_test.py::test_sampler_fail PASSED.
Async code.  Hahah yeah that wouldn't surprise me.
Now it crashed on test_pauli_string_sample_collector_extra_qubit_x (also asyncio).  https://travis-ci.com/quantumlib/Cirq/builds/126289206
Should we disable this test for Windows?
This could be pointing out an actual issue on Windows.  I wouldn't disable unless I know that this is caused by with async code on Windows only in pytest.
Does anyone have a windows device to easily debug this and not have to use travis to make it fail?
I can take a look
After the changes I mentioned in #2041, running tests test_pauli_string_sample_single and test_pauli_string_sample_collector_extra_qubit_z results in TypeErrors of unsafe casting.
Could it be that the errors appear sporadically/randomly due to memory corruption generated by data type casts?
Stale
