Having followed the documentation example, I turned to a more complex circuit, but encounter an error when computing the gradients. Is there any workaround?
Thanks a lot, MatÃ­as.
sympy.version = 1.8
tfq.version = 0.7.2
cirq.version = 0.13.1
and get ValueError: ('custom_gradient function expected to return', 5, 'gradients but returned', 4, 'instead.')
Tricky for me to figure out (never interacted with tf.custom_gradient before) but simple fix: instead of inputting a string for the symbol names, simply convert them to a tensor. E.g. ['alpha', 'beta'] -> tf.convert_to_tensor(['alpha', 'beta']). If you want to know why, see the end. The following code works for me:
With outputs:
Why?
The reason why this happens is because the custom_gradient function calls _eager_mode_decorator which then calls args = nest.flatten(args) on the inputs to the function. This will flatten the list into two elements, resulting in 5 elements when it expects 4 here (hence the error, it originally expected 5 because of the flattening but then later (correctly) only got 4). However, nest.flatten does not flatten tensors, keeping the correct number of elements at the beginning therefore aligning it with the 4 it gets later.
Also, just a note, but if you type python after the three ` you can get nice coloring on the code.
Amazing! Thanks a lot Owen. Will definitely add colors to code snippet the next time ;)
