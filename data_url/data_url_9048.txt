I feel like there shouldn't be a difference between expand_do_circuit(...MR 0 1...) and explicit measure_reset_z...but I'm dabbling in stim_internal, so I am probably missing something. Can you help explaining?
Results in:
Context: I'm building some simulations where I am doing active error correction based on syndrome measurements, kind of like in @Strilanc's teleportation example in the tutorial, except trying to use the TableauSimulator class directly from c++ using stimlib. Everything is okay-ish, except I ran into this behavior while I switched from circuit execution to explicit tableau operations. It gets fixed if I run reset on all the qubits, but that sounds fishy a little bit, the qubits should be in the zero state at the start of the simulation.
I'm using stim v1.5.0.
Oh, I figured out what the difference is - when you pass the circuit, stim resizes the tableau according to the number of qubits in the circuit before executing anything, initializing a proper zero state tableau. However, if you initialize the tableau without specifying num_qubits, and start operating directly on a potentially undersized tableau, you'll get random results it seems. Adding num_qubits to the constructor makes it stable. I can close this, although I don't know if this is the intended behavior or not.
One of the major differences between the python and C++ APIs is that the C++ API does not auto-expand the simulator size in this situation and instead lets you shoot yourself in the foot.
I would be open to contributions that changed that. But they have to not be on the hot path used by the internal code that has guaranteed the size is big enough.
Closing for now as working as intended.
