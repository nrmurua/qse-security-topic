QuTiP is currently incompatible with numpy 1.20.  Tests will fail to even collect with an error such as
and a lot of functionality will break - anything that requires Qobj.eigenstates() for example.
This is because Qobj defines __array__, one of numpy's "array interface" functions, intended for classes that can be safely converted implicitly into an ndarray.  This isn't really the case for Qobj - it loses all sorts of information when you do that, which is why we've maintained the separate Qobj.full() for explicitly getting the dense matrix representation of a Qobj.  This is not to mention that numpy ufuncs probably should not be able to implicitly convert Qobj - I'd strongly argue that np.sin(qutip.basis(2, 1)) should be TypeError, not array([[0.        +0.j], [0.84147098+0.j]]) (like it is right now).  We actually already removed this "functionality" in dev.major.
The most pressing incompatibility is that a few points in QuTiP put a few Qobj into a np.array(dtype=object).  In numpy 1.20, this no longer produces a 1D array of Qobj, but a 3D array of complex.  This breaks Qobj.eigenstates, and prevents test collection due to it being present in states.py::qutrit_basis(), which is called during parametrisation.
There are a two possible ways to solve this, and we ought to release a fix with one of them in a patch ASAP:
I'm personally in favour of "explicit is better than implicit" in this case, i.e. removing Qobj.__array__ and relying on Qobj.full().  As another example along this vein, note scipy.sparse matrices don't implement this either, and they're arguably closer to being safely coerced to ndarray than we are.
#938: feature request for implementing __array__.  This only asks for np.array(qobj) as a convenience, acknowledging the availability of Qobj.full().
#1017: includes a comment on buggy behaviour caused by __array__.  Note that the solution given there (np.asarray(..., dtype=object)) will no longer work with numpy 1.20.
I agree that performing a ufunc like np.sin(...) on a QObj and getting an np.array back is not that useful since presumably one would like a QObj back (otherwise why not just call .full() and work with the resulting numpy array directly).
Likely this is a breaking change for some people, so we should document whatever approach we take.
I definitely agree this should be handled with care - PR #1434 is indicative of how we could get an immediate fix for numpy 1.20, but we already know this will be a breaking change for at least one user (presumably the person who made the original feature request is still using it).  We can also fix QuTiP library code by removing all times we try and put Qobj inside numpy arrays on our end, which would also be a fix.
I've actually mellowed on my total opposition to Qobj.__array__.  Thinking more, I'm not actually super unhappy with the idea of deprecating Qobj.full() in QuTiP 5.0 (not removing until at least 6.0, since it's such a major function) and promoting np.array(qobj) to be the de jure method of getting the dense array out of a Qobj.  Qiskit recently (Qiskit/qiskit#5402) changed their behaviour to do something very similar to this.  You still wouldn't be able to put Qobj into numpy arrays except by doing something like
but probably that's not too much of a big deal.  Leaving QuTiP as it is right now would require that anyway.
My main problem is actually just with allowing ufuncs and other numpy interfaces to act directly on Qobj without an explicit conversion step, because it promotes the idea that it's ok to act elementwise on a Qobj.  I don't think we should allow ufuncs at all - Qobj is not meant to be like an ndarray and ufunc semantics don't make sense.  We can set Qobj.__array_ufunc__ = None and Qobj.__array_function__ = None to disable numpy functions acting on Qobj directly.  Example with this in place:
Alternatively, if people really want to be able to use ufuncs on Qobj, it is possible to define __array_ufunc__ in such a way that we allow only some ufuncs to operate.  Doing this leaves us susceptible to problems interacting with other libraries that implement this, though, beacuse whichever class has the highest __array_priority__ gets to dictate what makes sense.  Unless there's a really clear need for this, I don't think it's a good idea.
For completeness, the rest of this comment is stuff I find out while researching.
These have been special methods understood by numpy since at least 1.3 (2009 - the oldest docs still on scipy.org), and I imagine long before then too.  __array__ is mentioned (and still is) in the documentation of np.array, which is unchanged since 2009 and says that its argument should be
An array, any object exposing the array interface, an object whose __array__ method returns an array, or any (nested) sequence.
and __array_wrap__ is like the reverse - it's for coercing numpy arrays back into this class.  If we were to keep __array__ in Qobj, we should also implement __array_wrap__ for coercion back (something that isn't currently implemented).
At the time and up to inclusively 1.19, the presence of __array__ caused otherwise scalar types passed alone to np.array to return the output of input.__array__(*args, **kwargs), instead of becoming a 0D numpy array (like np.array(1) does).  Taken purely alone, that could make sense as something we implement.  However, this also implies that Qobj should fulfil the numpy ufunc interface; Qobj would be a container for data such that operations like np.sin is the elementwise sin, or (most notably) np.multiply is the elementwise multiplication.  Our Qobj does not fulfil the ufunc interface:
My main concern is point 1: I don't think that Qobj provides a similar object to an ndarray at all.  Right now we do use matrices underneath, but proposed additions to QuTiP such as symbolic Qobj and adaptive Hilbert spaces are compatible with the idea of "abstract linear algebra objects", but do not necessarily have a backing array.  Point 2 is mostly an extension of that: I'm not sure there is a sensible way for numpy's broadcasting rules to be applied to quantum objects as they exist now, even without extensions.
See NEP 13, NEP 18 and NEP 35.
Later versions of numpy allowed greater control over how ufuncs get implemented, which was most recently extended in 1.16 to cover non-ufuncs like tensordot.  These functions are intended for classes to define how ufuncs operate on their data, but implementors should still follow the ufunc spec for broadcasting rules, and a given ufunc should have the same conceptual behaviour (mostly elementwise operations or reductions).  Several libraries implement only these, but not __array__, but given my points 1 and 2 above, I don't think QuTiP should go this route.
You can, however, set these properties to None to unconditionally tell Numpy that the object is incompatible with ufuncs.  I think this might be a good way for us to go.
Provide everything:
Provide some things:
Do not implement anything:
@ajgpitch says:
but numpy 1.20 has ruled out being able to have np.array(qobj) and np.array([qobj1, qobj2], dtype=object)
Sorry, @jakelishman please clarify. Numpy 1.2 does not allow for arrays of objects? Seems strange. I some recollection doing this sometime, I am hoping it's not in qutip.control :/
Object arrays still exist in numpy 1.20, but the behaviour of the np.array() constructor now treats objects that implement __array__ differently.  For example, you can still do
to get an array of objects.  However, an array where every element implements __array__ will be normalised into an N-D numpy array (of dtype=object), rather than maintaining the originally passed in objects.  This means that in Numpy 1.20,
as opposed to previous versions of Numpy, where the last two lines would be
This change purely affects np.array and similar constructors when passed sequences of objects that all implement __array__.  It is still possible to make a Numpy array of Qobj even with Qobj.__array__ defined in Numpy 1.20, but you have to be rather more indirect about it:
The reason numpy does this now is because (my understanding is that) defining __array__ was meant to be a much stronger guarantee than just "it's convenient to let np.array know about this object".  It was meant to be an indication that your class can be safely coerced into ndarray (and potentially coerced back afterwards), and that mathematical operations will satisfy the normal ufunc broadcasting rules, which isn't true of Qobj.  That means that arrays of things implementing __array__ should be safely representable as ndarray, which clearly isn't true for us.  Similarly, ever since Qobj.__array__ was first defined you could use Numpy ufuncs on Qobj, which would get implicitly converted to ndarray and then return complete nonsense, rather than throwing an error like "what you're doing is silly":
(imo that should really be a TypeError if done without an explicit conversion into Numpy semantics).
There is a way around that latter point in modern Numpy - defining Qobj.__array_ufunc__ = Qobj.__array_function__ = None - but it does raise the question of whether we should define Qobj.__array__; we have no intention of implying that Qobj satisfies the general Numpy ufunc interface, and it isn't any sort of ndarray-like type, because it satisfies matrix semantics, not array semantics.  That's the reason scipy.sparse types don't implement __array__.  There always was a sanctioned method for converting Qobj to ndarray - Qobj.full(), similar to scipy's spmatrix.toarray() - so Qobj.__array__ was never a necessity, just a convenience in some workflows.
Given the tools we can use to suppress the ufunc behaviour, the only question we need to decide on is whether that particular convenience (converting a single Qobj to ndarray with np.array rather than Qobj.full) is worth the loss of another (it's now rather faffy to put Qobj into an ndarray).  Both have simple alternatives and I'll go along with either, though my personal preference is not to define Qobj.__array__.
Of course, Python does in general allow users to override whatever behaviour we choose - a user can always define Qobj.__array__ or any of the others themselves, which will monkey-patch QuTiP into doing what that user wants.  Similarly, we could have Qobj.__array__ defined conditionally on a global QuTiP option; pydata/sparse takes this approach, although theirs is a slightly different case semantically because they are trying to make sparse equivalents of ndarray, rather than sparse matrices.
In case it helps this discussion, here is @goerz original request for __array__ which has a good description of and links to his use cases -- #938.
Perhaps we are over thinking this a bit. Some thoughts:
The new behaviour of np.array (i.e. converting items in lists) makes a lot of sense to me and I'm not sure how common it is to want an ndarray of Qobjs (which seems not that useful). Perhaps we just need to fix our own code that is broken by the numpy change and let others fix theirs, unless someone knows of important breakages in third party code?
Implementing __array_wraps__ sounds like a good idea, since that answers my earlier point of how to get back to a QObj.
I don't think elementwise operations on a QObj are completely nonsensical. Sure, they're not part of the algebra of QObjs, but in practice elementwise operations can be very useful while manipulating piles of numbers anyway (e.g. maybe I want sin(theta) in a lot of places in my operator and just want to put the values there).
Thoughts? Happy to try help fix the breakages inside QuTiP.
To me this is a question of what guarantees our primary type makes, so it's quite a big decision to be taken.
I'm not sure I agree that implementing __array_wrap__ is a good idea - Qobj does not support ufunc semantics, and implementing that implies that we're a similar class to ndarray, which I don't think we are.  I don't think np.sin(qobj) should return ndarray or Qobj; I think it should be a TypeError.  To me, we should be rather conservative about adding features like that when there's little tangible benefit - when there's a slightly more explicit alternative syntax, it's better to fail-safe than add potential "gotchas".  The fact that elementwise operations are not part of the algebra of Qobj should be enough of a reason to cause you to have to explicitly ask for it, otherwise it tacitly becomes part of the algebra.
For your point three, if that's the case, I'd argue you're doing something wrong: are you constructing the Qobj before you've finalised your data?  Shouldn't it be
not
As a compromise, we could ensure that all our data-layer types (CSR, Dense, whatever else) will support ufuncs with ndarray syntax; then you could do Qobj(np.sin(qobj.data)) to be explicitly elementwise if you really wanted, rather than absolutely requiring you to produce a full dense matrix.  I'm still not sure I see the use case there, though.
I'm in favour of removing np.array([qobj1, qobj2, ...], dtype=object) usage inside QuTiP no matter which way we come down on this, though.  As far as I recall from seeing it, there no reason to use ndarray over a regular Python list in any of our internal use, and it's rarely (if ever) actually returned out of a QuTiP function.  Given it might cause subtle differences between different numpy versions, probably best to avoid it.  If GSoC applications are imminent, we could open an issue and tag it with "good first issue" to give prospective applicants a potential PR?
I agree with removing use of np.array([qobj1, qobj2, ...], dtype=object) and keep Qobj.array.
But I would not  wait for GSoC applications. A fix for a new numpy version should come sooner than later.
Elementwise operations on Qobj should require a special call. I don't really like np.sin(qobj.data) either. We kept data-layer light and ensuring that they support ufuncs feels going against that and these operations a rarely used. I would prefer the verbose Qobj(np.array(A), dims=A.dims) or adding a linear_map, apply_ufunc, ( or whatever name make sense) method to Qobj and an equivalent dispatched function to data layer.
Oh yeah, that's a good point we should push out the change sooner rather than later.
With how the data-layer classes are implemented, ufunc handling on them wouldn't actually add any memory footprint, but it does add complexity whenever someone wants to implement a new data-layer class.  It's hard to fit general ufunc machinery into the Dispatcher spec, because the ufunc interface is rather general, and we don't want to entirely reimplement numpy.  You also can't dispatch on "unary" / "binary" / "arbitrary" ufuncs as groups (could have been an alternative), because (e.g.) sin has very different performance characteristics to cos on sparse matrices.
If the dispatchers aren't in use, then having a separate function (apply_ufunc) doesn't make a performance difference over defining __array_ufunc__ in a Cython class in speed or memory, but it does make it harder for a user.  Class functions like that in Cython are actually implemented as separate C-backed functions - you can't override them on an instance-by-instance basis, so the instances aren't carrying around extra vtables or anything like that.
One option for user convenience there could be to allow unary ufuncs on data-layer objects and forbid binary+ ones.  We can do that with __array_ufunc__.  It's not so difficult to keep track of the few numpy ufuncs that have f(0) = 0 so different sparse structures can optimise based on that.
Edit: oh, I think I misunderstood what you were saying about "lightness" - do you mean the spec of what they have to support is light, or their memory impact is light?
I mean that the data-layer object is quite minimal and need only a few methods to be defined. If we add ufunc support to Data then all data-layer need to be matrix like. If we want to support symbolic object, or other exotic Data type, it could become a problem. So for something rarely used, I would wait for user to complain that they want some ufunc support, or at least an idea of where the symbolic stuff is trying to go before implementing them. For now, lets use Qobj.full().
Yeah, that's a very fair point.  If you absolutely want to do it in a sparse manner too, there's CSR.as_scipy() available as well that'll let you munge our data however you like.
I'm still not a fan of Qobj.__array__, but happy enough to go with it since it seems everyone else likes it (we should also reinstate it in dev.major).  We can set Qobj.__array_ufunc__ = Qobj.__array_function__ = None to disable ufuncs and other numpy functions unconditionally.  It's unlikely this will annoy anyone, since we've not had a complaint that ufuncs on Qobj does something super weird since Qobj.__array__ was implemented.
We can leave it unless Simon wants to make some more of the case for allowing ufuncs on Qobj, or happy to go with this? (tag @hodgestar.)
We can also give it a day or two for Michael (tag @goerz), but it seems people are generally resolved to keeping the functionality he originally wanted anyway, even with numpy 1.20 changing its behaviour.
This all sounds good to me... I wouldn't necessarily expect ufuncs to operate transparently on Qobj's. I still think my original request of np.array(qobj) being equivalent to qobj.full() would be very useful to have, for all the reasons originally outlinee in #938. Since you're planning to keep that functionality, I'm happy! üëç
Further notes: in numpy 1.20 defining __array__ breaks np.asarray, except in the case where the user explicitly defines np.asarray([qutip.qeye(2)], dtype=object).  This is actually a very very common function in numpy operations; things like np.shape or np.all implicitly call np.asarray without a dtype, which will result in a TypeError:
I think we may be able to get around this with a suitable definition of Qobj.__array_function__, though I am a little worried that we'll keep turning up these knock-on effects of Qobj.__array__.
One major problem is that I'm not sure how we'll define __array_function__ to satisfy this case, without having to manually disable every single numpy function.  We can't have np.asarray() not work on Qobj because that would break parity with np.array(qobj), however we also can't implicitly convert ourselves to an array if we're in a nested sequence, because then np.all([qobj]) will pretty much always be false; it will have implicitly become an element-wise operation, even though the user probably meant to check if every object in the array was not the zero operator.
This isn't just np.all, it's also np.shape, np.any, and several more that make up the non-ufunc interface of numpy.
It seems like there are some subtleties to addressing this -- would it be worth putting numpy < 1.20 in setup.py in the mean time?
We have a patch already written in #1440 - just needs a review before we merge and hopefully push out a new version to conda.
