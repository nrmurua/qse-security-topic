Hi all,
I am trying to run an automatic differentiation in QAOA. It turns out that the gradients are for some reason unsupported by tensorflow in the case where the algorithm is run using the exponential solver.
The code I am using is
and the error I get is
Can you please share any insight about what it the problem here?
Thanks!
If I understand correctly what you were doing I believe that the best solution is just to use directly the minimize method of the QAOA object. You can even set the optimizer and the number of epochs that will be used by passing a dictionary containing the key "optimizer" and the key "nepochs" as an argument. The following code should match exactly what you were doing, using the Adam optimizer.
If you prefer to code it explicitly you need to be careful about the type of variables that you are using when dealing with tf optimization. For example in this line
params = 0.01 * tf.Variable(tf.random.uniform((4,), dtype=tf.float64))
you are implicitly converting a tf.Variable into a Tensor:
Also some qibo methods requires specific types, such as set_parameters in this particular case.
For your particular problem this is the correct version of the code:
Thank you very much for the answer, this works fine.
I wanted to add, however, that I am trying to optimize a circuit in this way because it is part of a much more complicated model. I will probably have some more problems as I keep going, so I prefer not to close the issue until a little bit more of work is done.
Thanks!!
