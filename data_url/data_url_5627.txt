max_parallel_experiments= or precision= do not seem to take effect on simulation performance. Simulation times and memory usage are basically unchanged when tuning these parameters.
Also, when I tried to raise an error with one of the options (like precision='something_that_should_not_work') it did only raise an error when calling .result() (in my example when calling answer).
This has been replicated locally (in my Mac) and also on an HPC cluster running Linux.
For example:
`simulator = AerSimulator(method='statevector', precision='double', max_parallel_experiments=5)
circuits_list = transpile(circuits_list, simulator)
job_statevector = simulator(circuits_list)
print(f"Backend options: {simulator.options}") #to check if it passing the correct info, which it does
answer = job_statevector.result().get_counts()`
I would expect halving the memory usage when comparing results from precision="double" to ="single" and faster execution times with different memory usage when experimenting with max_parallel_experiments=
No idea :(.
The issue of max_parallel_experiments is same issue as #1873 and it will be fixed by PR #1880
precision='single' will half the memory usage of statevector, but the simulation time will not be half of double precision in most of cases (5-10% performance improvements in most of cases)
