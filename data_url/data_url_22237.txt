Using artiq 2.0 on windows, I ran into a key error when trying to load an experiment to reanalyse,
This is is a datum that is used to set the default argument but isn't set by the experiment. In more detail, if we set the value in the dataset self.set_dataset("data.browser.x", 2, persist=True),
and use this to instantiate a value in an experiment,
I get this error when trying to open the experiment in the browser.
Am I missing something? If not, one solution would be to save all the values from the dataset that are called in anyway by an experiment (through get_dataset). Saving all persistent dataset values to every hd5 file could be another, possibly better solution if we want to keep track of all ion parameters very experiment.
ARTIQ doesn't do anything there by default, because the values of the input datasets can change while the experiment is executing (think of a long experiment that pauses, and gets interrupted by periodic recalibrations).
Because of this possible change of values, snapshots of all persistent values in every HDF5 is not the right solution for keeping track of ion parameters - the influxdb logger is more appropriate, or analyzing multiple HDF5s (since the experiments producing changes will also generate their own output files).
For those input datasets that you know will not change, you can save them manually in the HDF5 with set_dataset(save=True). I'm OK with building this functionality into ARTIQ, by adding an archive argument to get_dataset that also enforces that you can get each dataset only once.
I'm OK with building this functionality into ARTIQ, by adding an archive argument to get_dataset that also enforces that you can get each dataset only once.
I think that's fine for us, except for meta experiments like this.  I guess we can pass an index maybe to an experiment but seems slightly cleaner this way.
while time()-exp_start < self.delay:
sleep(5)
sleep(self.delay-(time()-exp_start)) ?
core_times = self.get_dataset("data.mw.rsb.drift.core_time")
frequencies = self.get_dataset("data.mw.rsb.drift.frequency")
frequency = self.get_dataset("trap.radial_1.mw.f")
I would locate and open the HDF5 file corresponding to rid. Using broadcasted datasets for getting values from the sub-experiments is not robust as the datasets may have been modified in the meantime.
And it is not a problem anyway for the HDF5 archival proposal since you could simply set archive=False on those dataset requests and issue them multiple times.
