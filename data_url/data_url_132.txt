Right now, we have both BLAS and OpenBLAS in the mix, built with and without OpenMP support. It would be nice to see if we can use the same installation across the board and preferably with OpenMP  enabled.
What is currently preventing this is that we see sporadic failures (Illegal instructions) with the VQE H2 tests, caused by the LBFGS optimizer that comes from ensmallen. In principle, ensmallen says it supports OpenBLAS, but something seems to not quite work here when using OpenBLAS instead of BLAS. It might be worth giving 0.3.21 a shot - this is an older version that might be more compatible with ensmallen, but that's a shot in the dark.
The following OpenBLAS packages exist, and in principle meet our needs: libopenblas-dev (via apt-get), openblas-static (via dnf).
It would be nicer to build from source, since this can be done on all platforms:
Download location: https://github.com/xianyi/OpenBLAS/releases/download/v0.3.23/OpenBLAS-0.3.23.tar.gz
Build with OpenMP support: make USE_OPENMP=0 && make install PREFIX=...
Note that gcc and clang work with different OpenMP libraries (libgomp vs libomp).
To enable OpenMP support we hence should build OpenBLAS with the same compiler toolchain as we build CUDA Quantum with to ensure we link against the OpenMP library supported by that compiler.
If we can do so and it is appropriate, we should isolate a small test case and file a bug against ensmallen and/or OpenBLAS.
Why do you include ensmallen + armadillo, if you already have Eigen and could use e.g. OptimLib? Eigen is much faster than armadillo and you could reduce dependencies. I sure don't know the details yet but have you already considered that?
I have considered it, I ultimately chose ensmallen because it had more optimization algorithms implemented. The good thing is that optimizers in cuda quantum can sort of be seen as an opt-in extension, you can use it or not and you can add more if you want. I do want to get rid of the NLOpt optimizers, perhaps we should consider adding new optimizers from OptimLib.
