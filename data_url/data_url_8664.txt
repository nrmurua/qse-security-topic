Is it possible to use MKL blas for sparse matrix products? I wonder how much faster it can be compared to spmv...
I'm not sure, I've never used MKL, but I don't think it give much (or any) improvement for sparse matrix products since it probably doesn't use BLAS routines. Perhaps @nonhermitian knows something about it, or perhaps if sparse matrix products is any faster with OpenBLAS?
I have noticed some performance benefits with openblas but nothing noticeable for the sparse matrix routines.  Multithreading gets some extra performance but the scaling is sublinear for sure.  Just a couple of percent.  From what I understand many sparse routines are limited by memory bandwidth.  This is usually discussed in the context of the spmv.
The biggest benefit when going to openblas is the removal of the umfpack out of memory errors.  I dont think this has anything to do with the actual openblas functions but somewhere in the build process (suitesparse, metis, or something) the memory limitation is removed.
Hi Paul,
How do you use openblas from python? I found that some blas routines are exposed in numpy but not all of them. Are there some examples of sparse blas calls from python?
EPD and Anaconda python include MKL so I would like to play a bit with sparse blas routines.
I good guide for compiling openblas and building numpy against it can be found here:
osdf.github.io/blog/numpyscipy-w ith-openblas-for-ubuntu-1204-second-try.html
Calling the blas functions from inside of cython was a project called Tokyo:
https://github.com/tokyo/tokyo
As you can tell by the file dates, it has more or less been abandoned.  However, the work they have done would obviously be a good starting point for doing something similar.
Thank you for the links
