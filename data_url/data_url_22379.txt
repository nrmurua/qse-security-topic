Is there a way to call applets from the script for given datasets or automaticly plot the output of a fit/scan etc.? If not, I think we need that.
How is this supposed to work?
I think it means we should be able to start an applet from a script, i.e, create an applet with the parameters we want, set it enable so when you submit the experiment you can see the plot without having to separately set up the applet.
Yes, but how is it configured? What if the applet already exists? What if the experiment creates an applet, then the user modifies its parameters in the GUI, and the experiment is run again - should it create another applet?
When an experiment starts an applet, how to display it in a way that does not disrupt whatever the user was doing?
Probably one would have to identify the applet by some sort of name. If it already exists, I think it should just enable the applet. If it doesn't exist it should create it and enable immediately. If the name of the applet is the same but the parameters are modified perhaps it should just replace the old applet of the same name?
If the experiment starts an applet I think it's fine if it just pops up like it does if you start an applet now. I imagine in the typical use case, the user has just submitted an experiment and wants to see the plot immediately so is expecting the applet to pop up somewhere anyway.
Hi,
I'm not sure if I under stand 'disrupt what the user is doing' correctly. Do you mean the current window, text box etc. looses focus? Or is there something more fundamental?
Would it be possible to leave these decisions to the user? It might be that we see that we need some plots to open and focus and not replace other plots but some data from several experiments might be plotted in just one applet replacing whatever was in there before. Or we might want to plot several data sets from multiple runs of the same experiment in the same graph/plot.
For now I would be happy to be able to open a applet and tell it what to plot from the experiment script. and the applet overrides an applet with the same name/id or just overrides the data with the new data, but leaves the position of the app as it was.
Is there some documentation about the applets or some sort of roadmap/future feature list?
One option might also be to include plots in the experiment window.
D.
That applet dock would appear at some random time. Completely independent and unrelated to a user action. This goes against HIG in a rather offensive way and kills usability. Imagine you are just dragging and dropping something or just about to click on some TTL button and the UI changes under your nose/mouse. In the worst case your click will now end up on the new applet. Sensibly, we could think about doing this but only at the request of the user ("fill/open suggested applets").
Come on, Robert.  This was a hostile answer to a legitimate proposal for how things might work.  If the user has the ability to select whether the applet receives focus or not when it appears (and the default behavior is for it not to receive focus), then users should be able to customize to their taste, regardless of generalized principles of UI design saying that having a window receive focus when it appears is not a good idea.  If this is the functionality that is being requested by multiple users, it seems clear that it does not in fact "kill usability".
The big issue is this: right now there is no way of sending data from an analyze() method to be displayed in an applet in an automated way.  So how about something like this:
What would the difficulties be in implementing such a specification?  Are there corner cases not considered here that would need to be handled?
No Daniel. Calm down. It is hostile to attack the style of a contribution or the person behind it. And others would even take it personal if their technical comments are brushed away and consider that hostile. But attacking the content of a comment with specific criticism is not hostile. That's just an argument. You should really not use "many people want something like this" as a means to short-circuit a technical discussion on how to implement it.
Did you really just completely ignore the proposal to resolve my criticism?
If a user interface changes in certain ways (stuff appearing, disappearing or moving around) not as a response to a request by the user, then that's is problematic. Users are offended by applications creating windows and docks when they didn't ask for them and when they can't at least roughly predict when they will jump at them. Calm, organized, and predictable behavior of a UI is so much more valuable. The docks/windows don't even have to steal focus. Whether a new window gets focus or not is not relevant. Its mere appearance can easily lead to undesired effects because the user does not expect it.
This is not some hypothetical and obscure corner case construct that we are making up just to get rid of tedious feature requests: just try moving windows around or clicking on buttons in HfGui while it is starting and spewing more and more windows in more or less unpredictable places. Or a random fat news web page that changes while it is loading. Or just ads on the web.
The corner cases not considered are (summarizing what was said already):
But other than that who said the feature per se is particularly difficult to implement? It is just work. Doing it right and without breaking other things is what's difficult.
And it is instructive to see this feature as part of a bigger concept, scripting the dashboard. Both because discussing the bigger concept would provide clear and "obvious" guidelines on how to implement this and because other feature requests will come that also fall into this concept. Scripting the GUI would allow users to open/close/arrange groups of experiments/applets, implement typical lab work-flows (load ion, tweak things, do physics, keep stuff calibrated) etc.
OK, so let's attack the problem.  Where/when do you propose to have a "fill/open suggested applets" feature?  This cannot be a dialog box that pops up or else it violates the same UI guidelines that you have described.  So how should it be implemented?  If there is a dedicated permanent button on the UI that can be clicked by the user when desired, that would be good.  So now the questions:
I think that a lot of these notions extend in a reasonable way to interfacing with experimental replay concepts, but all thoughts/suggestions/comments are welcome.  All things with a checkbox/button listed above would also need to be scriptable obviously.
@dkienzler @r-srinivas I am interested in your thoughts on these ideas.
Hi,
@jordens @sbourdeauducq
Right now we are typing the name of the data set in a new applet we create by hand in the GUI. this is very cumbersome. Is there some other way you intended the GUI plotting to be used? Is there some way of coding the applets? I don't think filling in dataset names in the GUI for ~ 200-400 experiments (which is minimum of what we've looking at for Quantum 2) is a viable option.
Robert, I don't see a problem with a plot updating if it's in the background. Could you elaborate on this? This is actually the way the GUI currently behaves, if the applet is already open and the experiment is automatically re-run, the new data gets filled into the applet automatically.
Another question: Right now everything seems to be happening in one main window. That's not very usable for a multi-screen environment. Is it possible to break the window up in several? Maybe I just haven't found how this works... (See also below for the option of a dashboard for plots.)
@jordens @sbourdeauducq @dhslichter @r-srinivas
My experience originates from the Zurich Ionizer derivate, where you get a new plot window for every experiment you run. I see that it is not possible to use that scheme for a large-scale experiment with constant calibrations running automated. Still I think it's necessary to be able to look at these plots quickly. Do you think a dashboard might be an option, where all or most open applets live? (In Quantum 2 we are talking about ~5 calibration experiments run in the background, so not the 400 I was talking above about).
I think a 'hold' feature like Daniel described it would certainly be nice, or a possibility to plot, say the last 5 scans of a calibration run, where always the oldest gets dropped when a new calibration is run. This would probably need some kind of counter on the data sets.
I think the queue Daniel suggested is not the worst Idea. I would still vote for an option "open immediately". If you're operating a very basic experiment I think there is no danger of being overwhelmed by random plots popping up.
The common window I think would also be a good think to have, for scans you run once in the morning, but don't have a calibration for running in the background.
Right now we are typing the name of the data set in a new applet we create by hand in the GUI. this is very cumbersome.
2.0.dev has autocompletion.
Another question: Right now everything seems to be happening in one main window. That's not very usable for a multi-screen environment. Is it possible to break the window up in several
You can resize the main window to span several screens, and detach docks and place them on other screens.
a possibility to plot, say the last 5 scans of a calibration run, where always the oldest gets dropped when a new calibration is run.
The calibration experiment can maintain a single dataset with the output from its last 5 runs (e.g. as 2D numpy arrays where one dimension is the run number), and then a custom applet can plot them as desired.
Right now we are typing the name of the data set in a new applet we create by hand in the GUI. this is very cumbersome.
2.0.dev has autocompletion.
While it is a small improvement, this doesn't address the main issue -- one should not have to manually type in the datasets to be plotted in an applet every time.  We need to be able to automate this completely given the number of plots that will be shown in typical use cases.
@dkienzler I don't think that having a new plot come up for each experiment run is the ideal way to go, given the complexity of things (although I don't think you are really proposing to do this?)
You can resize the main window to span several screens, and detach docks and place them on other screens.
OK. Thanks. I only tried this with the experiment window, for which it does not work.
@dkienzler I don't think that having a new plot come up for each experiment run is the ideal way to go, given the complexity of things (although I don't think you are really proposing to do this?)
No, not in principle, but possibly for each experiment (one for carrier A, one for rsb A, one for carrier B ...)
But it would still be nice to have access to all of them.
I played around a little and of course it's possible to just call the dataset the same in each experiment, that way they are going to be shown in the same window.
But I guess that will make it impossible to later look again at old plots (and also it's discouraged in the manual). I think wildcards might be a viable solution. That way I could call my datasets 'X_DATASET_carier_xyz_time_scan' and call it in an applet with '--x X_DATASET*'. And I could still later open a applet to look at 'X_DATASET_carier_xyz_time_scan' specifically by defining '--x X_DATASET_carier_xyz_time_scan'.
We would just need to make sure, that it always takes the newest dataset that maches the wildcard-string.
I guess that way I would even be able to number the different runs of the experiment.
Do you think that would be possible? Probably I've forgotten some caveat.
OK. Thanks. I only tried this with the experiment window, for which it does not work.
Unlike docks, the experiment windows are captive to the main window. But there should be no problem with the main window spanning multiple screens.
The analogy here would be to something like the HFGui common plot, where you have a window that can be used to show the latest counts vs scan variable scan, for example. This is primarily for diagnostic purposes in an experiment so you may not want a new window to pop up each time you change scan variable, for example. In the case of something like the common plot, you would probably not want to have to hit "fill/open applets" every time a differently named dataset is to be shown in the "common plot", so having a mechanism that allows one to update the data in an existing applet to new/differently named datasets without user clicks/interaction would be nice.
While not perfect, copying the dataset to another "common_xy_plot" dataset in the experiments is a simple way of doing this.
But I guess that will make it impossible to later look again at old plots (and also it's discouraged in the manual).
Old plots are archived in the HDF5 files, and there will be a separate tool (artiq_browser) to look at them. Though you may not want to archive "common_xy_plot" etc. in the HDF5s (but only the original copy of the datasets)...
Would the following ideas solve most of the problem:
These are good ideas, @sbourdeauducq , but I don't really see how they will address the main issue that was initially raised, namely automated generation of new applets from an experimental run.  Are we backtracking completely on the "fill/open suggested applets" idea?  The point is that we would like to be able to run experiments and have various results appear without having to manually invoke applets with specific dataset names.
To your individual points:
Yes, with those "display datasets", I think that the applet configuration could be simple enough and rather static, and configuring them from experiments may be not needed.
Yes, the current framework can do that and already has an option to enable/disable HDF5 output per dataset, it is called save (not archive).
Datasets updates are never dropped and when "hold" is released, the applet updates to the current dataset immediately.
Im way behind in terms of actually using Artiq but trying to catch up but I will throw out an opinion anyway.
I agree that having random applets show up randomly on the screen is annoying and would drive me nuts but isn't that up to the user?  Can't the user choose how to use that feature and make the decision themselves in their code.
I think the absence of the "common plot" would be really annoying.  I see a lot of value in being able to write up an experiment that whenever it runs it updates the common plot.  If I dont want a calibration routine to show up in that plot I can control that in the file, right?
And if i can have a "common plot" I can have "common plot 2" and so forth to use for calibrations or whatever.  If the applet named common plot doesnt exist it should create it, if it does then it overwrites it.
None of this affects the integrity of the data right?  The results are still stored, its just the real time plotting of that data, not analysis.
Regarding your "common plot" comments, see my point 1.
All of this still does not resolve the question of having applets be automatically configurable/launchable.  The approach @sbourdeauducq is proposing still means you have to manually launch applets for each of the desired named "display datasets" beforehand, and then each experiment has to reference those specific dataset names to come up in the already created plots.  I still want to be able to have ARTIQ launch applets to display different kinds of data without my having to manually create the applets first. For something like just implementing a common plot (or several common plots), it's perhaps not so bad if one can script applet creation at startup (or if the state is saved each time).  But let's say you do something dumb like accidentally closing the common plot, or you run a special calibration experiment that generates 3 different diagnostic graphs.  One should not have to manually create all of these applets to see the data (remembering the names of the datasets to which the data is written etc).  It should be possible for ARTIQ to create/recreate them automatically.  The queue design for applets solves this problem while allowing for compliance with UI best practices, and can reuse code from the experiment queue for efficient implementation in the GUI.  One can add a checkbox of "create applets immediately" to allow the user, as @ksmckay suggests, to have applets appear without having to click "fill/open applets", at the cost of disobeying the rule of not having windows pop up at random.  Some people want this feature, but it should not be the default behavior.
None of this is at odds with what @sbourdeauducq has proposed, just adds a needed functionality.
@dhslichter Closing an applet does not delete its configuration, it just unticks its "enabled" checkbox ...
I would think that we could simply allow applets to be created but only in prepare, so that they would not pop up randomly and instead pop up immediately after the user presses run.   Doesn't this satisfy ui design best practices?  Then we don't need the queue, which sounds a bit annoying to use.
This is a feature I would like to have.
see also #514
Applet grouping is done, with some extras: nested groups, reordering applets and groups by drag-and-drop, and simplified command line.
Does anyone really need to edit code applets from the dashboard? There are two main issues with that:
Also, what types of applet creation request filtering are useful?
I think being able to edit from the dashboard isn't a big deal if we can edit it from the script. Of course, it would be nice to be able to reorder them from the dashboard.
I'm not sure what you mean by applet creation request filtering.
All operations are supported (except editing the code).
What I mean is: what sort of selection of the applet requests from the experiment should the dashboard support? Right now, you can either ignore all of them, or take into account all of them. Is anything fine-grained desirable? With what criteria?
I see, so if some experiments generate new applets, should the dashboard accept all of them or just ignore all of them until you make a decision? It could be nice if you could accept or ignore at a group level. I could imagine running a set of experiments together, they would have applets in the same group and we would want those applets to appear as they're created.
until you make a decision?
What do you mean? The applet is either created or the request is ignored immediately.
I meant more whether to enable them or not. When you say create does that include them appearing in the applet dock and being enabled?
Yes.
I can easily implement "ignore/create/create+enable" modes in the dashboard, selected with a menu.
I think having those options would be useful. It could be nice to be able to apply those options on an applet group level as well.
Definitely would be nice to have the different modes apply on a group level, but not sure how one would implement this in a nice way in the GUI.  Perhaps by right-clicking on the group name in the applet list to bring up a pop-up menu?
Also, does self.ccb.issue have to be called in run or it can it be called from prepare?
In the code at 
I find this makes the code easier to read, since you get syntax highlighting, and makes it feel like less of a bolt-on hack.
Perhaps by right-clicking on the group name in the applet list to bring up a pop-up menu?
There are some corner cases. Imagine the following situation: you ignore requests for a group deep into the hierarchy, then delete all traces of that group in the GUI, and requests keep being ignored. You cannot edit the group rule because the group is no longer displayed. I suppose it could automatically delete the corresponding group rules when a group is deleted, and fall back on the global rule.
Also, does self.ccb.issue have to be called in run or it can it be called from prepare?
It can be called from prepare.
I find this makes the code easier to read, since you get syntax highlighting, and makes it feel like less of a bolt-on hack.
It will have to be y="flopping_f_brightness"... (with additional quotes), this syntax is not general, and I find it confusing. Why try to hide the fact that the applet is a separate program?
Can the function for disable applet just disable one applet? Can it also be used to disable a group of applets or all applets? The case I'm thinking of is when we have a separate run of the experiment and would maybe like to clear the dashboard of applet clutter before displaying applets as experiments run.
Yes, make a list of the applets you have created and call the function repeatedly.
Is that list kept track of automatically and you can just get it or do you have to keep track of it yourself?
The user may have added/deleted applets and only the dashboard knows about that. There is no dashboard->experiment communication there. Keeping track in the experiments is much simpler (e.g. write wrapper functions that maintain the list, and pass it via dataset across experiments) and more flexible.
That being said, disable_applet_group should be straightforward.
Okay. If that's the case then it could be useful to be able to enable/disable applet groups from the code. Maybe just a disable all applets function as well.
All done except disabling all applets. I suggest creating a group "experiment-controlled applets" instead, possibly with sub-groups.
