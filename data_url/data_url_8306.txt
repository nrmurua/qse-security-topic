I've been playing around with larger systems recently; when I started out ptrace had a memory issue and couldn't handle what I was doing, so I had written a home-made version to do it. Recently I ended up doing the ptrace with the fixed built-in function and I found it to be much slower.
I did some testing with my new function. At least on the machine I'm running on, with 9+ qubits it's about 10x faster for calculating a partial trace on a density matrix. If you're starting out with a ket, you can go even faster, an additional 5x improvement: (test code below)
My new version is pretty simple, using numpy's built-in ndarray routines. I've looked at the code for ptrace and it's a bit opaque to me; at the moment I don't feel quite up to modifying it, so I'm just putting up the code I've used instead of  doing a pull request.
My new function is here:
and the test code here:
Thank you for the code.
The present version use sparse matrices so it can be used for bigger system (tested up to 26 Qbit).
For size that fit in memory, your version is great. And we don't have any ket version.
I can make the PR if you don't feel comfortable.
A much faster version einsum built in function in numpy I actually implemented it to mathematica you can use same idea to do it for python
https://drive.google.com/file/d/1RgVv40sw8PmAdXY_kTxGNWqFDrMEOMje/view?usp=drivesdk
