The quantum_neural_network.py example output is Nan when using more than 1 mode. (working as expected for 1 mode)
Expected behavior: Not Nan
Actual behavior: Beginning optimization Rep: 0 Cost: 7.0005 Fidelity: 0.0000 Trace: 1.0000 Rep: 1 Cost: nan Fidelity: nan Trace: nan Rep: 2 Cost: nan Fidelity: nan Trace: nan Rep: 3 Cost: nan Fidelity: nan Trace: nan
Reproduces how often: 100%
System information:
update line 135 of the example quantum_neural_network.py from modes = 1 to modes = 2
Hi @jonasbrami, thank you for catching this! I could reproduce the issue based on your suggestion and it seems that the issue is with computing the gradient of the
line in the cost function. Changing the absolute value computation such that a relatively small constant is added and having tf.abs(ket - target_state + 1e-10) makes the resulting nan values disappear.
We're considering a fitting fix here.
Hi @jonasbrami, we've updated the example, it should work now for multiple modes. Let us know if something else comes up ðŸ™‚
