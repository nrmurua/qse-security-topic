{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from gensim import corpora, models\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the directory path containing the text files\n",
    "directory = 'data_url'\n",
    "\n",
    "# Set the path to the stopwords file\n",
    "stopwords_file = 'stopWords2.txt'\n",
    "\n",
    "# Set the output file path\n",
    "output_file = 'topics.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load stopwords from the stopwords file\n",
    "with open(stopwords_file, 'r') as file:\n",
    "    stopwords_list = file.read().splitlines()\n",
    "\n",
    "# Create a list of stopwords by combining NLTK stopwords and custom stopwords\n",
    "stopwords_list += stopwords.words('english')\n",
    "stopwords_list += [\"n\\'t\", \"\\'ve\", \"\\'ll\", \"\\\\users\\\\abc_user\\\\appdata\\\\roaming\\\\python\\\\python36\\\\site-packages\\\\projectq\\\\cengines\\\\_optimize.py\", \"\\\\users\\\\abc_user\\\\appdata\\\\roaming\\\\python\\\\python36\\\\site-packages\\\\projectq\\\\cengines\\\\_basics.py\"]\n",
    "stopwords_list += [\"/usr/bin/ld\", \"'s\",\"q\",\"/opt/openssl/.openssl/lib/libssl.a\",\"''\",\"'m\",\"'re\",\"large\",\"'d\",\"operators\",\"-wl\",\"pre-commit\",\"static\",\"/usr/bin/ld\",\"oqs_meth.c\",\"/opt/openssl/.openssl/lib/libcrypto.a\",\"extensions_clnt.c\",\"oqs_meth.o\",\"cp2k.popt\",\"extensions_srvr.c\",\"e.g\",\"-z\"]\n",
    "stopwords_list += [\"libxsmm_se=1\",\"oqs_kem_free'\",\"oqs_kem_free\",\"base\", \"ridge\", \"helper\", \"moment\", \"assumed\", \"workaround\", \"logic\", \"psis_bitrev_montgomery\", \"packets\", \"fails\", \"easy\", \"rely\", \"generated\", \"addition\", \"enforced\", \"function\", \"language\", \"instance\", \"helped\", \"years\", \"/sys/fs/selinux/enforce\",\"underlying\"]\n",
    "stopwords_list += [\"qldbsession.qldbsession\",\"18.04.2\",\"absolutely\",\"compile\",\"separate\",\"packet\",\"configure\", \"power\",\"cxxompflags\",\"compiled\",\"fails\",\"fail\",\"latest\",\"optimal\",\"assume\",\"making\",\"regular\",\"people\",\"specification\",\"specifications\",\"libxsmm_se=0\",\"extra\",\"extra\",\"buffer\",\"exchange\",\"practical\",\"oqs_kem_new\",\"oqs_sig_free'\",\"oqs-openssl\",\"offline\",\"read\",\"great\",\"company\",\"request\",\"concern\",\"means\",\"ca\",\"hear\"]\n",
    "stopwords_list += [\"implementing\",\"ec\",\"ci\",\"save\",\"storage\",\"json\",\"dictionary\",\"mind\",\"naming\",\"fixes\",\"complete\",\"complete\",\"page\",\"functions\",\"liboqs\",\"qldbdriver\",\"effort\",\"exists\",\"requests\",\"progress\",\"338\",\"operator\",\"module\",\"dig\",\"worked\",\"explicitly\",\"installation\",\"observe\",\"constructor\",\"potential\",\"pointer\",\"oqs\",\"1.10\",\"pip\",\"millions\",\"oqs-chromium\",\"extremely\",\"fine\",\"start\",\"generating\",\"startup\",\"re-used\",\"constants\",\"engine\",\"cases\",\"writing\",\"pages\",\".text+0x13d\",\".text+0x489c\",\"oqs_sig_sign'\"]\n",
    "stopwords_list += [\"understand\",\"settings\",\"428\",\"improved\",\"clear\",\"hard\",\"condition\",\"submit\",\"pay\",\"precommit\",\"g\",\"spot\",\"transport\",\"sqrt\",\"pre-computed\",\"pushed\",\"replicate\",\"instructions\",\"task\",\"pays\",\"helpful\",\"swapped\",\"information\",\"rebuild\",\"expected\",\"existing\",\"string\",\"enforce\",\"libraries\",\"crytpo\",\"figure\",\"codes\",\"selection\",\"oqs_kem_alg_is_enabled'\",\"128\",\"ld\",\"re-build\",\"choose\",\"scientific\",\"url\",\"elpa\",\"-l/opt/openssl/oqs/lib\",\"space\"]\n",
    "stopwords_list += [\"checksums\",\"mirror\",\"2c11076\",\"ubuntu\",\"download\",\"preseved\",\"practice\",\"difficult\",\"//github.com/yhyoo93/isogenysignature/blob/master/validate.c\",\"loss\",\"incentive\",\"implications\",\"ulimit\",\"anymore\",\"shy\",\"ðŸ˜…ðŸ˜…\",\"capabilities\",\"ray\",\"calculated\",\"install_elpa.sh\",\"share\",\"replace\",\"t1_lib.c\",\".text+0x47b\",\"content\",\"suppose\",\"purpose\",\"newhope_n/2\",\"successfully\",\"property\",\"format\",\"stored\",\"storing\",\"pickle\",\"saving\",\"noticable\",\"incoming/outgoing\",\"small\",\"attendee\",\"unnecessary\",\"compare\",\"expensive\",\"holding\",\"longer\",\"load\",\"links\",\"select\",\"strength\",\"give\",\"pickling\",\"integer\",\"conduct\"]\n",
    "stopwords_list += [\"simple\",\"initial\",\"no-check-certificate\",\"returned\",\"classes\",\"chose\",\"response\",\"grow\",\"basic\",\".text+0x45cc\",\"times\",\"slower\",\"alice\",\"compute\",\"accessible\",\"pipelines\",\"pair\",\"suggest\",\"str\",\"individual\",\"pkey_oqs_digestverify\",\"framework\",\"rate-limited\",\"404\",\"simplify\",\"front\",\"numeric\",\"numerics\",\"plenty\",\"array\",\"cuz\",\"long\",\"oak\"]\n",
    "stopwords_list += [\"extensions_srvr.o\",\"with-ld-opt='-l/opt/openssl/oqs/lib-wl\",\"arguments\",\"oqs_sig_free\",\"stuff\",\"-fopenmp\",\"bad\",\"parameters\", \"\\n\"]\n",
    "\n",
    "# Initialize an empty list to store the document texts\n",
    "documents = []\n",
    "\n",
    "# Read the file names from the 'keywords' file\n",
    "file_names = []\n",
    "with open('keywords.txt', 'r') as file:\n",
    "    lines = file.read().splitlines()\n",
    "    for line in lines:\n",
    "        if line.startswith('Source File:'):\n",
    "            filename = line.replace('Source File:', '').strip()\n",
    "            file_names.append(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over the file names\n",
    "for filename in file_names:\n",
    "    file_path = os.path.join(directory, filename)\n",
    "\n",
    "    # Check if the file exists\n",
    "    if os.path.isfile(file_path):\n",
    "        with open(file_path, 'r') as file:\n",
    "            content = file.read()\n",
    "\n",
    "            # Tokenize the text into words\n",
    "            tokens = word_tokenize(content)\n",
    "\n",
    "            # Remove stopwords and convert words to lowercase\n",
    "            filtered_words = [word.lower() for word in tokens if word.lower() not in stopwords_list ]\n",
    "\n",
    "            # Append the filtered words to the documents list\n",
    "            documents.append(filtered_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary from the documents\n",
    "dictionary = corpora.Dictionary(documents)\n",
    "\n",
    "# Create a corpus (bag of words) from the documents\n",
    "corpus = [dictionary.doc2bow(doc) for doc in documents]\n",
    "\n",
    "# Perform LDA topic modeling\n",
    "lda_model = models.LdaModel(corpus, id2word=dictionary, num_topics=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the topics and their top words to a file\n",
    "with open(output_file, 'w') as file:\n",
    "    for topic_id, topic_words in lda_model.show_topics():\n",
    "        file.write(f\"Topic ID: {topic_id}\\n\")\n",
    "        file.write(f\"Top Words: {topic_words}\\n\")\n",
    "        file.write('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
